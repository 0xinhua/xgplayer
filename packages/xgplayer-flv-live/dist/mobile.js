!function(e,n){"object"==typeof exports&&"object"==typeof module?module.exports=n(require("xgplayer")):"function"==typeof define&&define.amd?define(["xgplayer"],n):"object"==typeof exports?exports["xgplayer-flv"]=n(require("xgplayer")):e["xgplayer-flv"]=n(e.xgplayer)}(window,(function(__WEBPACK_EXTERNAL_MODULE_xgplayer__){return function(e){var n={};function t(r){if(n[r])return n[r].exports;var a=n[r]={i:r,l:!1,exports:{}};return e[r].call(a.exports,a,a.exports,t),a.l=!0,a.exports}return t.m=e,t.c=n,t.d=function(e,n,r){t.o(e,n)||Object.defineProperty(e,n,{enumerable:!0,get:r})},t.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},t.t=function(e,n){if(1&n&&(e=t(e)),8&n)return e;if(4&n&&"object"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(t.r(r),Object.defineProperty(r,"default",{enumerable:!0,value:e}),2&n&&"string"!=typeof e)for(var a in e)t.d(r,a,function(n){return e[n]}.bind(null,a));return r},t.n=function(e){var n=e&&e.__esModule?function(){return e.default}:function(){return e};return t.d(n,"a",n),n},t.o=function(e,n){return Object.prototype.hasOwnProperty.call(e,n)},t.p="",t(t.s=1)}({"../../node_modules/events/events.js":
/*!*****************************************************************************************!*\
  !*** /Users/leonardo/Documents/front-end/player/xgplayer/node_modules/events/events.js ***!
  \*****************************************************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null;\nvar ReflectApply = R && typeof R.apply === 'function' ? R.apply : function ReflectApply(target, receiver, args) {\n  return Function.prototype.apply.call(target, receiver, args);\n};\n\nvar ReflectOwnKeys;\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys;\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target).concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n};\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function () {\n    return defaultMaxListeners;\n  },\n  set: function (arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function () {\n\n  if (this._events === undefined || this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction $getMaxListeners(that) {\n  if (that._maxListeners === undefined) return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return $getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = type === 'error';\n\n  var events = this._events;\n  if (events !== undefined) doError = doError && events.error === undefined;else if (!doError) return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0) er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined) return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i) ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type, listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] = prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = $getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' + existing.length + ' ' + String(type) + ' listeners ' + 'added. Use emitter.setMaxListeners() to ' + 'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener = function prependListener(type, listener) {\n  return _addListener(this, type, listener, true);\n};\n\nfunction onceWrapper() {\n  var args = [];\n  for (var i = 0; i < arguments.length; i++) args.push(arguments[i]);\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    ReflectApply(this.listener, this.target, args);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener = function prependOnceListener(type, listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n  this.prependListener(type, _onceWrap(this, type, listener));\n  return this;\n};\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener = function removeListener(type, listener) {\n  var list, events, position, i, originalListener;\n\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n\n  events = this._events;\n  if (events === undefined) return this;\n\n  list = events[type];\n  if (list === undefined) return this;\n\n  if (list === listener || list.listener === listener) {\n    if (--this._eventsCount === 0) this._events = Object.create(null);else {\n      delete events[type];\n      if (events.removeListener) this.emit('removeListener', type, list.listener || listener);\n    }\n  } else if (typeof list !== 'function') {\n    position = -1;\n\n    for (i = list.length - 1; i >= 0; i--) {\n      if (list[i] === listener || list[i].listener === listener) {\n        originalListener = list[i].listener;\n        position = i;\n        break;\n      }\n    }\n\n    if (position < 0) return this;\n\n    if (position === 0) list.shift();else {\n      spliceOne(list, position);\n    }\n\n    if (list.length === 1) events[type] = list[0];\n\n    if (events.removeListener !== undefined) this.emit('removeListener', type, originalListener || listener);\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners = function removeAllListeners(type) {\n  var listeners, events, i;\n\n  events = this._events;\n  if (events === undefined) return this;\n\n  // not listening for removeListener, no need to emit\n  if (events.removeListener === undefined) {\n    if (arguments.length === 0) {\n      this._events = Object.create(null);\n      this._eventsCount = 0;\n    } else if (events[type] !== undefined) {\n      if (--this._eventsCount === 0) this._events = Object.create(null);else delete events[type];\n    }\n    return this;\n  }\n\n  // emit removeListener for all listeners on all events\n  if (arguments.length === 0) {\n    var keys = Object.keys(events);\n    var key;\n    for (i = 0; i < keys.length; ++i) {\n      key = keys[i];\n      if (key === 'removeListener') continue;\n      this.removeAllListeners(key);\n    }\n    this.removeAllListeners('removeListener');\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n    return this;\n  }\n\n  listeners = events[type];\n\n  if (typeof listeners === 'function') {\n    this.removeListener(type, listeners);\n  } else if (listeners !== undefined) {\n    // LIFO order\n    for (i = listeners.length - 1; i >= 0; i--) {\n      this.removeListener(type, listeners[i]);\n    }\n  }\n\n  return this;\n};\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined) return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined) return [];\n\n  if (typeof evlistener === 'function') return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ? unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function (emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i) copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++) list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\n//# sourceURL=webpack://xgplayer-flv//Users/leonardo/Documents/front-end/player/xgplayer/node_modules/events/events.js?")},"../xgplayer-buffer/index.js":
/*!***********************************!*\
  !*** ../xgplayer-buffer/index.js ***!
  \***********************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nmodule.exports = {\n  Track: __webpack_require__(/*! ./src/track */ "../xgplayer-buffer/src/track.js").default,\n  Tracks: __webpack_require__(/*! ./src/track */ "../xgplayer-buffer/src/track.js").Tracks,\n  AudioTrack: __webpack_require__(/*! ./src/track */ "../xgplayer-buffer/src/track.js").AudioTrack,\n  VideoTrack: __webpack_require__(/*! ./src/track */ "../xgplayer-buffer/src/track.js").VideoTrack,\n\n  XgBuffer: __webpack_require__(/*! ./src/buffer */ "../xgplayer-buffer/src/buffer.js").XgBuffer,\n  RemuxBuffer: __webpack_require__(/*! ./src/buffer */ "../xgplayer-buffer/src/buffer.js").RemuxBuffer,\n\n  PreSource: __webpack_require__(/*! ./src/presouce */ "../xgplayer-buffer/src/presouce.js").default\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-buffer/index.js?')},"../xgplayer-buffer/src/buffer.js":
/*!****************************************!*\
  !*** ../xgplayer-buffer/src/buffer.js ***!
  \****************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\nclass XgBuffer {\n  /**\n   * A buffer to store loaded data.\n   *\n   * @class LoaderBuffer\n   * @param {number} length - Optional the buffer size\n   */\n  constructor(length) {\n    this.length = length || 0;\n    this.historyLen = length || 0;\n    this.array = [];\n    this.offset = 0;\n  }\n\n  /**\n   * The function to push data.\n   *\n   * @param {number} data - The data to push into the buffer\n   */\n  push(data) {\n    this.array.push(data);\n    this.length += data.byteLength;\n    this.historyLen += data.byteLength;\n  }\n\n  /**\n   * The function to shift data.\n   *\n   * @param {number} length - The size of shift.\n   */\n  shift(length) {\n    if (this.array.length < 1) {\n      return new Uint8Array(0);\n    }\n\n    if (length === undefined) {\n      return this._shiftBuffer();\n    }\n    if (this.offset + length === this.array[0].length) {\n      let ret = this.array[0].slice(this.offset, this.offset + length);\n      this.offset = 0;\n      this.array.shift();\n      this.length -= length;\n      return ret;\n    }\n\n    if (this.offset + length < this.array[0].length) {\n      let ret = this.array[0].slice(this.offset, this.offset + length);\n      this.offset += length;\n      this.length -= length;\n      return ret;\n    }\n\n    let ret = new Uint8Array(length);\n    let tmpoff = 0;\n    while (this.array.length > 0 && length > 0) {\n      if (this.offset + length < this.array[0].length) {\n        let tmp = this.array[0].slice(this.offset, this.offset + length);\n        ret.set(tmp, tmpoff);\n        this.offset += length;\n        this.length -= length;\n        length = 0;\n        break;\n      } else {\n        let templength = this.array[0].length - this.offset;\n        ret.set(this.array[0].slice(this.offset, this.array[0].length), tmpoff);\n        this.array.shift();\n        this.offset = 0;\n        tmpoff += templength;\n        this.length -= templength;\n        length -= templength;\n      }\n    }\n    return ret;\n  }\n\n  /**\n   * Function to clear the buffer.\n   */\n  clear() {\n    this.array = [];\n    this.length = 0;\n    this.offset = 0;\n  }\n\n  destroy() {\n    this.clear();\n    this.historyLen = 0;\n  }\n\n  /**\n   * Function to shift one unit8Array.\n   */\n  _shiftBuffer() {\n    this.length -= this.array[0].length;\n    this.offset = 0;\n    return this.array.shift();\n  }\n\n  /**\n   * Convert uint8 data to number.\n   *\n   * @param {number} start - the start postion.\n   * @param {number} length - the length of data.\n   */\n  toInt(start, length) {\n    let retInt = 0;\n    let i = this.offset + start;\n    while (i < this.offset + length + start) {\n      if (i < this.array[0].length) {\n        retInt = retInt * 256 + this.array[0][i];\n      } else if (this.array[1]) {\n        retInt = retInt * 256 + this.array[1][i - this.array[0].length];\n      }\n\n      i++;\n    }\n    return retInt;\n  }\n}\n\nexports.XgBuffer = XgBuffer;\nclass RemuxBuffer {\n  constructor() {\n    this.video = [];\n    this.audio = [];\n  }\n\n  destroy() {\n    this.video = [];\n    this.audio = [];\n  }\n}\nexports.RemuxBuffer = RemuxBuffer;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-buffer/src/buffer.js?')},"../xgplayer-buffer/src/presouce.js":
/*!******************************************!*\
  !*** ../xgplayer-buffer/src/presouce.js ***!
  \******************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass Source {\n  constructor() {\n    this.mimetype = '';\n    this.init = null;\n    this.data = [];\n  }\n}\n\nclass PreSource {\n  constructor() {\n    this.sources = {};\n  }\n\n  getSource(source) {\n    return this.sources[source];\n  }\n\n  createSource(name) {\n    this.sources[name] = new Source();\n    return this.sources[name];\n  }\n\n  clear() {\n    this.sources = {};\n  }\n\n  destroy() {\n    this.sources = {};\n  }\n}\n\nexports.default = PreSource;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-buffer/src/presouce.js?")},"../xgplayer-buffer/src/track.js":
/*!***************************************!*\
  !*** ../xgplayer-buffer/src/track.js ***!
  \***************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass Track {\n  /**\n   * The constructor.\n   */\n  constructor() {\n    this.id = -1;\n    this.sequenceNumber = 0;\n    this.samples = [];\n    this.droppedSamples = [];\n    this.length = 0;\n  }\n\n  /**\n   * Reset the track.\n   */\n  reset() {\n    this.sequenceNumber = 0;\n    this.samples = [];\n    this.length = 0;\n  }\n  /**\n   * destroy the track.\n   */\n  distroy() {\n    this.reset();\n    this.id = -1;\n  }\n}\n\nexports.default = Track;\nclass AudioTrack extends Track {\n  /**\n   * The constructor for audio track.\n   */\n  constructor() {\n    super();\n    this.TAG = 'AudioTrack';\n    this.type = 'audio';\n  }\n}\n\nexports.AudioTrack = AudioTrack;\nclass VideoTrack extends Track {\n  /**\n   * The constructor for video track.\n   */\n  constructor() {\n    super();\n    this.TAG = 'VideoTrack';\n    this.type = 'video';\n    this.dropped = 0;\n  }\n  /**\n   * reset the video track.\n   */\n  reset() {\n    this.sequenceNumber = 0;\n    this.samples = [];\n    this.length = 0;\n    this.dropped = 0;\n  }\n}\n\nexports.VideoTrack = VideoTrack;\nclass Tracks {\n  constructor() {\n    this.audioTrack = null;\n    this.videoTrack = null;\n  }\n}\nexports.Tracks = Tracks;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-buffer/src/track.js?")},"../xgplayer-codec/index.js":
/*!**********************************!*\
  !*** ../xgplayer-codec/index.js ***!
  \**********************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nmodule.exports = {\n  Nalunit: __webpack_require__(/*! ./src/h264/nalunit */ "../xgplayer-codec/src/h264/nalunit/index.js").default,\n  SpsParser: __webpack_require__(/*! ./src/h264/nalunit/sps */ "../xgplayer-codec/src/h264/nalunit/sps.js").default,\n\n  Compatibility: __webpack_require__(/*! ./src/compatibility */ "../xgplayer-codec/src/compatibility.js").default\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-codec/index.js?')},"../xgplayer-codec/src/aac/aac-helper.js":
/*!***********************************************!*\
  !*** ../xgplayer-codec/src/aac/aac-helper.js ***!
  \***********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\n\nclass AAC {\n\n  static getSilentFrame(codec, channelCount) {\n    if (codec === \'mp4a.40.2\') {\n      // handle LC-AAC\n      if (channelCount === 1) {\n        return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);\n      } else if (channelCount === 2) {\n        return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);\n      } else if (channelCount === 3) {\n        return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);\n      } else if (channelCount === 4) {\n        return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);\n      } else if (channelCount === 5) {\n        return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);\n      } else if (channelCount === 6) {\n        return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);\n      }\n    } else {\n      // handle HE-AAC (mp4a.40.5 / mp4a.40.29)\n      if (channelCount === 1) {\n        // ffmpeg -y -f lavfi -i "aevalsrc=0:d=0.05" -c:a libfdk_aac -profile:a aac_he -b:a 4k output.aac && hexdump -v -e \'16/1 "0x%x," "\\n"\' -v output.aac\n        return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x4e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x1c, 0x6, 0xf1, 0xc1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n      } else if (channelCount === 2) {\n        // ffmpeg -y -f lavfi -i "aevalsrc=0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e \'16/1 "0x%x," "\\n"\' -v output.aac\n        return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n      } else if (channelCount === 3) {\n        // ffmpeg -y -f lavfi -i "aevalsrc=0|0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e \'16/1 "0x%x," "\\n"\' -v output.aac\n        return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n      }\n    }\n    return null;\n  }\n\n}\n\nexports.default = AAC;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-codec/src/aac/aac-helper.js?')},"../xgplayer-codec/src/compatibility.js":
/*!**********************************************!*\
  !*** ../xgplayer-codec/src/compatibility.js ***!
  \**********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _xgplayerUtils = __webpack_require__(/*! xgplayer-utils */ \"../xgplayer-utils/index.js\");\n\nvar _aacHelper = __webpack_require__(/*! ./aac/aac-helper */ \"../xgplayer-codec/src/aac/aac-helper.js\");\n\nvar _aacHelper2 = _interopRequireDefault(_aacHelper);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst { REMUX_EVENTS } = _xgplayerUtils.EVENTS;\n\nclass Compatibility {\n  constructor() {\n    this.nextAudioDts = 0; // 模拟下一段音频数据的dts\n    this.nextVideoDts = 0; // 模拟下一段视频数据的dts\n\n    this.lastAudioSamplesLen = 0; // 上一段音频数据的长度\n    this.lastVideoSamplesLen = 0; // 上一段视频数据的长度\n\n    this.lastVideoDts = undefined; // 上一段音频数据的长度\n    this.lastAudioDts = undefined; // 上一段视频数据的长度\n\n    this.allAudioSamplesCount = 0; // 音频总数据量(原始帧)\n    this.allVideoSamplesCount = 0; // 视频总数据量(原始帧)\n\n    this._firstAudioSample = null;\n    this._firstVideoSample = null;\n\n    this.filledAudioSamples = []; // 补充音频帧（）\n    this.filledVideoSamples = []; // 补充视频帧（）\n  }\n\n  init() {\n    this.before(REMUX_EVENTS.REMUX_MEDIA, this.doFix.bind(this));\n  }\n\n  reset() {\n    this.nextAudioDts = 0; // 模拟下一段音频数据的dts\n    this.nextVideoDts = 0; // 模拟下一段视频数据的dts\n\n    this.lastAudioSamplesLen = 0; // 上一段音频数据的长度\n    this.lastVideoSamplesLen = 0; // 上一段视频数据的长度\n\n    this.lastVideoDts = undefined; // 上一段音频数据的长度\n    this.lastAudioDts = undefined; // 上一段视频数据的长度\n\n    this.allAudioSamplesCount = 0; // 音频总数据量(原始帧)\n    this.allVideoSamplesCount = 0; // 视频总数据量(原始帧)\n\n    this._firstAudioSample = null;\n    this._firstVideoSample = null;\n\n    this.filledAudioSamples = []; // 补充音频帧（）\n    this.filledVideoSamples = []; // 补充视频帧（）\n  }\n\n  doFix() {\n    const { isFirstAudioSamples, isFirstVideoSamples } = this.getFirstSample();\n\n    this.removeInvalidSamples();\n\n    this.recordSamplesCount();\n\n    if (this._firstVideoSample) {\n      this.fixRefSampleDuration(this.videoTrack.meta, this.videoTrack.samples);\n    }\n    if (this._firstAudioSample) {\n      this.fixRefSampleDuration(this.audioTrack.meta, this.audioTrack.samples);\n    }\n\n    this.doFixVideo(isFirstVideoSamples);\n    this.doFixAudio(isFirstAudioSamples);\n  }\n\n  doFixVideo(first) {\n    let { samples: videoSamples, meta } = this.videoTrack;\n\n    if (meta.frameRate && meta.frameRate.fixed === false) {\n      return;\n    }\n\n    if (!videoSamples || !videoSamples.length || !this._firstVideoSample) {\n      return;\n    }\n\n    // console.log(`video lastSample, ${videoSamples[videoSamples.length - 1].dts}`)\n\n    const firstSample = videoSamples[0];\n    const firstDts = firstSample.dts;\n\n    const samplesLen = videoSamples.length;\n\n    // step1. 修复与audio首帧差距太大的问题\n    if (first && this._firstAudioSample) {\n      const videoFirstDts = this._firstVideoSample.dts;\n      const audioFirstDts = this._firstAudioSample.dts;\n      const gap = videoFirstDts - audioFirstDts;\n      if (gap > 2 * meta.refSampleDuration) {\n        const fillCount = Math.floor(gap / meta.refSampleDuration);\n\n        for (let i = 0; i < fillCount; i++) {\n          const clonedFirstSample = Object.assign({}, firstSample); // 视频头部帧缺失需要复制第一帧\n          // 重新计算sample的dts和pts\n          clonedFirstSample.dts = videoFirstDts - (i + 1) * meta.refSampleDuration;\n          clonedFirstSample.pts = clonedFirstSample.dts + clonedFirstSample.cts;\n\n          videoSamples.unshift(clonedFirstSample);\n\n          this.filledVideoSamples.push({\n            dts: clonedFirstSample.dts,\n            size: clonedFirstSample.data.byteLength\n          });\n        }\n      }\n    }\n\n    let gap;\n    // step2. 修复samples段之间的间距问题、\n    if (this.nextVideoDts) {\n      // step1. 处理samples段之间的丢帧情况\n      // 当发现duration差距大于2帧时进行补帧\n      gap = firstDts - this.nextVideoDts;\n      const absGap = Math.abs(gap);\n      if (gap > 2 * meta.refSampleDuration) {\n        const fillFrameCount = Math.floor(gap / meta.refSampleDuration);\n\n        for (let i = 0; i < fillFrameCount; i++) {\n          const clonedSample = Object.assign({}, videoSamples[0]);\n          const computed = firstDts - (i + 1) * meta.refSampleDuration;\n\n          clonedSample.dts = computed > this.nextVideoDts ? computed : this.nextVideoDts; // 补的第一帧一定要是nextVideoDts\n          clonedSample.pts = clonedSample.dts + clonedSample.cts;\n\n          this.videoTrack.samples.unshift(clonedSample);\n\n          this.filledVideoSamples.push({\n            dts: clonedSample.dts,\n            size: clonedSample.data.byteLength\n          });\n        }\n      } else if (absGap <= 10 && absGap > 0) {\n        // 当差距在+-一帧之间时将第一帧的dts强行定位到期望位置\n        // console.log('重定位视频帧dts', videoSamples[0].dts, this.nextVideoDts)\n        videoSamples[0].dts = this.nextVideoDts;\n        videoSamples[0].originDts = videoSamples[0].dts;\n        videoSamples[0].cts = videoSamples[0].cts || videoSamples[0].pts - videoSamples[0].dts;\n        videoSamples[0].pts = videoSamples[0].dts + videoSamples[0].cts;\n      }\n    }\n    const lastDts = videoSamples[videoSamples.length - 1].dts;\n\n    const lastSampleDuration = videoSamples.length >= 2 ? lastDts - videoSamples[videoSamples.length - 2].dts : meta.refSampleDuration;\n\n    this.lastVideoSamplesLen = samplesLen;\n    this.nextVideoDts = lastDts + lastSampleDuration;\n    this.lastVideoDts = lastDts;\n\n    // step2. 修复sample段之内的间距问题\n    // step3. 修复samples段内部的dts异常问题\n    for (let i = 0, len = videoSamples.length; i < len; i++) {\n      const current = videoSamples[i];\n      const next = videoSamples[i + 1];\n\n      if (!next) {\n        break;\n      }\n\n      const duration = next.dts - current.dts;\n\n      if (duration > 2 * meta.refSampleDuration) {\n        // 两帧之间间隔太大，需要补空白帧\n        let fillFrameCount = Math.floor(duration / meta.refSampleDuration);\n\n        let fillFrameIdx = 0;\n        while (fillFrameIdx < fillFrameCount) {\n          const fillFrame = Object.assign({}, next);\n          fillFrame.dts = current.dts + (fillFrameIdx + 1) * meta.refSampleDuration;\n          fillFrame.pts = fillFrame.dts + fillFrame.cts;\n          if (fillFrame < next.dts) {\n            videoSamples.splice(i, 0, fillFrame);\n\n            this.filledVideoSamples.push({\n              dts: fillFrame.dts,\n              size: fillFrame.data.byteLength\n            });\n          }\n\n          fillFrameIdx++;\n          i++;\n        }\n      }\n    }\n\n    this.videoTrack.samples = videoSamples;\n  }\n\n  doFixAudio(first) {\n    let { samples: audioSamples, meta } = this.audioTrack;\n\n    if (!audioSamples || !audioSamples.length) {\n      return;\n    }\n    // console.log(`audio lastSample, ${audioSamples[audioSamples.length - 1].dts}`)\n\n    const samplesLen = audioSamples.length;\n    const silentFrame = _aacHelper2.default.getSilentFrame(meta.codec, meta.channelCount);\n\n    const firstSample = this._firstAudioSample;\n\n    // 对audioSamples按照dts做排序\n    audioSamples = Compatibility.sortAudioSamples(audioSamples);\n\n    // step0. 首帧与video首帧间距大的问题\n    if (this._firstVideoSample && first) {\n      const videoFirstPts = this._firstVideoSample.pts ? this._firstVideoSample.pts : this._firstVideoSample.dts + this._firstVideoSample.cts;\n\n      if (firstSample.dts - videoFirstPts > meta.refSampleDuration) {\n        const silentSampleCount = Math.floor((firstSample.dts - videoFirstPts) / meta.refSampleDuration);\n\n        for (let i = 0; i < silentSampleCount; i++) {\n          const silentSample = {\n            data: silentFrame,\n            datasize: silentFrame.byteLength,\n            dts: firstSample.dts - (i + 1) * meta.refSampleDuration,\n            filtered: 0\n          };\n\n          audioSamples.unshift(silentSample);\n\n          this.filledAudioSamples.push({\n            dts: silentSample.dts,\n            size: silentSample.data.byteLength\n          });\n        }\n      }\n    }\n\n    let gap;\n    const firstDts = audioSamples[0].dts;\n\n    if (this.nextAudioDts) {\n      // step1. 处理samples段之间的丢帧情况\n      // 当发现duration差距大于1帧时进行补帧\n      gap = firstDts - this.nextAudioDts;\n      const absGap = Math.abs(gap);\n\n      if (absGap > meta.refSampleDuration && samplesLen === 1 && this.lastAudioSamplesLen === 1) {\n        meta.refSampleDurationFixed = undefined;\n      }\n\n      if (gap > 2 * meta.refSampleDuration) {\n        if (samplesLen === 1 && this.lastAudioSamplesLen === 1) {\n          // 如果sample的length一直是1，而且一直不符合refSampleDuration，需要动态修改refSampleDuration\n          meta.refSampleDurationFixed = meta.refSampleDurationFixed !== undefined ? meta.refSampleDurationFixed + gap : meta.refSampleDuration + gap;\n        } else {\n          const silentFrameCount = Math.floor(gap / meta.refSampleDuration);\n\n          for (let i = 0; i < silentFrameCount; i++) {\n            const computed = firstDts - (i + 1) * meta.refSampleDuration;\n            const silentSample = Object.assign({}, audioSamples[0], {\n              dts: computed > this.nextAudioDts ? computed : this.nextAudioDts\n            });\n\n            this.filledAudioSamples.push({\n              dts: silentSample.dts,\n              size: silentSample.data.byteLength\n            });\n            this.audioTrack.samples.unshift(silentSample);\n          }\n        }\n      } else if (absGap <= 10 && absGap > 0) {\n        // 当差距比较小的时候将音频帧重定位\n        // console.log('重定位音频帧dts', audioSamples[0].dts, this.nextAudioDts)\n        audioSamples[0].dts = this.nextAudioDts;\n        audioSamples[0].pts = this.nextAudioDts;\n      }\n    }\n    const lastDts = audioSamples[audioSamples.length - 1].dts;\n    const lastSampleDuration = audioSamples.length >= 2 ? lastDts - audioSamples[audioSamples.length - 2].dts : meta.refSampleDuration;\n\n    this.lastAudioSamplesLen = samplesLen;\n    this.nextAudioDts = meta.refSampleDurationFixed ? lastDts + meta.refSampleDurationFixed : lastDts + lastSampleDuration;\n    this.lastAudioDts = lastDts;\n\n    // step3. 修复samples段内部的dts异常问题\n    for (let i = 0, len = audioSamples.length; i < len; i++) {\n      const current = audioSamples[i];\n      const next = audioSamples[i + 1];\n\n      if (!next) {\n        break;\n      }\n\n      const duration = next.dts - current.dts;\n      audioSamples[i].duration = duration;\n      /*\n      if (duration > (2 * meta.refSampleDuration)) {\n        // 两帧之间间隔太大，需要补空白帧\n        /**\n        let silentFrameCount = Math.floor(duration / meta.refSampleDuration)\n        let frameIdx = 0\n         while (frameIdx < silentFrameCount) {\n          const silentSample = {\n            data: silentFrame,\n            datasize: silentFrame.byteLength,\n            dts: current.dts + (frameIdx + 1) * meta.refSampleDuration,\n            filtered: 0,\n            isSilent: true\n          }\n           audioSamples.splice(i, 0, silentSample)\n           this.filledAudioSamples.push({\n            dts: silentSample.dts,\n            size: silentSample.data.byteLength\n          })\n           frameIdx++\n          i++ // 不对静音帧做比较\n        }\n      } */\n    }\n\n    this.audioTrack.samples = Compatibility.sortAudioSamples(audioSamples);\n  }\n\n  getFirstSample() {\n    // 获取video和audio的首帧数据\n    let { samples: videoSamples } = this.videoTrack;\n    let { samples: audioSamples } = this.audioTrack;\n\n    let isFirstVideoSamples = false;\n    let isFirstAudioSamples = false;\n\n    if (!this._firstVideoSample && videoSamples.length) {\n      this._firstVideoSample = Compatibility.findFirstVideoSample(videoSamples);\n      isFirstVideoSamples = true;\n    }\n\n    if (!this._firstAudioSample && audioSamples.length) {\n      this._firstAudioSample = Compatibility.findFirstAudioSample(audioSamples); // 寻找dts最小的帧作为首个音频帧\n      isFirstAudioSamples = true;\n    }\n\n    return {\n      isFirstVideoSamples,\n      isFirstAudioSamples\n    };\n  }\n\n  /**\n   * 在没有refSampleDuration的问题流中，\n   */\n  fixRefSampleDuration(meta, samples) {\n    const isVideo = meta.type === 'video';\n    const allSamplesCount = isVideo ? this.allVideoSamplesCount : this.allAudioSamplesCount;\n    const firstDts = isVideo ? this._firstVideoSample.dts : this._firstAudioSample.dts;\n    const filledSamplesCount = isVideo ? this.filledVideoSamples.length : this.filledAudioSamples.length;\n\n    if (!meta.refSampleDuration || meta.refSampleDuration <= 0 || Number.isNaN(meta.refSampleDuration)) {\n      if (samples.length >= 1) {\n        const lastDts = samples[samples.length - 1].dts;\n\n        meta.refSampleDuration = Math.floor((lastDts - firstDts) / (allSamplesCount + filledSamplesCount - 1)); // 将refSampleDuration重置为计算后的平均值\n      }\n    } else if (meta.refSampleDuration) {\n      if (samples.length >= 3) {\n        const lastDts = samples[samples.length - 1].dts;\n        const firstDts = samples[0].dts;\n        const durationAvg = (lastDts - firstDts) / samples.length;\n\n        meta.refSampleDuration = Math.abs(meta.refSampleDuration - durationAvg) <= meta.refSampleDuration ? meta.refSampleDuration : durationAvg; // 将refSampleDuration重置为计算后的平均值\n      }\n    }\n  }\n\n  /**\n   * 记录截止目前一共播放了多少帧\n   */\n  recordSamplesCount() {\n    const { audioTrack, videoTrack } = this;\n\n    this.allAudioSamplesCount += audioTrack.samples.length;\n    this.allVideoSamplesCount += videoTrack.samples.length;\n  }\n\n  /**\n   * 去除不合法的帧（倒退、重复帧）\n   */\n  removeInvalidSamples() {\n    const { _firstVideoSample, _firstAudioSample } = this;\n\n    this.audioTrack.samples = this.audioTrack.samples.filter(sample => {\n      return sample.dts >= _firstAudioSample.dts && (this.lastAudioDts === undefined || sample.dts > this.lastAudioDts);\n    });\n\n    this.videoTrack.samples = this.videoTrack.samples.filter(sample => {\n      return sample.dts >= _firstVideoSample.dts && (this.lastVideoDts === undefined || sample.dts > this.lastVideoDts);\n    });\n  }\n\n  static sortAudioSamples(samples) {\n    if (samples.length === 1) {\n      return samples;\n    }\n\n    return samples.sort((a, b) => {\n      return a.dts - b.dts;\n    });\n  }\n\n  /**\n   * 寻找dts最小的sample\n   * @param samples\n   */\n  static findFirstAudioSample(samples) {\n    if (!samples || samples.length === 0) {\n      return null;\n    }\n\n    return Compatibility.sortAudioSamples(samples)[0];\n  }\n\n  static findFirstVideoSample(samples) {\n    if (!samples.length) {\n      return null;\n    }\n\n    const sorted = samples.sort((a, b) => {\n      return a.dts - b.dts;\n    });\n\n    for (let i = 0, len = sorted.length; i < len; i++) {\n      if (sorted[i].isKeyframe) {\n        return sorted[i];\n      }\n    }\n  }\n\n  get tracks() {\n    return this._context.getInstance('TRACKS');\n  }\n\n  get audioTrack() {\n    if (this.tracks) {\n      return this.tracks.audioTrack;\n    }\n    return null;\n  }\n\n  get videoTrack() {\n    if (this.tracks) {\n      return this.tracks.videoTrack;\n    }\n    return null;\n  }\n}\nexports.default = Compatibility;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-codec/src/compatibility.js?")},"../xgplayer-codec/src/h264/nalunit/golomb.js":
/*!****************************************************!*\
  !*** ../xgplayer-codec/src/h264/nalunit/golomb.js ***!
  \****************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass Golomb {\n  constructor(uint8array) {\n    this.TAG = 'Golomb';\n    this._buffer = uint8array;\n    this._bufferIndex = 0;\n    this._totalBytes = uint8array.byteLength;\n    this._totalBits = uint8array.byteLength * 8;\n    this._currentWord = 0;\n    this._currentWordBitsLeft = 0;\n  }\n\n  destroy() {\n    this._buffer = null;\n  }\n\n  _fillCurrentWord() {\n    let bufferBytesLeft = this._totalBytes - this._bufferIndex;\n    if (bufferBytesLeft <= 0) {\n      // TODO 异常处理\n    }\n\n    let bytesRead = Math.min(4, bufferBytesLeft);\n    let word = new Uint8Array(4);\n    word.set(this._buffer.subarray(this._bufferIndex, this._bufferIndex + bytesRead));\n    this._currentWord = new DataView(word.buffer).getUint32(0, false);\n\n    this._bufferIndex += bytesRead;\n    this._currentWordBitsLeft = bytesRead * 8;\n  }\n\n  readBits(bits) {\n    if (bits > 32) {\n      // TODO\n    }\n\n    if (bits <= this._currentWordBitsLeft) {\n      let result = this._currentWord >>> 32 - bits;\n      this._currentWord <<= bits;\n      this._currentWordBitsLeft -= bits;\n      return result;\n    }\n\n    let result = this._currentWordBitsLeft ? this._currentWord : 0;\n    // eslint-disable-next-line\n    result >>> 32 - this._currentWordBitsLeft;\n    let bitsNeedLeft = bits - this._currentWordBitsLeft;\n\n    this._fillCurrentWord();\n    let bitsReadNext = Math.min(bitsNeedLeft, this._currentWordBitsLeft);\n\n    let result2 = this._currentWord >>> 32 - bitsReadNext;\n    this._currentWord <<= bitsReadNext;\n    this._currentWordBitsLeft -= bitsReadNext;\n\n    result = result << bitsReadNext | result2;\n    return result;\n  }\n\n  readBool() {\n    return this.readBits(1) === 1;\n  }\n\n  readByte() {\n    return this.readBits(8);\n  }\n\n  _skipLeadingZero() {\n    let zeroCount;\n    for (zeroCount = 0; zeroCount < this._currentWordBitsLeft; zeroCount++) {\n      if ((this._currentWord & 0x80000000 >>> zeroCount) !== 0) {\n        this._currentWord <<= zeroCount;\n        this._currentWordBitsLeft -= zeroCount;\n        return zeroCount;\n      }\n    }\n    this._fillCurrentWord();\n    return zeroCount + this._skipLeadingZero();\n  }\n\n  readUEG() {\n    // unsigned exponential golomb\n    let leadingZeros = this._skipLeadingZero();\n    return this.readBits(leadingZeros + 1) - 1;\n  }\n\n  readSEG() {\n    // signed exponential golomb\n    let value = this.readUEG();\n    if (value & 0x01) {\n      return value + 1 >>> 1;\n    } else {\n      return -1 * (value >>> 1);\n    }\n  }\n}\n\nexports.default = Golomb;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-codec/src/h264/nalunit/golomb.js?")},"../xgplayer-codec/src/h264/nalunit/index.js":
/*!***************************************************!*\
  !*** ../xgplayer-codec/src/h264/nalunit/index.js ***!
  \***************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\n\nvar _sps = __webpack_require__(/*! ./sps */ "../xgplayer-codec/src/h264/nalunit/sps.js");\n\nvar _sps2 = _interopRequireDefault(_sps);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nclass Nalunit {\n  static getNalunits(buffer) {\n    if (buffer.length - buffer.position < 4) {\n      return [];\n    }\n\n    let buf = buffer.dataview;\n    let position = buffer.position;\n    if (buf.getInt32(position) === 1 || buf.getInt16(position) === 0 && buf.getInt8(position + 2) === 1) {\n      return Nalunit.getAnnexbNals(buffer);\n    } else {\n      return Nalunit.getAvccNals(buffer);\n    }\n  }\n\n  static getAnnexbNals(buffer) {\n    let nals = [];\n    let position = Nalunit.getHeaderPositionAnnexB(buffer);\n    let start = position.pos;\n    let end = start;\n    while (start < buffer.length - 4) {\n      let header = buffer.buffer.slice(start, start + position.headerLength);\n      if (position.pos === buffer.position) {\n        buffer.skip(position.headerLength);\n      }\n      position = Nalunit.getHeaderPositionAnnexB(buffer);\n      end = position.pos;\n      let body = new Uint8Array(buffer.buffer.slice(start + header.byteLength, end));\n      let unit = { header, body };\n      Nalunit.analyseNal(unit);\n      nals.push(unit);\n      buffer.skip(end - buffer.position);\n      start = end;\n    }\n    return nals;\n  }\n\n  static getAvccNals(buffer) {\n    let nals = [];\n    while (buffer.position < buffer.length - 4) {\n      let length = buffer.dataview.getInt32(buffer.position);\n      if (buffer.length - buffer.position >= length) {\n        let header = buffer.buffer.slice(buffer.position, buffer.position + 4);\n        buffer.skip(4);\n        let body = buffer.buffer.slice(buffer.position, buffer.position + length);\n        buffer.skip(length);\n        let unit = { header, body };\n        Nalunit.analyseNal(unit);\n        nals.push(unit);\n      } else {\n        break;\n      }\n    }\n    return nals;\n  }\n\n  static analyseNal(unit) {\n    let type = unit.body[0] & 0x1f;\n    switch (type) {\n      case 1:\n        // NDR\n        unit.ndr = true;\n        break;\n      case 5:\n        // IDR\n        unit.idr = true;\n        break;\n      case 6:\n        // SEI\n        break;\n      case 7:\n        // SPS\n        unit.sps = _sps2.default.parseSPS(unit.body);\n        break;\n      case 8:\n        // PPS\n        unit.pps = true;\n        break;\n      case 9:\n        // AUD\n        break;\n      default:\n        break;\n    }\n  }\n\n  static getHeaderPositionAnnexB(buffer) {\n    // seperate\n    let pos = buffer.position;\n    let headerLength = 0;\n    while (headerLength !== 3 && headerLength !== 4 && pos < buffer.length - 4) {\n      if (buffer.dataview.getInt16(pos) === 0) {\n        if (buffer.dataview.getInt16(pos + 2) === 1) {\n          // 0x000001\n          headerLength = 4;\n        } else if (buffer.dataview.getInt8(pos + 2) === 1) {\n          headerLength = 3;\n        } else {\n          pos++;\n        }\n      } else {\n        pos++;\n      }\n    }\n\n    if (pos === buffer.length - 4) {\n      if (buffer.dataview.getInt16(pos) === 0) {\n        if (buffer.dataview.getInt16(pos + 2) === 1) {\n          // 0x000001\n          headerLength = 4;\n        }\n      } else {\n        pos++;\n        if (buffer.dataview.getInt16(pos) === 0 && buffer.dataview.getInt8(pos) === 1) {\n          // 0x0000001\n          headerLength = 3;\n        } else {\n          pos = buffer.length;\n        }\n      }\n    }\n    return { pos, headerLength };\n  }\n\n  static getAvcc(sps, pps) {\n    let ret = new Uint8Array(sps.byteLength + pps.byteLength + 11);\n    ret[0] = 0x01;\n    ret[1] = sps[1];\n    ret[2] = sps[2];\n    ret[3] = sps[3];\n    ret[4] = 255;\n    ret[5] = 225;\n\n    let offset = 6;\n\n    ret.set(new Uint8Array([sps.byteLength >>> 8 & 0xff, sps.byteLength & 0xff]), offset);\n    offset += 2;\n    ret.set(sps, offset);\n    offset += sps.byteLength;\n\n    ret[offset] = 1;\n    offset++;\n\n    ret.set(new Uint8Array([pps.byteLength >>> 8 & 0xff, pps.byteLength & 0xff]), offset);\n    offset += 2;\n    ret.set(pps, offset);\n    return ret;\n  }\n}\n\nexports.default = Nalunit;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-codec/src/h264/nalunit/index.js?')},"../xgplayer-codec/src/h264/nalunit/sps.js":
/*!*************************************************!*\
  !*** ../xgplayer-codec/src/h264/nalunit/sps.js ***!
  \*************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _golomb = __webpack_require__(/*! ./golomb */ \"../xgplayer-codec/src/h264/nalunit/golomb.js\");\n\nvar _golomb2 = _interopRequireDefault(_golomb);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nclass SPSParser {\n  static _ebsp2rbsp(uint8array) {\n    let src = uint8array;\n    let srcLength = src.byteLength;\n    let dst = new Uint8Array(srcLength);\n    let dstIdx = 0;\n\n    for (let i = 0; i < srcLength; i++) {\n      if (i >= 2) {\n        if (src[i] === 0x03 && src[i - 1] === 0x00 && src[i - 2] === 0x00) {\n          continue;\n        }\n      }\n      dst[dstIdx] = src[i];\n      dstIdx++;\n    }\n\n    return new Uint8Array(dst.buffer, 0, dstIdx);\n  }\n\n  static parseSPS(uint8array) {\n    let rbsp = SPSParser._ebsp2rbsp(uint8array);\n    let gb = new _golomb2.default(rbsp);\n\n    gb.readByte();\n    let profileIdc = gb.readByte();\n    gb.readByte();\n    let levelIdc = gb.readByte();\n    gb.readUEG();\n\n    let profile_string = SPSParser.getProfileString(profileIdc);\n    let level_string = SPSParser.getLevelString(levelIdc);\n    let chroma_format_idc = 1;\n    let chroma_format = 420;\n    let chroma_format_table = [0, 420, 422, 444];\n    let bit_depth = 8;\n\n    if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128 || profileIdc === 138 || profileIdc === 144) {\n      chroma_format_idc = gb.readUEG();\n      if (chroma_format_idc === 3) {\n        gb.readBits(1);\n      }\n      if (chroma_format_idc <= 3) {\n        chroma_format = chroma_format_table[chroma_format_idc];\n      }\n\n      bit_depth = gb.readUEG() + 8;\n      gb.readUEG();\n      gb.readBits(1);\n      if (gb.readBool()) {\n        let scaling_list_count = chroma_format_idc !== 3 ? 8 : 12;\n        for (let i = 0; i < scaling_list_count; i++) {\n          if (gb.readBool()) {\n            if (i < 6) {\n              SPSParser._skipScalingList(gb, 16);\n            } else {\n              SPSParser._skipScalingList(gb, 64);\n            }\n          }\n        }\n      }\n    }\n    gb.readUEG();\n    let pic_order_cnt_type = gb.readUEG();\n    if (pic_order_cnt_type === 0) {\n      gb.readUEG();\n    } else if (pic_order_cnt_type === 1) {\n      gb.readBits(1);\n      gb.readSEG();\n      gb.readSEG();\n      let num_ref_frames_in_pic_order_cnt_cycle = gb.readUEG();\n      for (let i = 0; i < num_ref_frames_in_pic_order_cnt_cycle; i++) {\n        gb.readSEG();\n      }\n    }\n    gb.readUEG();\n    gb.readBits(1);\n\n    let pic_width_in_mbs_minus1 = gb.readUEG();\n    let pic_height_in_map_units_minus1 = gb.readUEG();\n\n    let frame_mbs_only_flag = gb.readBits(1);\n    if (frame_mbs_only_flag === 0) {\n      gb.readBits(1);\n    }\n    gb.readBits(1);\n\n    let frame_crop_left_offset = 0;\n    let frame_crop_right_offset = 0;\n    let frame_crop_top_offset = 0;\n    let frame_crop_bottom_offset = 0;\n\n    let frame_cropping_flag = gb.readBool();\n    if (frame_cropping_flag) {\n      frame_crop_left_offset = gb.readUEG();\n      frame_crop_right_offset = gb.readUEG();\n      frame_crop_top_offset = gb.readUEG();\n      frame_crop_bottom_offset = gb.readUEG();\n    }\n\n    let par_width = 1,\n        par_height = 1;\n    let fps = 0,\n        fps_fixed = true,\n        fps_num = 0,\n        fps_den = 0;\n\n    let vui_parameters_present_flag = gb.readBool();\n    if (vui_parameters_present_flag) {\n      if (gb.readBool()) {\n        // aspect_ratio_info_present_flag\n        let aspect_ratio_idc = gb.readByte();\n        let par_w_table = [1, 12, 10, 16, 40, 24, 20, 32, 80, 18, 15, 64, 160, 4, 3, 2];\n        let par_h_table = [1, 11, 11, 11, 33, 11, 11, 11, 33, 11, 11, 33, 99, 3, 2, 1];\n\n        if (aspect_ratio_idc > 0 && aspect_ratio_idc < 16) {\n          par_width = par_w_table[aspect_ratio_idc - 1];\n          par_height = par_h_table[aspect_ratio_idc - 1];\n        } else if (aspect_ratio_idc === 255) {\n          par_width = gb.readByte() << 8 | gb.readByte();\n          par_height = gb.readByte() << 8 | gb.readByte();\n        }\n      }\n\n      if (gb.readBool()) {\n        gb.readBool();\n      }\n      if (gb.readBool()) {\n        gb.readBits(4);\n        if (gb.readBool()) {\n          gb.readBits(24);\n        }\n      }\n      if (gb.readBool()) {\n        gb.readUEG();\n        gb.readUEG();\n      }\n      if (gb.readBool()) {\n        let num_units_in_tick = gb.readBits(32);\n        let time_scale = gb.readBits(32);\n        fps_fixed = gb.readBool();\n\n        fps_num = time_scale;\n        fps_den = num_units_in_tick * 2;\n        fps = fps_num / fps_den;\n      }\n    }\n\n    let parScale = 1;\n    if (par_width !== 1 || par_height !== 1) {\n      parScale = par_width / par_height;\n    }\n\n    let crop_unit_x = 0,\n        crop_unit_y = 0;\n    if (chroma_format_idc === 0) {\n      crop_unit_x = 1;\n      crop_unit_y = 2 - frame_mbs_only_flag;\n    } else {\n      let sub_wc = chroma_format_idc === 3 ? 1 : 2;\n      let sub_hc = chroma_format_idc === 1 ? 2 : 1;\n      crop_unit_x = sub_wc;\n      crop_unit_y = sub_hc * (2 - frame_mbs_only_flag);\n    }\n\n    let codec_width = (pic_width_in_mbs_minus1 + 1) * 16;\n    let codec_height = (2 - frame_mbs_only_flag) * ((pic_height_in_map_units_minus1 + 1) * 16);\n\n    codec_width -= (frame_crop_left_offset + frame_crop_right_offset) * crop_unit_x;\n    codec_height -= (frame_crop_top_offset + frame_crop_bottom_offset) * crop_unit_y;\n\n    let present_width = Math.ceil(codec_width * parScale);\n\n    gb.destroy();\n    gb = null;\n\n    return {\n      profile_string: profile_string,\n      level_string: level_string,\n      bit_depth: bit_depth,\n      chroma_format: chroma_format,\n      chroma_format_string: SPSParser.getChromaFormatString(chroma_format),\n\n      frame_rate: {\n        fixed: fps_fixed,\n        fps: fps,\n        fps_den: fps_den,\n        fps_num: fps_num\n      },\n\n      par_ratio: {\n        width: par_width,\n        height: par_height\n      },\n\n      codec_size: {\n        width: codec_width,\n        height: codec_height\n      },\n\n      present_size: {\n        width: present_width,\n        height: codec_height\n      }\n    };\n  }\n\n  static _skipScalingList(gb, count) {\n    let last_scale = 8,\n        next_scale = 8;\n    let delta_scale = 0;\n    for (let i = 0; i < count; i++) {\n      if (next_scale !== 0) {\n        delta_scale = gb.readSEG();\n        next_scale = (last_scale + delta_scale + 256) % 256;\n      }\n      last_scale = next_scale === 0 ? last_scale : next_scale;\n    }\n  }\n\n  static getProfileString(profileIdc) {\n    switch (profileIdc) {\n      case 66:\n        return 'Baseline';\n      case 77:\n        return 'Main';\n      case 88:\n        return 'Extended';\n      case 100:\n        return 'High';\n      case 110:\n        return 'High10';\n      case 122:\n        return 'High422';\n      case 244:\n        return 'High444';\n      default:\n        return 'Unknown';\n    }\n  }\n\n  static getLevelString(levelIdc) {\n    return (levelIdc / 10).toFixed(1);\n  }\n\n  static getChromaFormatString(chroma) {\n    switch (chroma) {\n      case 420:\n        return '4:2:0';\n      case 422:\n        return '4:2:2';\n      case 444:\n        return '4:4:4';\n      default:\n        return 'Unknown';\n    }\n  }\n\n  static toVideoMeta(spsConfig) {\n    let meta = {};\n    if (spsConfig && spsConfig.codec_size) {\n      meta.codecWidth = spsConfig.codec_size.width;\n      meta.codecHeight = spsConfig.codec_size.height;\n      meta.presentWidth = spsConfig.present_size.width;\n      meta.presentHeight = spsConfig.present_size.height;\n    }\n\n    meta.profile = spsConfig.profile_string;\n    meta.level = spsConfig.level_string;\n    meta.bitDepth = spsConfig.bit_depth;\n    meta.chromaFormat = spsConfig.chroma_format;\n\n    meta.parRatio = {\n      width: spsConfig.par_ratio.width,\n      height: spsConfig.par_ratio.height\n    };\n\n    meta.frameRate = spsConfig.frame_rate;\n\n    let fpsDen = meta.frameRate.fps_den;\n    let fpsNum = meta.frameRate.fps_num;\n    meta.refSampleDuration = Math.floor(meta.timescale * (fpsDen / fpsNum));\n  }\n} /* eslint-disable camelcase  */\n/* eslint-disable one-var  */\nexports.default = SPSParser;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-codec/src/h264/nalunit/sps.js?")},"../xgplayer-demux/index.js":
/*!**********************************!*\
  !*** ../xgplayer-demux/index.js ***!
  \**********************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nmodule.exports = {\n  // HLS\n  M3U8Parser: __webpack_require__(/*! ./src/hls/demuxer/m3u8parser */ "../xgplayer-demux/src/hls/demuxer/m3u8parser.js").default,\n  TsDemuxer: __webpack_require__(/*! ./src/hls/demuxer/ts */ "../xgplayer-demux/src/hls/demuxer/ts.js").default,\n  Playlist: __webpack_require__(/*! ./src/hls/playlist */ "../xgplayer-demux/src/hls/playlist.js").default,\n  FlvDemuxer: __webpack_require__(/*! ./src/flv/index */ "../xgplayer-demux/src/flv/index.js").default\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-demux/index.js?')},"../xgplayer-demux/src/flv/amf-parser.js":
/*!***********************************************!*\
  !*** ../xgplayer-demux/src/flv/amf-parser.js ***!
  \***********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _xgplayerUtils = __webpack_require__(/*! xgplayer-utils */ \"../xgplayer-utils/index.js\");\n\nconst DATA_TYPES = {\n  NUMBER: 0,\n  BOOLEAN: 1,\n  STRING: 2,\n  OBJECT: 3,\n  MIX_ARRAY: 8,\n  OBJECT_END: 9,\n  STRICT_ARRAY: 10,\n  DATE: 11,\n  LONE_STRING: 12\n\n  /**\n   * meta信息解析\n   */\n};class AMFParser {\n  constructor() {\n    this.offset = 0;\n    this.readOffset = this.offset;\n  }\n\n  resolve(meta, size) {\n    if (size < 3) {\n      throw new Error('not enough data for metainfo');\n    }\n    const metaData = {};\n    const name = this.parseValue(meta);\n    const value = this.parseValue(meta, size - name.bodySize);\n    metaData[name.data] = value.data;\n\n    this.resetStatus();\n    return metaData;\n  }\n\n  resetStatus() {\n    this.offset = 0;\n    this.readOffset = this.offset;\n  }\n\n  parseString(buffer) {\n    const dv = new DataView(buffer, this.readOffset);\n    const strLen = dv.getUint16(0, !_xgplayerUtils.isLe);\n    let str = '';\n    if (strLen > 0) {\n      str = _xgplayerUtils.UTF8.decode(new Uint8Array(buffer, this.readOffset + 2, strLen));\n    } else {\n      str = '';\n    }\n    let size = strLen + 2;\n    this.readOffset += size;\n    return {\n      data: str,\n      bodySize: strLen + 2\n    };\n  }\n\n  parseDate(buffer, size) {\n    const dv = new DataView(buffer, this.readOffset, size);\n    let ts = dv.getFloat64(0, !_xgplayerUtils.isLe);\n    const timeOffset = dv.getInt16(8, !_xgplayerUtils.isLe);\n    ts += timeOffset * 60 * 1000;\n\n    this.readOffset += 10;\n    return {\n      data: new Date(ts),\n      bodySize: 10\n    };\n  }\n\n  parseObject(buffer, size) {\n    const name = this.parseString(buffer, size);\n    const value = this.parseValue(buffer, size - name.bodySize);\n    return {\n      data: {\n        name: name.data,\n        value: value.data\n      },\n      bodySize: name.bodySize + value.bodySize,\n      isObjEnd: value.isObjEnd\n    };\n  }\n\n  parseLongString(buffer) {\n    const dv = new DataView(buffer, this.readOffset);\n    const strLen = dv.getUint32(0, !_xgplayerUtils.isLe);\n    let str = '';\n    if (strLen > 0) {\n      str = _xgplayerUtils.UTF8.decode(new Uint8Array(buffer, this.readOffset + 2, strLen));\n    } else {\n      str = '';\n    }\n    // const size = strLen + 4;\n    this.readOffset += strLen + 4;\n    return {\n      data: str,\n      bodySize: strLen + 4\n    };\n  }\n\n  /**\n   * 解析meta中的变量\n   */\n  parseValue(data, size) {\n    let buffer = new ArrayBuffer();\n    if (data instanceof ArrayBuffer) {\n      buffer = data;\n    } else {\n      buffer = data.buffer;\n    }\n    const {\n      NUMBER,\n      BOOLEAN,\n      STRING,\n      OBJECT,\n      MIX_ARRAY,\n      OBJECT_END,\n      STRICT_ARRAY,\n      DATE,\n      LONE_STRING\n    } = DATA_TYPES;\n    const dataView = new DataView(buffer, this.readOffset, size);\n    let isObjEnd = false;\n    const type = dataView.getUint8(0);\n    let offset = 1;\n    this.readOffset += 1;\n    let value = null;\n\n    switch (type) {\n      case NUMBER:\n        {\n          value = dataView.getFloat64(1, !_xgplayerUtils.isLe);\n          this.readOffset += 8;\n          offset += 8;\n          break;\n        }\n      case BOOLEAN:\n        {\n          const boolNum = dataView.getUint8(1);\n          value = !!boolNum;\n          this.readOffset += 1;\n          offset += 1;\n          break;\n        }\n      case STRING:\n        {\n          const str = this.parseString(buffer);\n          value = str.data;\n          offset += str.bodySize;\n          break;\n        }\n      case OBJECT:\n        {\n          value = {};\n          let objEndSize = 0;\n          if (dataView.getUint32(size - 4, !_xgplayerUtils.isLe) & 0x00FFFFFF) {\n            objEndSize = 3;\n          }\n          // this.readOffset += offset - 1;\n          while (offset < size - 4) {\n            const amfObj = this.parseObject(buffer, size - offset - objEndSize);\n            if (amfObj.isObjectEnd) {\n              break;\n            }\n            value[amfObj.data.name] = amfObj.data.value;\n            offset += amfObj.bodySize;\n          }\n          if (offset <= size - 3) {\n            const mark = dataView.getUint32(offset - 1, !_xgplayerUtils.isLe) & 0x00FFFFFF;\n            if (mark === 9) {\n              this.readOffset += 3;\n              offset += 3;\n            }\n          }\n          break;\n        }\n      case MIX_ARRAY:\n        {\n          value = {};\n          offset += 4;\n          this.readOffset += 4;\n          let objEndSize = 0;\n          if ((dataView.getUint32(size - 4, !_xgplayerUtils.isLe) & 0x00FFFFFF) === 9) {\n            objEndSize = 3;\n          }\n\n          while (offset < size - 8) {\n            const amfVar = this.parseObject(buffer, size - offset - objEndSize);\n            if (amfVar.isObjectEnd) {\n              break;\n            }\n            value[amfVar.data.name] = amfVar.data.value;\n            offset += amfVar.bodySize;\n          }\n          if (offset <= size - 3) {\n            const marker = dataView.getUint32(offset - 1, !_xgplayerUtils.isLe) & 0x00FFFFFF;\n            if (marker === 9) {\n              offset += 3;\n              this.readOffset += 3;\n            }\n          }\n          break;\n        }\n\n      case OBJECT_END:\n        {\n          value = null;\n          isObjEnd = true;\n          break;\n        }\n\n      case STRICT_ARRAY:\n        {\n          value = [];\n          const arrLength = dataView.getUint32(1, !_xgplayerUtils.isLe);\n          offset += 4;\n          this.readOffset += 4;\n          for (let i = 0; i < arrLength; i++) {\n            const script = this.parseValue(buffer, size - offset);\n            value.push(script.data);\n            offset += script.bodySize;\n          }\n          break;\n        }\n\n      case DATE:\n        {\n          const date = this.parseDate(buffer, size - 1);\n          value = date.data;\n          offset += date.bodySize;\n          break;\n        }\n\n      case LONE_STRING:\n        {\n          const longStr = this.parseLongString(buffer, size - 1);\n          value = longStr.data;\n          offset += longStr.bodySize;\n          break;\n        }\n\n      default:\n        {\n          offset = size;\n        }\n    }\n\n    return {\n      data: value,\n      bodySize: offset,\n      isObjEnd: isObjEnd\n    };\n  }\n}\nexports.default = AMFParser;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-demux/src/flv/amf-parser.js?")},"../xgplayer-demux/src/flv/index.js":
/*!******************************************!*\
  !*** ../xgplayer-demux/src/flv/index.js ***!
  \******************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _xgplayerUtils = __webpack_require__(/*! xgplayer-utils */ \"../xgplayer-utils/index.js\");\n\nvar _xgplayerCodec = __webpack_require__(/*! xgplayer-codec */ \"../xgplayer-codec/index.js\");\n\nvar _xgplayerBuffer = __webpack_require__(/*! xgplayer-buffer */ \"../xgplayer-buffer/index.js\");\n\nvar _amfParser = __webpack_require__(/*! ./amf-parser */ \"../xgplayer-demux/src/flv/amf-parser.js\");\n\nvar _amfParser2 = _interopRequireDefault(_amfParser);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst DEMUX_EVENTS = _xgplayerUtils.EVENTS.DEMUX_EVENTS;\n\nclass FlvDemuxer {\n  constructor() {\n    this._firstFragmentLoaded = false;\n    this._trackNum = 0;\n    this._hasScript = false;\n  }\n\n  init() {\n    this.on(DEMUX_EVENTS.DEMUX_START, this.doParseFlv.bind(this));\n  }\n\n  /**\n   * if the flv head is valid\n   * @param data\n   * @returns {boolean}\n   */\n  static isFlvFile(data) {\n    return !(data[0] !== 0x46 || data[1] !== 0x4C || data[2] !== 0x56 || data[3] !== 0x01);\n  }\n\n  /**\n   * If the stream has audio or video.\n   * @param {number} streamFlag - Data from the stream which is define whether the audio / video track is exist.\n   */\n  static getPlayType(streamFlag) {\n    const result = {\n      hasVideo: false,\n      hasAudio: false\n    };\n\n    if (streamFlag & 0x01 > 0) {\n      result.hasVideo = true;\n    }\n\n    if (streamFlag & 0x04 > 0) {\n      result.hasAudio = true;\n    }\n\n    return result;\n  }\n\n  doParseFlv() {\n    if (!this._firstFragmentLoaded) {\n      if (this.loaderBuffer.length < 13) {\n        return;\n      }\n      const header = this.loaderBuffer.shift(13);\n      this.parseFlvHeader(header);\n      this.doParseFlv(); // 递归调用，继续解析flv流\n    } else {\n      if (this.loaderBuffer.length < 11) {\n        return;\n      }\n      let chunk;\n      do {\n        chunk = this._parseFlvTag();\n      } while (chunk);\n\n      this.emit(DEMUX_EVENTS.DEMUX_COMPLETE);\n    }\n  }\n\n  parseFlvHeader(header) {\n    if (!FlvDemuxer.isFlvFile(header)) {\n      this.emit(DEMUX_EVENTS.DEMUX_ERROR, new Error('invalid flv file'));\n      this.doParseFlv();\n    } else {\n      this._firstFragmentLoaded = true;\n      const playType = FlvDemuxer.getPlayType(header[4]);\n\n      if (playType.hasVideo) {\n        this.initVideoTrack();\n      }\n\n      if (playType.hasAudio) {\n        this.initAudioTrack();\n      }\n    }\n    this.doParseFlv();\n  }\n\n  /**\n   * init default video track configs\n   */\n  initVideoTrack() {\n    this._trackNum++;\n    let videoTrack = new _xgplayerBuffer.VideoTrack();\n    videoTrack.meta = new _xgplayerUtils.VideoTrackMeta();\n    videoTrack.id = videoTrack.meta.id = this._trackNum;\n\n    this.tracks.videoTrack = videoTrack;\n  }\n\n  /**\n   * init default audio track configs\n   */\n  initAudioTrack() {\n    this._trackNum++;\n    let audioTrack = new _xgplayerBuffer.AudioTrack();\n    audioTrack.meta = new _xgplayerUtils.AudioTrackMeta();\n    audioTrack.id = audioTrack.meta.id = this._trackNum;\n\n    this.tracks.audioTrack = audioTrack;\n  }\n\n  /**\n   * Package the data as the following data structure\n   * {\n   *    data: Uint8Array. the Stream data.\n   *    info: The first byte info of the Tag.\n   *    tagType: 8、9、18\n   *    timeStamp: the timestemp\n   * }\n   */\n  _parseFlvTag() {\n    if (this.loaderBuffer.length < 11) {\n      return null;\n    }\n    let chunk = this._parseFlvTagHeader();\n    if (chunk) {\n      this._processChunk(chunk);\n    }\n    return chunk;\n  }\n\n  /**\n   * Parse the 11 byte tag Header\n   */\n  _parseFlvTagHeader() {\n    let offset = 0;\n    let chunk = {};\n\n    let tagType = this.loaderBuffer.toInt(offset, 1);\n    offset += 1;\n\n    // 2 bit FMS reserved, 1 bit filtered, 5 bit tag type\n    chunk.filtered = (tagType & 32) >>> 5;\n    chunk.tagType = tagType & 31;\n\n    // 3 Byte datasize\n    chunk.datasize = this.loaderBuffer.toInt(offset, 3);\n    offset += 3;\n\n    if (chunk.tagType !== 8 && chunk.tagType !== 9 && chunk.tagType !== 11 && chunk.tagType !== 18 || this.loaderBuffer.toInt(8, 3) !== 0) {\n      if (this.loaderBuffer && this.loaderBuffer.length > 0) {\n        this.loaderBuffer.shift(1);\n      }\n      this.logger.warn(this.TAG, 'tagType ' + chunk.tagType);\n      return null;\n    }\n\n    if (this.loaderBuffer.length < chunk.datasize + 15) {\n      return null;\n    }\n\n    // read the data.\n    this.loaderBuffer.shift(4);\n\n    // 3 Byte timestamp\n    let timestamp = this.loaderBuffer.toInt(0, 3);\n    this.loaderBuffer.shift(3);\n\n    // 1 Byte timestampExt\n    let timestampExt = this.loaderBuffer.shift(1)[0];\n    if (timestampExt > 0) {\n      timestamp += timestampExt * 0x1000000;\n    }\n\n    chunk.dts = timestamp;\n\n    // streamId\n    this.loaderBuffer.shift(3);\n    return chunk;\n  }\n\n  _processChunk(chunk) {\n    switch (chunk.tagType) {\n      case 18:\n        this._parseScriptData(chunk);\n        break;\n      case 8:\n        this._parseAACData(chunk);\n        break;\n      case 9:\n        this._parseHevcData(chunk);\n        break;\n      case 11:\n        // for some CDN that did not process the currect RTMP messages\n        this.loaderBuffer.shift(3);\n        break;\n      default:\n        this.loaderBuffer.shift(1);\n    }\n  }\n\n  /**\n   * parse flv script data\n   * @param chunk\n   * @private\n   */\n  _parseScriptData(chunk) {\n    let audioTrack = this.tracks.audioTrack;\n    let videoTrack = this.tracks.videoTrack;\n\n    let data = this.loaderBuffer.shift(chunk.datasize);\n\n    const info = new _amfParser2.default().resolve(data, data.length);\n\n    const onMetaData = this._context.onMetaData = info ? info.onMetaData : undefined;\n\n    // fill mediaInfo\n    this._context.mediaInfo.duration = onMetaData.duration;\n    this._context.mediaInfo.hasVideo = onMetaData.hasVideo;\n    this._context.mediaInfo.hsaAudio = onMetaData.hasAudio;\n\n    let validate = this._datasizeValidator(chunk.datasize);\n    if (validate) {\n      this.emit(DEMUX_EVENTS.MEDIA_INFO);\n      this._hasScript = true;\n    }\n\n    // Edit default meta.\n    if (audioTrack && !audioTrack.hasSpecificConfig) {\n      let meta = audioTrack.meta;\n      if (onMetaData.audiosamplerate) {\n        meta.sampleRate = onMetaData.audiosamplerate;\n      }\n\n      if (onMetaData.audiochannels) {\n        meta.channelCount = onMetaData.audiochannels;\n      }\n\n      switch (onMetaData.audiosamplerate) {\n        case 44100:\n          meta.sampleRateIndex = 4;\n          break;\n        case 22050:\n          meta.sampleRateIndex = 7;\n          break;\n        case 11025:\n          meta.sampleRateIndex = 10;\n          break;\n      }\n    }\n    if (videoTrack && !videoTrack.hasSpecificConfig) {\n      let meta = videoTrack.meta;\n      if (typeof onMetaData.framerate === 'number') {\n        let fpsNum = Math.floor(onMetaData.framerate * 1000);\n        if (fpsNum > 0) {\n          let fps = fpsNum / 1000;\n          if (!meta.frameRate) {\n            meta.frameRate = {};\n          }\n          meta.frameRate.fixed = true;\n          meta.frameRate.fps = fps;\n          meta.frameRate.fps_num = fpsNum;\n          meta.frameRate.fps_den = 1000;\n        }\n      }\n    }\n  }\n\n  _aacSequenceHeaderParser(data) {\n    let ret = {};\n    ret.hasSpecificConfig = true;\n    ret.objectType = data[1] >>> 3;\n    ret.sampleRateIndex = (data[1] & 7) << 1 | data[2] >>> 7;\n    ret.audiosamplerate = this._switchAudioSampleRate(ret.sampleRateIndex);\n    ret.channelCount = (data[2] & 120) >>> 3;\n    ret.frameLength = (data[2] & 4) >>> 2;\n    ret.dependsOnCoreCoder = (data[2] & 2) >>> 1;\n    ret.extensionFlagIndex = data[2] & 1;\n\n    ret.codec = `mp4a.40.${ret.objectType}`;\n    let userAgent = window.navigator.userAgent.toLowerCase();\n    let extensionSamplingIndex;\n\n    let config;\n    let samplingIndex = ret.sampleRateIndex;\n\n    if (userAgent.indexOf('firefox') !== -1) {\n      // firefox: use SBR (HE-AAC) if freq less than 24kHz\n      if (ret.sampleRateIndex >= 6) {\n        ret.objectType = 5;\n        config = new Array(4);\n        extensionSamplingIndex = samplingIndex - 3;\n      } else {\n        // use LC-AAC\n        ret.objectType = 2;\n        config = new Array(2);\n        extensionSamplingIndex = samplingIndex;\n      }\n    } else if (userAgent.indexOf('android') !== -1) {\n      // android: always use LC-AAC\n      ret.objectType = 2;\n      config = new Array(2);\n      extensionSamplingIndex = samplingIndex;\n    } else {\n      // for other browsers, e.g. chrome...\n      // Always use HE-AAC to make it easier to switch aac codec profile\n      ret.objectType = 5;\n      extensionSamplingIndex = ret.sampleRateIndex;\n      config = new Array(4);\n\n      if (ret.sampleRateIndex >= 6) {\n        extensionSamplingIndex = ret.sampleRateIndex - 3;\n      } else if (ret.channelCount === 1) {\n        // Mono channel\n        ret.objectType = 2;\n        config = new Array(2);\n        extensionSamplingIndex = ret.sampleRateIndex;\n      }\n    }\n\n    config[0] = ret.objectType << 3;\n    config[0] |= (ret.sampleRateIndex & 0x0F) >>> 1;\n    config[1] = (ret.sampleRateIndex & 0x0F) << 7;\n    config[1] |= (ret.channelCount & 0x0F) << 3;\n    if (ret.objectType === 5) {\n      config[1] |= (extensionSamplingIndex & 0x0F) >>> 1;\n      config[2] = (extensionSamplingIndex & 0x01) << 7;\n      // extended audio object type: force to 2 (LC-AAC)\n      config[2] |= 2 << 2;\n      config[3] = 0;\n    }\n    ret.config = config;\n    return ret;\n  }\n\n  _parseAACData(chunk) {\n    let track = this.tracks.audioTrack;\n    if (!track) {\n      return;\n    }\n\n    let meta = track.meta;\n\n    if (!meta) {\n      meta = new _xgplayerUtils.AudioTrackMeta();\n    }\n\n    let info = this.loaderBuffer.shift(1)[0];\n\n    chunk.data = this.loaderBuffer.shift(chunk.datasize - 1);\n\n    let format = (info & 240) >>> 4;\n\n    track.format = format;\n\n    if (format !== 10) {\n      this.emit(DEMUX_EVENTS.DEMUX_ERROR, new Error(`invalid audio format: ${format}`));\n    }\n\n    if (format === 10 && !this._hasAudioSequence) {\n      meta.sampleRate = this._switchAudioSamplingFrequency(info);\n      meta.sampleRateIndex = (info & 12) >>> 2;\n      meta.frameLenth = (info & 2) >>> 1;\n      meta.channelCount = info & 1;\n      meta.refSampleDuration = Math.floor(1024 / meta.audioSampleRate * meta.timescale);\n    }\n\n    let audioSampleRate = meta.audioSampleRate;\n    let audioSampleRateIndex = meta.sampleRateIndex;\n    let refSampleDuration = meta.refSampleDuration;\n\n    delete chunk.tagType;\n    let validate = this._datasizeValidator(chunk.datasize);\n\n    if (chunk.data[0] === 0) {\n      // AAC Sequence Header\n      let aacHeader = this._aacSequenceHeaderParser(chunk.data);\n      audioSampleRate = aacHeader.audiosamplerate || meta.audioSampleRate;\n      audioSampleRateIndex = aacHeader.sampleRateIndex || meta.sampleRateIndex;\n      refSampleDuration = Math.floor(1024 / audioSampleRate * meta.timescale);\n\n      meta.channelCount = aacHeader.channelCount;\n      meta.sampleRate = audioSampleRate;\n      meta.sampleRateIndex = audioSampleRateIndex;\n      meta.refSampleDuration = refSampleDuration;\n      meta.duration = this._context.mediaInfo.duration * meta.timescale;\n      meta.config = aacHeader.config;\n      meta.objectType = aacHeader.objectType;\n\n      const audioMedia = this._context.mediaInfo.audio;\n\n      // fill audio media info\n      audioMedia.codec = aacHeader.codec;\n      audioMedia.channelCount = aacHeader.channelCount;\n      audioMedia.sampleRate = audioSampleRate;\n      audioMedia.sampleRateIndex = aacHeader.audioSampleRateIndex;\n\n      if (this._hasScript && !this._hasAudioSequence) {\n        this.emit(DEMUX_EVENTS.METADATA_PARSED, 'audio');\n      } else if (this._hasScript && this._hasAudioSequence) {\n        this.emit(DEMUX_EVENTS.AUDIO_METADATA_CHANGE);\n      }\n      ;\n      this._hasAudioSequence = true;\n    } else {\n      chunk.data = chunk.data.slice(1, chunk.data.length);\n      track.samples.push(chunk);\n    }\n    if (!validate) {\n      const error = new Error('TAG length error at ' + chunk.datasize);\n      this.emit(DEMUX_EVENTS.DEMUX_ERROR, error.message);\n      this.logger.warn(this.TAG, error.message);\n    }\n  }\n\n  /**\n   * parse hevc/avc video data\n   * @param chunk\n   * @private\n   */\n  _parseHevcData(chunk) {\n    // header\n    let info = this.loaderBuffer.shift(1)[0];\n    chunk.frameType = (info & 0xf0) >>> 4;\n    chunk.isKeyframe = chunk.frameType === 1;\n    // let tempCodecID = this.tracks.videoTrack.codecID\n    let codecID = info & 0x0f;\n    this.tracks.videoTrack.codecID = codecID;\n\n    // hevc和avc的header解析方式一样\n    chunk.avcPacketType = this.loaderBuffer.shift(1)[0];\n    chunk.cts = this.loaderBuffer.toInt(0, 3);\n    this.loaderBuffer.shift(3);\n\n    // 12 for hevc, 7 for avc\n    if (codecID === 12) {\n      const data = this.loaderBuffer.shift(chunk.datasize - 5);\n      chunk.data = data;\n\n      if (Number.parseInt(chunk.avcPacketType) !== 0) {\n        if (!this._datasizeValidator(chunk.datasize)) {\n          this.logger.warn(this.TAG, `invalid video tag datasize: ${chunk.datasize}`);\n        }\n        let nalu = {};\n        let r = 0;\n        nalu.cts = chunk.cts;\n        nalu.dts = chunk.dts;\n        while (chunk.data.length > r) {\n          let sizes = chunk.data.slice(Number.parseInt(r), 4 + r);\n          nalu.size = sizes[3];\n          nalu.size += sizes[2] * 256;\n          nalu.size += sizes[1] * 256 * 256;\n          nalu.size += sizes[0] * 256 * 256 * 256;\n          r += 4;\n          nalu.data = chunk.data.slice(Number.parseInt(r), nalu.size + r);\n          r += nalu.size;\n          this.tracks.videoTrack.samples.push(nalu);\n          this.emit(DEMUX_EVENTS.METADATA_PARSED, 'video');\n        }\n      } else if (Number.parseInt(chunk.avcPacketType) === 0) {\n        if (!this._datasizeValidator(chunk.datasize)) {\n          this.logger.warn(this.TAG, `invalid video tag datasize: ${chunk.datasize}`);\n        } else {\n          this.emit(DEMUX_EVENTS.METADATA_PARSED, 'video');\n        }\n      }\n    } else if (codecID === 7) {\n      let data = this.loaderBuffer.shift(chunk.datasize - 5);\n      if (data[4] === 0 && data[5] === 0 && data[6] === 0 && data[7] === 1) {\n        let avcclength = 0;\n        for (let i = 0; i < 4; i++) {\n          avcclength = avcclength * 256 + data[i];\n        }\n        avcclength -= 4;\n        data = data.slice(4, data.length);\n        data[3] = avcclength % 256;\n        avcclength = (avcclength - data[3]) / 256;\n        data[2] = avcclength % 256;\n        avcclength = (avcclength - data[2]) / 256;\n        data[1] = avcclength % 256;\n        data[0] = (avcclength - data[1]) / 256;\n      }\n\n      chunk.data = data;\n      // If it is AVC sequece Header.\n      if (chunk.avcPacketType === 0) {\n        this._avcSequenceHeaderParser(chunk.data);\n        let validate = this._datasizeValidator(chunk.datasize);\n        if (validate) {\n          if (this._hasScript && !this._hasVideoSequence) {\n            this.emit(DEMUX_EVENTS.METADATA_PARSED, 'video');\n          } else if (this._hasScript && this._hasVideoSequence) {\n            this.emit(DEMUX_EVENTS.VIDEO_METADATA_CHANGE);\n          }\n          this._hasVideoSequence = true;\n        }\n      } else {\n        if (!this._datasizeValidator(chunk.datasize)) {\n          this.logger.warn(this.TAG, `invalid video tag datasize: ${chunk.datasize}`);\n          return;\n        }\n        this.tracks.videoTrack.samples.push(chunk);\n        // this.emit(DEMUX_EVENTS.DEMUX_COMPLETE)\n      }\n    } else {\n      this.logger.warn(this.TAG, `video codeid is ${codecID}`);\n      chunk.data = this.loaderBuffer.shift(chunk.datasize - 1);\n      if (!this._datasizeValidator(chunk.datasize)) {\n        this.logger.warn(this.TAG, `invalid video tag datasize: ${chunk.datasize}`);\n      }\n      this.tracks.videoTrack.samples.push(chunk);\n      this.emit(DEMUX_EVENTS.DEMUX_COMPLETE);\n    }\n    delete chunk.tagType;\n  }\n\n  /**\n   * parse avc metadata\n   * @param data\n   * @private\n   */\n  _avcSequenceHeaderParser(data) {\n    let track = this.tracks.videoTrack;\n\n    if (!track) {\n      return;\n    }\n\n    let offset = 0;\n\n    if (!track.meta) {\n      track.meta = new _xgplayerUtils.VideoTrackMeta();\n    }\n    let meta = track.meta;\n\n    meta.configurationVersion = data[0];\n    meta.avcProfileIndication = data[1];\n    meta.profileCompatibility = data[2];\n    meta.avcLevelIndication = data[3] / 10;\n    meta.nalUnitLength = (data[4] & 0x03) + 1;\n\n    let numOfSps = data[5] & 0x1f;\n    offset = 6;\n    let config = {};\n\n    // parse SPS\n    for (let i = 0; i < numOfSps; i++) {\n      let size = data[offset] * 255 + data[offset + 1];\n      offset += 2;\n\n      let sps = new Uint8Array(size);\n      for (let j = 0; j < size; j++) {\n        sps[j] = data[offset + j];\n      }\n\n      // codec string\n      let codecString = 'avc1.';\n      for (let j = 1; j < 4; j++) {\n        let h = sps[j].toString(16);\n        if (h.length < 2) {\n          h = '0' + h;\n        }\n        codecString += h;\n      }\n\n      meta.codec = codecString;\n\n      offset += size;\n      this.tracks.videoTrack.meta.sps = sps;\n      config = _xgplayerCodec.SpsParser.parseSPS(sps);\n    }\n\n    let numOfPps = data[offset];\n\n    offset++;\n\n    for (let i = 0; i < numOfPps; i++) {\n      let size = data[offset] * 255 + data[offset + 1];\n      offset += 2;\n      let pps = new Uint8Array(size);\n      for (let j = 0; j < size; j++) {\n        pps[j] = data[offset + j];\n      }\n      offset += size;\n      this.tracks.videoTrack.meta.pps = pps;\n    }\n\n    Object.assign(meta, _xgplayerCodec.SpsParser.toVideoMeta(config));\n\n    // fill video media info\n    const videoMedia = this._context.mediaInfo.video;\n\n    videoMedia.codec = meta.codec;\n    videoMedia.profile = meta.profile;\n    videoMedia.level = meta.level;\n    videoMedia.chromaFormat = meta.chromaFormat;\n    videoMedia.frameRate = meta.frameRate;\n    videoMedia.parRatio = meta.parRatio;\n    videoMedia.width = videoMedia.width === meta.presentWidth ? videoMedia.width : meta.presentWidth;\n    videoMedia.height = videoMedia.height === meta.presentHeight ? videoMedia.width : meta.presentHeight;\n\n    meta.duration = this._context.mediaInfo.duration * meta.timescale;\n    meta.avcc = new Uint8Array(data.length);\n    meta.avcc.set(data);\n    track.meta = meta;\n  }\n\n  /**\n   * choose audio sample rate\n   * @param samplingFrequencyIndex\n   * @returns {number}\n   * @private\n   */\n  _switchAudioSampleRate(samplingFrequencyIndex) {\n    let samplingFrequencyList = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];\n    return samplingFrequencyList[samplingFrequencyIndex];\n  }\n\n  /**\n   * choose audio sampling frequence\n   * @param info\n   * @returns {number}\n   * @private\n   */\n  _switchAudioSamplingFrequency(info) {\n    let samplingFrequencyIndex = (info & 12) >>> 2;\n    let samplingFrequencyList = [5500, 11025, 22050, 44100, 48000];\n    return samplingFrequencyList[samplingFrequencyIndex];\n  }\n\n  /**\n   * choose audio channel count\n   * @param info\n   * @returns {number}\n   * @private\n   */\n  _switchAudioChannel(info) {\n    let sampleTrackNumIndex = info & 1;\n    let sampleTrackNumList = [1, 2];\n    return sampleTrackNumList[sampleTrackNumIndex];\n  }\n\n  /**\n   * check datasize is valid use 4 Byte after current tag\n   * @param datasize\n   * @returns {boolean}\n   * @private\n   */\n  _datasizeValidator(datasize) {\n    let datasizeConfirm = this.loaderBuffer.toInt(0, 4);\n    this.loaderBuffer.shift(4);\n    return datasizeConfirm === datasize + 11;\n  }\n\n  get loaderBuffer() {\n    if (this._context.getInstance('LOADER_BUFFER')) {\n      return this._context.getInstance('LOADER_BUFFER');\n    } else {\n      this.emit(DEMUX_EVENTS.DEMUX_ERROR, new Error('找不到 loaderBuffer 实例'));\n    }\n  }\n\n  get tracks() {\n    return this._context.getInstance('TRACKS');\n  }\n\n  get logger() {\n    return this._context.getInstance('LOGGER');\n  }\n}\n\nexports.default = FlvDemuxer;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-demux/src/flv/index.js?")},"../xgplayer-demux/src/hls/demuxer/m3u8parser.js":
/*!*******************************************************!*\
  !*** ../xgplayer-demux/src/hls/demuxer/m3u8parser.js ***!
  \*******************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n/**\n * Reference: https://tools.ietf.org/html/rfc8216#section-4.3\n */\nclass M3U8Parser {\n  static parse(text, baseurl = '') {\n    let ret = {\n      duration: 0\n    };\n    if (!text || !text.split) {\n      return;\n    }\n    let refs = text.split(/\\r|\\n/);\n    refs = refs.filter(ref => {\n      return ref;\n    });\n    let ref = refs.shift();\n    if (!ref.match('#EXTM3U')) {\n      // TODO:M3U格式错误。\n      return null;\n    }\n    ref = refs.shift();\n    while (ref) {\n      let refm = ref.match(/#(.*):(.*)/);\n      if (refm && refm.length > 2) {\n        switch (refm[1]) {\n          case 'EXT-X-VERSION':\n            ret.version = parseInt(refm[2]);\n            break;\n          case 'EXT-X-MEDIA-SEQUENCE':\n            ret.sequence = parseInt(refm[2]);\n            break;\n          case 'EXT-X-TARGETDURATION':\n            ret.targetduration = parseFloat(refm[2]);\n            break;\n          case 'EXTINF':\n            M3U8Parser.parseFrag(refm, refs, ret, baseurl);\n            break;\n          default:\n            break;\n        }\n      }\n      ref = refs.shift();\n    }\n    return ret;\n  }\n\n  static parseFrag(refm, refs, ret, baseurl) {\n    if (!ret.frags) {\n      ret.frags = [];\n    }\n\n    let freg = {\n      start: ret.duration,\n      duration: parseFloat(refm[2]) * 1000\n    };\n\n    ret.duration += freg.duration;\n    let nextline = refs.shift();\n    if (nextline.match(/#(.*):(.*)/)) {\n      nextline = refs.shift();\n    }\n    if (nextline.length > 0 && nextline.charAt(0) === '/' && baseurl.match(/.*\\/\\/.*\\.\\w+/g)) {\n      baseurl = baseurl.match(/.*\\/\\/.*\\.\\w+/g)[0];\n    }\n    if (nextline.match(/.*:\\/\\/.*/)) {\n      freg.url = nextline;\n    } else {\n      freg.url = baseurl + nextline;\n    }\n\n    ret.frags.push(freg);\n  }\n\n  static parseURL(url) {\n    let baseurl = '';\n    let urls = url.match(/(.*\\/).*\\.m3u8/);\n    if (urls && urls.length > 0) {\n      for (let i = 0; i < urls.length; i++) {\n        if (urls[i].match(/.*\\/$/g) && urls[i].length > baseurl.length) {\n          baseurl = urls[i];\n        }\n      }\n    }\n    return baseurl;\n  }\n}\n\nexports.default = M3U8Parser;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-demux/src/hls/demuxer/m3u8parser.js?")},"../xgplayer-demux/src/hls/demuxer/ts.js":
/*!***********************************************!*\
  !*** ../xgplayer-demux/src/hls/demuxer/ts.js ***!
  \***********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _xgplayerCodec = __webpack_require__(/*! xgplayer-codec */ \"../xgplayer-codec/index.js\");\n\nvar _xgplayerBuffer = __webpack_require__(/*! xgplayer-buffer */ \"../xgplayer-buffer/index.js\");\n\nvar _xgplayerUtils = __webpack_require__(/*! xgplayer-utils */ \"../xgplayer-utils/index.js\");\n\nconst DEMUX_EVENTS = _xgplayerUtils.EVENTS.DEMUX_EVENTS;\nconst StreamType = {\n  0x01: ['video', 'MPEG-1'],\n  0x02: ['video', 'MPEG-2'],\n  0x1b: ['video', 'AVC.H264'],\n  0xea: ['video', 'VC-1'],\n  0x03: ['audio', 'MPEG-1'],\n  0x04: ['audio', 'MPEG-2'],\n  0x0f: ['audio', 'MPEG-2.AAC'],\n  0x11: ['audio', 'MPEG-4.AAC'],\n  0x80: ['audio', 'LPCM'],\n  0x81: ['audio', 'AC3'],\n  0x06: ['audio', 'AC3'],\n  0x82: ['audio', 'DTS'],\n  0x83: ['audio', 'Dolby TrueHD'],\n  0x84: ['audio', 'AC3-Plus'],\n  0x85: ['audio', 'DTS-HD'],\n  0x86: ['audio', 'DTS-MA'],\n  0xa1: ['audio', 'AC3-Plus-SEC'],\n  0xa2: ['audio', 'DTS-HD-SEC']\n};\n\nclass TsDemuxer {\n  constructor(configs) {\n    this.configs = Object.assign({}, configs);\n    this.demuxing = false;\n    this.pat = [];\n    this.pmt = [];\n    this._hasVideoMeta = false;\n    this._hasAudioMeta = false;\n  }\n\n  init() {\n    this.on(DEMUX_EVENTS.DEMUX_START, this.demux.bind(this));\n  }\n\n  demux() {\n    if (this.demuxing) {\n      return;\n    }\n\n    let buffer = this.inputBuffer;\n    let frags = { pat: [], pmt: [] };\n    let peses = {};\n\n    // Read TS segment\n    while (buffer.length >= 188) {\n      while (buffer.length >= 1 && buffer.array[0][buffer.offset] !== 71) {\n        buffer.shift(1);\n      }\n      let buf = buffer.shift(188);\n      // console.log(buf);\n      let tsStream = new _xgplayerUtils.Stream(buf.buffer);\n      let ts = {};\n      TsDemuxer.read(tsStream, ts, frags);\n      if (ts.pes) {\n        if (!peses[ts.header.pid]) {\n          peses[ts.header.pid] = [];\n        }\n        peses[ts.header.pid].push(ts.pes);\n        ts.pes.ES.buffer = [ts.pes.ES.buffer];\n      } else if (peses[ts.header.pid]) {\n        peses[ts.header.pid][peses[ts.header.pid].length - 1].ES.buffer.push(ts.payload.stream);\n      }\n    }\n\n    // Get Frames data\n    for (let i = 0; i < Object.keys(peses).length; i++) {\n      let epeses = peses[Object.keys(peses)[i]];\n      for (let j = 0; j < epeses.length; j++) {\n        epeses[j].id = Object.keys(peses)[i];\n        epeses[j].ES.buffer = TsDemuxer.Merge(epeses[j].ES.buffer);\n        if (epeses[j].type === 'audio') {\n          this.pushAudioSample(epeses[j]);\n        } else if (epeses[j].type === 'video') {\n          this.pushVideoSample(epeses[j]);\n        }\n      }\n    }\n\n    if (this._hasAudioMeta) {\n      this.emit(DEMUX_EVENTS.DEMUX_COMPLETE, 'audio');\n    }\n    if (this._hasVideoMeta) {\n      this.emit(DEMUX_EVENTS.DEMUX_COMPLETE, 'video');\n    }\n  }\n\n  pushAudioSample(pes) {\n    let track;\n    if (!this._tracks.audioTrack) {\n      this._tracks.audioTrack = new _xgplayerBuffer.AudioTrack();\n      track = this._tracks.audioTrack;\n      track.meta = new _xgplayerUtils.AudioTrackMeta({\n        audioSampleRate: pes.ES.frequence,\n        sampleRate: pes.ES.frequence,\n        channelCount: pes.ES.channel,\n        codec: 'mp4a.40.' + pes.ES.audioObjectType,\n        config: pes.ES.audioConfig,\n        id: 2,\n        sampleRateIndex: pes.ES.frequencyIndex\n      });\n      track.meta.refSampleDuration = Math.floor(1024 / track.meta.audioSampleRate * track.meta.timescale);\n      if (!this._hasAudioMeta) {\n        this._hasAudioMeta = true;\n        this.emit(DEMUX_EVENTS.METADATA_PARSED, 'audio');\n      }\n    } else {\n      track = this._tracks.audioTrack;\n    }\n    let data = new Uint8Array(pes.ES.buffer.buffer.slice(pes.ES.buffer.position, pes.ES.buffer.length));\n    let dts = parseInt(pes.pts / 90);\n    let pts = parseInt(pes.pts / 90);\n    let sample = new _xgplayerUtils.AudioTrackSample({ dts, pts, data });\n    track.samples.push(sample);\n  }\n\n  pushVideoSample(pes) {\n    let nals = _xgplayerCodec.Nalunit.getNalunits(pes.ES.buffer);\n    let track;\n    if (!this._tracks.videoTrack) {\n      this._tracks.videoTrack = new _xgplayerBuffer.VideoTrack();\n      track = this._tracks.videoTrack;\n      track.meta = new _xgplayerUtils.VideoTrackMeta();\n    } else {\n      track = this._tracks.videoTrack;\n    }\n    let sampleLength = 0;\n    let sps = false;\n    let pps = false;\n    for (let i = 0; i < nals.length; i++) {\n      let nal = nals[i];\n      if (nal.sps) {\n        // TODO：VideoTrack信息 和 Meta 信息\n        if (track.sps && TsDemuxer.compaireUint8(nal.body, track.sps)) {\n          continue;\n        }\n\n        sps = nal;\n        track.sps = nal.body;\n        track.meta.chromaFormat = sps.sps.chroma_format;\n        track.meta.codec = 'avc1.';\n        for (var j = 1; j < 4; j++) {\n          var h = sps.body[j].toString(16);\n          if (h.length < 2) {\n            h = '0' + h;\n          }\n          track.meta.codec += h;\n        }\n        track.meta.codecHeight = sps.sps.codec_size.height;\n        track.meta.codecWidth = sps.sps.codec_size.width;\n        track.meta.frameRate = sps.sps.frame_rate;\n        track.meta.id = 1;\n        track.meta.level = sps.sps.level_string;\n        track.meta.presentHeight = sps.sps.present_size.height;\n        track.meta.presentWidth = sps.sps.present_size.width;\n        track.meta.profile = sps.sps.profile_string;\n        track.meta.refSampleDuration = Math.floor(track.meta.timescale * (sps.sps.frame_rate.fps_den / sps.sps.frame_rate.fps_num));\n        track.meta.sarRatio = sps.sps.sar_ratio ? sps.sps.sar_ratio : sps.sps.par_ratio;\n      } else if (nal.pps) {\n        track.pps = nal.body;\n        pps = nal;\n      } else {\n        sampleLength += 4 + nal.body.byteLength;\n      }\n    }\n\n    if (sps && pps) {\n      track.meta.avcc = _xgplayerCodec.Nalunit.getAvcc(sps.body, pps.body);\n      if (!this._hasVideoMeta) {\n        this._hasVideoMeta = true;\n        this.emit(DEMUX_EVENTS.METADATA_PARSED, 'video');\n      }\n    }\n\n    let data = new Uint8Array(sampleLength);\n    let offset = 0;\n    let isKeyframe = false;\n    for (let i = 0; i < nals.length; i++) {\n      let nal = nals[i];\n      let length = nal.body.byteLength;\n      if (nal.idr) {\n        isKeyframe = true;\n      }\n      if (!nal.pps && !nal.sps) {\n        data.set(new Uint8Array([length >>> 24 & 0xff, length >>> 16 & 0xff, length >>> 8 & 0xff, length & 0xff]), offset);\n        offset += 4;\n        data.set(nal.body, offset);\n        offset += length;\n      }\n    }\n    let sample = new _xgplayerUtils.VideoTrackSample({\n      dts: parseInt(pes.dts / 90),\n      pts: parseInt(pes.pts / 90),\n      cts: (pes.pts - pes.dts) / 90,\n      originDts: pes.dts,\n      isKeyframe,\n      data\n    });\n    track.samples.push(sample);\n  }\n\n  destory() {\n    this.off(DEMUX_EVENTS.DEMUX_START, this.demux);\n    this.configs = {};\n    this.demuxing = false;\n    this.pat = [];\n    this.pmt = [];\n    this._hasVideoMeta = false;\n    this._hasAudioMeta = false;\n  }\n\n  static compaireUint8(a, b) {\n    if (a.byteLength !== b.byteLength) {\n      return false;\n    }\n    let ret = true;\n    for (let i = 0; i < a.byteLength; i++) {\n      if (a[i] !== b[i]) {\n        ret = false;\n      }\n    }\n    return ret;\n  }\n  static Merge(buffers) {\n    let data;\n    let length = 0;\n    let offset = 0;\n    for (let i = 0; i < buffers.length; i++) {\n      length += buffers[i].length - buffers[i].position;\n    }\n\n    data = new Uint8Array(length);\n    for (let i = 0; i < buffers.length; i++) {\n      let buffer = buffers[i];\n      data.set(new Uint8Array(buffer.buffer, buffer.position), offset);\n      offset += buffer.length - buffer.position;\n    }\n    return new _xgplayerUtils.Stream(data.buffer);\n  }\n\n  static read(stream, ts, frags) {\n    TsDemuxer.readHeader(stream, ts);\n    TsDemuxer.readPayload(stream, ts, frags);\n    if (ts.header.packet === 'MEDIA' && ts.header.payload === 1 && !ts.unknownPIDs) {\n      ts.pes = TsDemuxer.PES(ts);\n    }\n  }\n\n  static readPayload(stream, ts, frags) {\n    let header = ts.header;\n    let pid = header.pid;\n    switch (pid) {\n      case 0:\n        TsDemuxer.PAT(stream, ts, frags);\n        break;\n      case 1:\n        TsDemuxer.CAT(stream, ts, frags);\n        break;\n      case 2:\n        TsDemuxer.TSDT(stream, ts, frags);\n        break;\n      case 0x1fff:\n        break;\n      default:\n        // TODO: some的写法不太好，得改\n        if (frags.pat.some(item => {\n          return item.pid === pid;\n        })) {\n          TsDemuxer.PMT(stream, ts, frags);\n        } else {\n          let sts = frags.pmt ? frags.pmt.filter(item => item.pid === pid) : [];\n          if (sts.length > 0) {\n            TsDemuxer.Media(stream, ts, StreamType[sts[0].streamType][0]);\n          } else {\n            ts.unknownPIDs = true;\n          };\n        }\n    }\n  }\n\n  static readHeader(stream, ts) {\n    let header = {};\n    header.sync = stream.readUint8();\n    let next = stream.readUint16();\n    header.error = next >>> 15;\n    header.payload = next >>> 14 & 1;\n    header.priority = next >>> 13 & 1;\n    header.pid = next & 0x1fff;\n\n    next = stream.readUint8();\n\n    header.scrambling = next >> 6 & 0x3; // 是否加密，00表示不加密\n\n    /**\n     * 00 ISO/IEC未来使用保留\n     * 01 没有调整字段，仅含有184B有效净荷\n     * 02 没有有效净荷，仅含有183B调整字段\n     * 03 0~182B调整字段后为有效净荷\n     */\n    header.adaptation = next >> 4 & 0x3;\n    header.continuity = next & 15;\n    header.packet = header.pid === 0 ? 'PAT' : 'MEDIA';\n    ts.header = header;\n  }\n\n  static PAT(stream, ts, frags) {\n    let ret = {};\n    let next = stream.readUint8();\n    stream.skip(next);\n    next = stream.readUint8();\n    ret.tabelID = next;\n    next = stream.readUint16();\n    ret.error = next >>> 7;\n    ret.zero = next >>> 6 & 1;\n    ret.sectionLength = next & 0xfff;\n    ret.streamID = stream.readUint16();\n    ret.current = stream.readUint8() & 1;\n    ret.sectionNumber = stream.readUint8();\n    ret.lastSectionNumber = stream.readUint8();\n    let N = (ret.sectionLength - 9) / 4;\n    let list = [];\n    for (let i = 0; i < N; i++) {\n      let programNumber = stream.readUint16();\n      let pid = stream.readUint16() & 0x1fff;\n      list.push({\n        program: programNumber,\n        pid,\n        type: programNumber === 0 ? 'network' : 'mapPID'\n      });\n    }\n    if (list.length > 0) {\n      frags.pat = frags.pat.concat(list);\n    }\n    ret.list = list;\n    ret.program = stream.readUint16();\n    ret.pid = stream.readUint16() & 0x1fff;\n    ts.payload = ret;\n    // TODO CRC\n  }\n\n  static PMT(stream, ts, frags) {\n    let ret = {};\n    let header = ts.header;\n    header.packet = 'PMT';\n    let next = stream.readUint8();\n    stream.skip(next);\n    next = stream.readUint8();\n    ret.tableID = next;\n    next = stream.readUint16();\n    ret.sectionLength = next & 0xfff;\n    ret.program = stream.readUint16();\n    ret.current = stream.readUint8() & 1;\n    ret.order = stream.readUint8();\n    ret.lastOrder = stream.readUint8();\n    ret.PCR_PID = stream.readUint16() & 0x1fff;\n    ret.programLength = stream.readUint16() & 0xfff;\n    let N = (ret.sectionLength - 13) / 5;\n    let list = [];\n    for (let i = 0; i < N; i++) {\n      list.push({\n        streamType: stream.readUint8(),\n        pid: stream.readUint16() & 0x1fff, // 0x07e5 视频，0x07e6\n        es: stream.readUint16() & 0xfff\n      });\n    }\n    ret.list = list;\n    if (!this.pmt) {\n      this.pmt = [];\n    }\n    frags.pmt = this.pmt.concat(list.map(item => {\n      return {\n        pid: item.pid,\n        es: item.es,\n        streamType: item.streamType,\n        program: ret.program\n      };\n    }));\n    ts.payload = ret;\n  }\n\n  static Media(stream, ts, type) {\n    let header = ts.header;\n    let payload = {};\n    header.type = type;\n    if (header.adaptation === 0x03) {\n      payload.adaptationLength = stream.readUint8();\n      if (payload.adaptationLength > 0) {\n        let next = stream.readUint8();\n        payload.discontinue = next >>> 7;\n        payload.access = next >>> 6 & 0x01;\n        payload.priority = next >>> 5 & 0x01;\n        payload.PCR = next >>> 4 & 0x01;\n        payload.OPCR = next >>> 3 & 0x01;\n        payload.splicePoint = next >>> 2 & 0x01;\n        payload.transportPrivate = next >>> 1 & 0x01;\n        payload.adaptationField = next & 0x01;\n        let _start = stream.position;\n        if (payload.PCR === 1) {\n          payload.programClockBase = stream.readUint32() << 1;\n          next = stream.readUint16();\n          payload.programClockBase |= next >>> 15;\n          payload.programClockExtension = next & 0x1ff;\n        }\n        if (payload.OPCR === 1) {\n          payload.originProgramClockBase = stream.readUint32() << 1;\n          next = stream.readUint16();\n          payload.originProgramClockBase += next >>> 15;\n          payload.originProgramClockExtension = next & 0x1ff;\n        }\n        if (payload.splicePoint === 1) {\n          payload.spliceCountdown = stream.readUint8();\n        }\n        if (payload.transportPrivate === 1) {\n          let length = stream.readUint8();\n          let transportPrivateData = [];\n          for (let i = 0; i < length; i++) {\n            transportPrivateData.push(stream.readUint8());\n          }\n        }\n        if (payload.adaptationField === 1) {\n          let length = stream.readUint8();\n          let next = stream.readUint8();\n          let start = stream.position;\n          let ltw = next >>> 7;\n          let piecewise = next >>> 6 & 0x1;\n          let seamless = next >>> 5 & 0x1;\n          if (ltw === 1) {\n            next = stream.readUint16();\n            payload.ltwValid = next >>> 15;\n            payload.ltwOffset = next & 0xefff;\n          }\n          if (piecewise === 1) {\n            next = stream.readUint24();\n            payload.piecewiseRate = next & 0x3fffff;\n          }\n          if (seamless === 1) {\n            next = stream.readInt8();\n            payload.spliceType = next >>> 4;\n            payload.dtsNextAU1 = next >>> 1 & 0x7;\n            payload.marker1 = next & 0x1;\n            next = stream.readUint16();\n            payload.dtsNextAU2 = next >>> 1;\n            payload.marker2 = next & 0x1;\n            next = stream.readUint16();\n            payload.dtsNextAU3 = next;\n          }\n          stream.skip(length - 1 - (stream.position - start));\n        }\n        let lastStuffing = payload.adaptationLength - 1 - (stream.position - _start);\n        stream.skip(lastStuffing);\n      }\n    }\n    payload.stream = new _xgplayerUtils.Stream(stream.buffer.slice(stream.position));\n    ts.payload = payload;\n  }\n\n  static PES(ts) {\n    let ret = {};\n    let buffer = ts.payload.stream;\n\n    let next = buffer.readUint24();\n    if (next !== 1) {\n      ret.ES = {};\n      ret.ES.buffer = buffer;\n    } else {\n      let streamID = buffer.readUint8();\n      if (streamID >= 0xe0 && streamID <= 0xef) {\n        ret.type = 'video';\n      }\n      if (streamID >= 0xc0 && streamID <= 0xdf) {\n        ret.type = 'audio';\n      }\n      let packetLength = buffer.readUint16();\n      ret.packetLength = packetLength;\n      if (ret.type === 'video' || ret.type === 'audio') {\n        let next = buffer.readUint8();\n        let first = next >>> 6;\n        if (first !== 0x02) {\n          throw new Error('error when parse pes header');\n        }\n        next = buffer.readUint8();\n        ret.ptsDTSFlag = next >>> 6;\n        ret.escrFlag = next >>> 5 & 0x01;\n        ret.esRateFlag = next >>> 4 & 0x01;\n        ret.dsmFlag = next >>> 3 & 0x01;\n        ret.additionalFlag = next >>> 2 & 0x01;\n        ret.crcFlag = next >>> 1 & 0x01;\n        ret.extensionFlag = next & 0x01;\n        ret.pesHeaderLength = buffer.readUint8();\n        let N1 = ret.pesHeaderLength;\n\n        if (ret.ptsDTSFlag === 2) {\n          let pts = [];\n          next = buffer.readUint8();\n          pts.push(next >>> 1 & 0x07);\n          next = buffer.readUint16();\n          pts.push(next >>> 1);\n          next = buffer.readUint16();\n          pts.push(next >>> 1);\n          ret.pts = pts[0] << 30 | pts[1] << 15 | pts[2];\n          N1 -= 5;\n          // 视频如果没有dts用pts\n          if (ret.type === 'video') {\n            ret.dts = ret.pts;\n          }\n        }\n        if (ret.ptsDTSFlag === 3) {\n          let pts = [];\n          next = buffer.readUint8();\n          pts.push(next >>> 1 & 0x07);\n          next = buffer.readUint16();\n          pts.push(next >>> 1);\n          next = buffer.readUint16();\n          pts.push(next >>> 1);\n          ret.pts = pts[0] << 30 | pts[1] << 15 | pts[2];\n          let dts = [];\n          next = buffer.readUint8();\n          dts.push(next >>> 1 & 0x07);\n          next = buffer.readUint16();\n          dts.push(next >>> 1);\n          next = buffer.readUint16();\n          dts.push(next >>> 1);\n          ret.dts = dts[0] << 30 | dts[1] << 15 | dts[2];\n          N1 -= 10;\n        }\n        if (ret.escrFlag === 1) {\n          let escr = [];\n          let ex = [];\n          next = buffer.readUint8();\n          escr.push(next >>> 3 & 0x07);\n          escr.push(next & 0x03);\n          next = buffer.readUint16();\n          escr.push(next >>> 13);\n          escr.push(next & 0x03);\n          next = buffer.readUint16();\n          escr.push(next >>> 13);\n          ex.push(next & 0x03);\n          next = buffer.readUint8();\n          ex.push(next >>> 1);\n          ret.escr = (escr[0] << 30 | escr[1] << 28 | escr[2] << 15 | escr[3] << 13 | escr[4]) * 300 + (ex[0] << 7 | ex[1]);\n          N1 -= 6;\n        }\n        if (ret.esRateFlag === 1) {\n          next = buffer.readUint24();\n          ret.esRate = next >>> 1 & 0x3fffff;\n          N1 -= 3;\n        }\n        if (ret.dsmFlag === 1) {\n          throw new Error('not support DSM_trick_mode');\n        }\n        if (ret.additionalFlag === 1) {\n          next = buffer.readUint8();\n          ret.additionalCopyInfo = next & 0x7f;\n          N1 -= 1;\n        }\n        if (ret.crcFlag === 1) {\n          ret.pesCRC = buffer.readUint16();\n          N1 -= 2;\n        }\n        if (ret.extensionFlag === 1) {\n          throw new Error('not support extension');\n        }\n        if (N1 > 0) {\n          buffer.skip(N1);\n        }\n        ret.ES = TsDemuxer.ES(buffer, ret.type);\n      } else {\n        throw new Error('format is not supported');\n      }\n    }\n    return ret;\n  }\n\n  static ES(buffer, type) {\n    let next;\n    let ret = {};\n    if (type === 'video') {\n      next = buffer.readUint32();\n      if (next !== 1) {\n        buffer.back(4);\n        next = buffer.readUint24();\n        if (next !== 1) {\n          throw new Error('h264 nal header parse failed');\n        }\n      }\n      buffer.skip(2); // 09 F0\n      // TODO readnalu\n      ret.buffer = buffer;\n    } else if (type === 'audio') {\n      next = buffer.readUint16();\n      // adts的同步字节，12位\n      if (next >>> 4 !== 0xfff) {\n        throw new Error('aac ES parse Error');\n      }\n      const fq = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];\n      ret.id = (next >>> 3 & 0x01) === 0 ? 'MPEG-4' : 'MPEG-2';\n      ret.layer = next >>> 1 & 0x03;\n      ret.absent = next & 0x01;\n      next = buffer.readUint16();\n      ret.audioObjectType = (next >>> 14 & 0x03) + 1;\n      ret.profile = ret.audioObjectType - 1;\n      ret.frequencyIndex = next >>> 10 & 0x0f;\n      ret.frequence = fq[ret.frequencyIndex];\n      ret.channel = next >>> 6 & 0x07;\n      ret.frameLength = (next & 0x03) << 11 | buffer.readUint16() >>> 5;\n      ret.audioConfig = TsDemuxer.getAudioConfig(ret.audioObjectType, ret.channel, ret.frequencyIndex);\n      buffer.skip(1);\n      ret.buffer = buffer;\n    } else {\n      throw new Error(`ES ${type} is not supported`);\n    }\n\n    return ret;\n  }\n\n  static TSDT(stream, ts, frags) {\n    // TODO\n    ts.payload = {};\n  }\n\n  static CAT(stream, ts, frags) {\n    let ret = {};\n    ret.tableID = stream.readUint8();\n    let next = stream.readUint16();\n    ret.sectionIndicator = next >>> 7;\n    ret.sectionLength = next & 0x0fff;\n    stream.skip(2);\n    next = stream.readUint8();\n    ret.version = next >>> 3;\n    ret.currentNextIndicator = next & 0x01;\n    ret.sectionNumber = stream.readUint8();\n    ret.lastSectionNumber = stream.readUint8();\n    let N = (this.sectionLength - 9) / 4;\n    let list = [];\n    for (let i = 0; i < N; i++) {\n      list.push({});\n    }\n    ret.crc32 = stream.readUint32();\n    ts.payload = ret;\n  }\n\n  static getAudioConfig(audioObjectType, channel, sampleIndex) {\n    let userAgent = navigator.userAgent.toLowerCase();\n    let config;\n    let extensionSampleIndex;\n    if (/firefox/i.test(userAgent)) {\n      if (sampleIndex >= 6) {\n        audioObjectType = 5;\n        config = new Array(4);\n        extensionSampleIndex = sampleIndex - 3;\n      } else {\n        audioObjectType = 2;\n        config = new Array(2);\n        extensionSampleIndex = sampleIndex;\n      }\n    } else if (userAgent.indexOf('android') !== -1) {\n      audioObjectType = 2;\n      config = new Array(2);\n      extensionSampleIndex = sampleIndex;\n    } else {\n      audioObjectType = 5;\n      config = new Array(4);\n      if (sampleIndex >= 6) {\n        extensionSampleIndex = sampleIndex - 3;\n      } else {\n        if (channel === 1) {\n          audioObjectType = 2;\n          config = new Array(2);\n        }\n        extensionSampleIndex = sampleIndex;\n      }\n    }\n\n    config[0] = audioObjectType << 3;\n    config[0] |= (sampleIndex & 0x0e) >> 1;\n    config[1] = (sampleIndex & 0x01) << 7;\n    config[1] |= channel << 3;\n    if (audioObjectType === 5) {\n      config[1] |= (extensionSampleIndex & 0x0e) >> 1;\n      config[2] = (extensionSampleIndex & 0x01) << 7;\n      config[2] |= 2 << 2;\n      config[3] = 0;\n    }\n    return config;\n  }\n\n  get inputBuffer() {\n    return this._context.getInstance(this.configs.inputbuffer);\n  }\n\n  get _tracks() {\n    return this._context.getInstance('TRACKS');\n  }\n}\n\nexports.default = TsDemuxer;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-demux/src/hls/demuxer/ts.js?")},"../xgplayer-demux/src/hls/playlist.js":
/*!*********************************************!*\
  !*** ../xgplayer-demux/src/hls/playlist.js ***!
  \*********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass Playlist {\n  constructor(configs) {\n    this._baseURL = '';\n    this._list = {};\n    this._ts = {};\n    this.version = 0;\n    this.sequence = -1;\n    this.targetduration = 0;\n    this.duration = 0;\n    this.fragLength = 0;\n    this._lastget = undefined;\n    this._audoclear = configs.autoclear || false;\n  }\n\n  get list() {\n    return this._list;\n  }\n\n  set baseURL(baseURL) {\n    if (this.baseURL !== baseURL) {\n      this.clear();\n      this._baseURL = baseURL;\n    }\n  }\n\n  get baseURL() {\n    return this._baseURL;\n  }\n\n  push(ts, duration) {\n    if (!this._ts[ts]) {\n      this._ts[ts] = { duration: duration, downloaded: false, downloading: false, start: this.duration };\n      this._list[this.duration] = ts;\n      this.duration += duration;\n      this.fragLength += 1;\n    }\n  }\n\n  deleteFrag(url) {\n    if (this._ts[url]) {\n      if (this._ts[url].start > this._lastget.time) {\n        this._lastget = {\n          duration: this._ts[url].duration,\n          time: this._ts[url].start,\n          downloaded: false,\n          downloading: false,\n          url: url\n        };\n      }\n      delete this._list[this._ts[url].start];\n      delete this._ts[url];\n      this.fragLength -= 1;\n    }\n  }\n\n  pushM3U8(data, deletepre) {\n    // 常规信息替换\n    if (!data) {\n      return;\n    }\n    this.version = data.version;\n    this.targetduration = data.targetduration;\n\n    // 新分片信息\n    if (data.sequence > this.sequence) {\n      this.sequence = data.sequence;\n      let newfraglist = [];\n      for (let i = 0; i < data.frags.length; i++) {\n        let frag = data.frags[i];\n        if (!this._ts[frag.url]) {\n          newfraglist.push(frag.url);\n          this.push(frag.url, frag.duration);\n        }\n      }\n      if (deletepre) {\n        let tslist = this.getTsList();\n        for (let i = 0; i < tslist.length; i++) {\n          if (newfraglist.indexOf(tslist[i]) < 0) {\n            this.deleteFrag(tslist[i]);\n          }\n        }\n      }\n    }\n  }\n\n  getTsList() {\n    return Object.keys(this._ts);\n  }\n\n  downloaded(tsname, isloaded) {\n    let ts = this._ts[tsname];\n    if (ts) {\n      ts.downloaded = isloaded;\n    }\n  }\n\n  downloading(tsname, loading) {\n    let ts = this._ts[tsname];\n    if (ts) {\n      ts.downloading = loading;\n    }\n  }\n\n  getTsByName(name) {\n    return this._ts[name];\n  }\n\n  getTs(time) {\n    let timelist = Object.keys(this._list);\n    let ts;\n\n    if (time === undefined) {\n      if (this._lastget) {\n        time = this._lastget.time + this._lastget.duration;\n      } else {\n        time = 0;\n      }\n    }\n\n    if (timelist.length < 1 || time >= this.duration) {\n      return undefined;\n    }\n    timelist.sort((a, b) => {\n      return parseFloat(a) - parseFloat(b);\n    });\n    for (let i = 0; i < timelist.length; i++) {\n      if (time >= parseInt(timelist[i])) {\n        let url = this._list[timelist[i]];\n        let downloaded = this._ts[url].downloaded;\n        let downloading = this._ts[url].downloading;\n        ts = { url, downloaded, downloading, time: parseInt(timelist[i]), duration: parseInt(this._ts[url].duration) };\n        if (this.autoclear) {\n          delete this._ts[this._lastget.url];\n          delete this._list[this._lastget.time];\n        }\n        this._lastget = ts;\n      } else {\n        break;\n      }\n    }\n    return ts;\n  }\n\n  clear() {\n    this._baseURL = '';\n    this._list = {};\n    this._ts = {};\n    this.version = 0;\n    this.sequence = -1;\n    this.targetduration = 0;\n    this.duration = 0;\n  }\n\n  clearDownloaded() {\n    for (let i = 0, l = Object.keys(this._ts).length; i < l; i++) {\n      let ts = this._ts[Object.keys(this._ts)[i]];\n      ts.downloaded = false;\n      ts.downloading = false;\n    }\n  }\n\n  destroy() {\n    this._baseURL = '';\n    this._list = {};\n    this._ts = {};\n    this.version = 0;\n    this.sequence = -1;\n    this.targetduration = 0;\n    this.duration = 0;\n    this.fragLength = 0;\n    this._lastget = undefined;\n    this._audoclear = false;\n  }\n}\n\nexports.default = Playlist;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-demux/src/hls/playlist.js?")},"../xgplayer-loader/index.js":
/*!***********************************!*\
  !*** ../xgplayer-loader/index.js ***!
  \***********************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nmodule.exports = {\n  FetchLoader: __webpack_require__(/*! ./src/fetch-loader */ "../xgplayer-loader/src/fetch-loader.js").default\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-loader/index.js?')},"../xgplayer-loader/src/fetch-loader.js":
/*!**********************************************!*\
  !*** ../xgplayer-loader/src/fetch-loader.js ***!
  \**********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _xgplayerUtils = __webpack_require__(/*! xgplayer-utils */ \"../xgplayer-utils/index.js\");\n\nconst LOADER_EVENTS = _xgplayerUtils.EVENTS.LOADER_EVENTS;\nconst READ_STREAM = 0;\nconst READ_TEXT = 1;\nconst READ_JSON = 2;\nconst READ_BUFFER = 3;\nclass FetchLoader {\n  constructor(configs) {\n    this.configs = Object.assign({}, configs);\n    this.url = null;\n    this.status = 0;\n    this.error = null;\n    this._reader = null;\n    this._canceled = false;\n    this.readtype = this.configs.readtype;\n    this.buffer = this.configs.buffer || 'LOADER_BUFFER';\n    this._loaderTaskNo = 0;\n  }\n\n  init() {\n    this.on(LOADER_EVENTS.LADER_START, this.load.bind(this));\n  }\n\n  static get type() {\n    return 'loader';\n  }\n\n  load(url, opts) {\n    let _this = this;\n    this.url = url;\n    this._canceled = false;\n\n    // TODO: Add Ranges\n    let params = this.getParams(opts);\n    _this.loading = true;\n    return fetch(this.url, params).then(function (response) {\n      if (response.ok) {\n        _this.status = response.status;\n        return _this._onFetchResponse(response);\n      }\n      _this.emit(LOADER_EVENTS.LOADER_ERROR, _this, response);\n      _this.loading = false;\n    }).catch(function (error) {\n      _this.emit(LOADER_EVENTS.LOADER_ERROR, _this, error);\n      _this.loading = false;\n      throw new Error(error.message);\n    });\n  }\n\n  _onFetchResponse(response) {\n    let _this = this;\n    let buffer = this._context.getInstance(this.buffer);\n    this._loaderTaskNo++;\n    let taskno = this._loaderTaskNo;\n    if (response.ok === true) {\n      switch (this.readtype) {\n        case READ_JSON:\n          response.json().then(data => {\n            _this.loading = false;\n            if (!_this._canceled) {\n              if (buffer) {\n                buffer.push(data);\n                _this.emit(LOADER_EVENTS.LOADER_COMPLETE, buffer);\n              } else {\n                _this.emit(LOADER_EVENTS.LOADER_COMPLETE, data);\n              }\n            }\n          });\n          break;\n        case READ_TEXT:\n          response.text().then(data => {\n            _this.loading = false;\n            if (!_this._canceled) {\n              if (buffer) {\n                buffer.push(data);\n                _this.emit(LOADER_EVENTS.LOADER_COMPLETE, buffer);\n              } else {\n                _this.emit(LOADER_EVENTS.LOADER_COMPLETE, data);\n              }\n            }\n          });\n          break;\n        case READ_BUFFER:\n          response.arrayBuffer().then(data => {\n            _this.loading = false;\n            if (!_this._canceled) {\n              if (buffer) {\n                buffer.push(new Uint8Array(data));\n                _this.emit(LOADER_EVENTS.LOADER_COMPLETE, buffer);\n              } else {\n                _this.emit(LOADER_EVENTS.LOADER_COMPLETE, data);\n              }\n            }\n          });\n          break;\n        case READ_STREAM:\n        default:\n          return this._onReader(response.body.getReader(), taskno);\n      }\n    }\n  }\n\n  _onReader(reader, taskno) {\n    let buffer = this._context.getInstance(this.buffer);\n\n    if (!buffer) {\n      this._reader.cancel();\n    }\n\n    this._reader = reader;\n    if (this.loading === false) {\n      return;\n    }\n\n    let _this = this;\n    // reader read function returns a Promise. get data when callback and has value.done when disconnected.\n    // read方法返回一个Promise. 回调中可以获取到数据。当value.done存在时，说明链接断开。\n    this._reader && this._reader.read().then(function (val) {\n      if (val.done) {\n        // TODO: 完成处理\n        _this.loading = false;\n        _this.status = 0;\n        _this.emit(LOADER_EVENTS.LOADER_COMPLETE, buffer);\n        return;\n      }\n\n      if (_this._canceled) {\n        _this._reader.cancel();\n        return;\n      }\n      buffer.push(val.value);\n      _this.emit(LOADER_EVENTS.LOADER_DATALOADED, buffer);\n      return _this._onReader(reader, taskno);\n    }).catch(error => {\n      console.error(error);\n      _this.emit(LOADER_EVENTS.LOADER_ERROR, _this, error);\n      _this.loading = false;\n    });\n  }\n\n  getParams(opts) {\n    let options = Object.assign({}, opts);\n    let headers = new Headers();\n\n    let params = {\n      method: 'GET',\n      headers: headers,\n      mode: 'cors',\n      cache: 'default'\n\n      // add custmor headers\n      // 添加自定义头\n    };if (typeof this.configs.headers === 'object') {\n      let configHeaders = this.configs.headers;\n      for (let key in configHeaders) {\n        if (configHeaders.hasOwnProperty(key)) {\n          headers.append(key, configHeaders[key]);\n        }\n      }\n    }\n\n    if (typeof options.headers === 'object') {\n      let optHeaders = options.headers;\n      for (let key in optHeaders) {\n        if (optHeaders.hasOwnProperty(key)) {\n          headers.append(key, optHeaders[key]);\n        }\n      }\n    }\n\n    if (options.cors === false) {\n      params.mode = 'same-origin';\n    }\n\n    // withCredentials is disabled by default\n    // withCredentials 在默认情况下不被使用。\n    if (options.withCredentials) {\n      params.credentials = 'include';\n    }\n\n    // TODO: Add ranges;\n    return params;\n  }\n\n  cancel() {\n    if (this._reader) {\n      this._reader.cancel();\n      this._reader = null;\n      this.loading = false;\n      this._canceled = true;\n    }\n  }\n\n  destroy() {\n    this.cancel();\n  }\n}\n\nexports.default = FetchLoader;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-loader/src/fetch-loader.js?")},"../xgplayer-remux/index.js":
/*!**********************************!*\
  !*** ../xgplayer-remux/index.js ***!
  \**********************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nmodule.exports = {\n  Mp4Remuxer: __webpack_require__(/*! ./src/mp4 */ "../xgplayer-remux/src/mp4/index.js").default\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-remux/index.js?')},"../xgplayer-remux/src/mp4/fmp4.js":
/*!*****************************************!*\
  !*** ../xgplayer-remux/src/mp4/fmp4.js ***!
  \*****************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _xgplayerUtils = __webpack_require__(/*! xgplayer-utils */ \"../xgplayer-utils/index.js\");\n\n// const UINT32_MAX = Math.pow(2, 32) - 1;\nclass Fmp4 {\n  static size(value) {\n    return _xgplayerUtils.Buffer.writeUint32(value);\n  }\n  static initBox(size, name, ...content) {\n    const buffer = new _xgplayerUtils.Buffer();\n    buffer.write(Fmp4.size(size), Fmp4.type(name), ...content);\n    return buffer.buffer;\n  }\n  static extension(version, flag) {\n    return new Uint8Array([version, flag >> 16 & 0xff, flag >> 8 & 0xff, flag & 0xff]);\n  }\n  static ftyp() {\n    return Fmp4.initBox(24, 'ftyp', new Uint8Array([0x69, 0x73, 0x6F, 0x6D, // isom,\n    0x0, 0x0, 0x00, 0x01, // minor_version: 0x01\n    0x69, 0x73, 0x6F, 0x6D, // isom\n    0x61, 0x76, 0x63, 0x31 // avc1\n    ]));\n  }\n  static moov({ type, meta }) {\n    let size = 8;\n    let mvhd = Fmp4.mvhd(meta.duration, meta.timescale);\n    let trak;\n\n    if (type === 'video') {\n      trak = Fmp4.videoTrak(meta);\n    } else {\n      trak = Fmp4.audioTrak(meta);\n    }\n\n    let mvex = Fmp4.mvex(meta.duration, meta.timescale || 1000, meta.id);\n    [mvhd, trak, mvex].forEach(item => {\n      size += item.byteLength;\n    });\n    return Fmp4.initBox(size, 'moov', mvhd, trak, mvex);\n  }\n  static mvhd(duration, timescale = 1000) {\n    // duration *= timescale;\n    let bytes = new Uint8Array([0x00, 0x00, 0x00, 0x00, // version(0) + flags     1位的box版本+3位flags   box版本，0或1，一般为0。（以下字节数均按version=0）\n    0x00, 0x00, 0x00, 0x00, // creation_time    创建时间  （相对于UTC时间1904-01-01零点的秒数）\n    0x00, 0x00, 0x00, 0x00, // modification_time   修改时间\n\n    /**\n           * timescale: 4 bytes文件媒体在1秒时间内的刻度值，可以理解为1秒长度\n           */\n    timescale >>> 24 & 0xFF, timescale >>> 16 & 0xFF, timescale >>> 8 & 0xFF, timescale & 0xFF,\n\n    /**\n           * duration: 4 bytes该track的时间长度，用duration和time scale值可以计算track时长，比如audio track的time scale = 8000,\n           * duration = 560128，时长为70.016，video track的time scale = 600, duration = 42000，时长为70\n           */\n    duration >>> 24 & 0xFF, duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x00, 0x01, 0x00, 0x00, // Preferred rate: 1.0   推荐播放速率，高16位和低16位分别为小数点整数部分和小数部分，即[16.16] 格式，该值为1.0（0x00010000）表示正常前向播放\n    /**\n           * PreferredVolume(1.0, 2bytes) + reserved(2bytes)\n           * 与rate类似，[8.8] 格式，1.0（0x0100）表示最大音量\n           */\n    0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, //  reserved: 4 + 4 bytes保留位\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, // ----begin composition matrix----\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // 视频变换矩阵   线性代数\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // ----end composition matrix----\n    0x00, 0x00, 0x00, 0x00, // ----begin pre_defined 6 * 4 bytes----\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre-defined 保留位\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // ----end pre_defined 6 * 4 bytes----\n    0xFF, 0xFF, 0xFF, 0xFF // next_track_ID 下一个track使用的id号\n    ]);\n    return Fmp4.initBox(8 + bytes.length, 'mvhd', new Uint8Array(bytes));\n  }\n  static videoTrak(data) {\n    let size = 8;\n\n    let tkhd = Fmp4.tkhd({\n      id: 1,\n      duration: data.duration,\n      timescale: data.timescale || 1000,\n      width: data.presentWidth,\n      height: data.presentHeight,\n      type: 'video'\n    });\n    let mdia = Fmp4.mdia({\n      type: 'video',\n      timescale: data.timescale || 1000,\n      duration: data.duration,\n      avcc: data.avcc,\n      parRatio: data.parRatio,\n      width: data.presentWidth,\n      height: data.presentHeight\n    });\n    [tkhd, mdia].forEach(item => {\n      size += item.byteLength;\n    });\n    return Fmp4.initBox(size, 'trak', tkhd, mdia);\n  }\n  static audioTrak(data) {\n    let size = 8;\n    let tkhd = Fmp4.tkhd({\n      id: 2,\n      duration: data.duration,\n      timescale: data.timescale || 1000,\n      width: 0,\n      height: 0,\n      type: 'audio'\n    });\n    let mdia = Fmp4.mdia({\n      type: 'audio',\n      timescale: data.timescale || 1000,\n      duration: data.duration,\n      channelCount: data.channelCount,\n      samplerate: data.sampleRate,\n      config: data.config\n    });\n    [tkhd, mdia].forEach(item => {\n      size += item.byteLength;\n    });\n    return Fmp4.initBox(size, 'trak', tkhd, mdia);\n  }\n  static tkhd(data) {\n    let id = data.id;\n    let duration = data.duration;\n    let width = data.width;\n    let height = data.height;\n    let content = new Uint8Array([0x00, 0x00, 0x00, 0x07, // version(0) + flags 1位版本 box版本，0或1，一般为0。（以下字节数均按version=0）按位或操作结果值，预定义如下：\n    // 0x000001 track_enabled，否则该track不被播放；\n    // 0x000002 track_in_movie，表示该track在播放中被引用；\n    // 0x000004 track_in_preview，表示该track在预览时被引用。\n    // 一般该值为7，1+2+4 如果一个媒体所有track均未设置track_in_movie和track_in_preview，将被理解为所有track均设置了这两项；对于hint track，该值为0\n    // hint track 这个特殊的track并不包含媒体数据，而是包含了一些将其他数据track打包成流媒体的指示信息。\n    0x00, 0x00, 0x00, 0x00, // creation_time创建时间（相对于UTC时间1904-01-01零点的秒数）\n    0x00, 0x00, 0x00, 0x00, // modification time 修改时间\n    id >>> 24 & 0xFF, // track_ID: 4 bytes id号，不能重复且不能为0\n    id >>> 16 & 0xFF, id >>> 8 & 0xFF, id & 0xFF, 0x00, 0x00, 0x00, 0x00, // reserved: 4 bytes    保留位\n    duration >>> 24 & 0xFF, // duration: 4 bytes track的时间长度\n    duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x00, 0x00, 0x00, 0x00, // reserved: 2 * 4 bytes    保留位\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // layer(2bytes) + alternate_group(2bytes)  视频层，默认为0，值小的在上层.track分组信息，默认为0表示该track未与其他track有群组关系\n    0x00, 0x00, 0x00, 0x00, // volume(2bytes) + reserved(2bytes)    [8.8] 格式，如果为音频track，1.0（0x0100）表示最大音量；否则为0   +保留位\n    0x00, 0x01, 0x00, 0x00, // ----begin composition matrix----\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, // 视频变换矩阵\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // ----end composition matrix----\n    width >>> 8 & 0xFF, // //宽度\n    width & 0xFF, 0x00, 0x00, height >>> 8 & 0xFF, // 高度\n    height & 0xFF, 0x00, 0x00]);\n    return Fmp4.initBox(8 + content.byteLength, 'tkhd', content);\n  }\n  static edts(data) {\n    let buffer = new _xgplayerUtils.Buffer();\n    let duration = data.duration;\n    let mediaTime = data.mediaTime;\n    buffer.write(Fmp4.size(36), Fmp4.type('edts'));\n    // elst\n    buffer.write(Fmp4.size(28), Fmp4.type('elst'));\n    buffer.write(new Uint8Array([0x00, 0x00, 0x00, 0x01, // entry count\n    duration >> 24 & 0xff, duration >> 16 & 0xff, duration >> 8 & 0xff, duration & 0xff, mediaTime >> 24 & 0xff, mediaTime >> 16 & 0xff, mediaTime >> 8 & 0xff, mediaTime & 0xff, 0x00, 0x00, 0x00, 0x01 // media rate\n    ]));\n    return buffer.buffer;\n  }\n  static mdia(data) {\n    let size = 8;\n    let mdhd = Fmp4.mdhd(data.timescale, data.duration);\n    let hdlr = Fmp4.hdlr(data.type);\n    let minf = Fmp4.minf(data);\n    [mdhd, hdlr, minf].forEach(item => {\n      size += item.byteLength;\n    });\n    return Fmp4.initBox(size, 'mdia', mdhd, hdlr, minf);\n  }\n  static mdhd(timescale = 1000, duration) {\n    let content = new Uint8Array([0x00, 0x00, 0x00, 0x00, // creation_time    创建时间\n    0x00, 0x00, 0x00, 0x00, // modification_time修改时间\n    timescale >>> 24 & 0xFF, // timescale: 4 bytes    文件媒体在1秒时间内的刻度值，可以理解为1秒长度\n    timescale >>> 16 & 0xFF, timescale >>> 8 & 0xFF, timescale & 0xFF, duration >>> 24 & 0xFF, // duration: 4 bytes  track的时间长度\n    duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, 0x55, 0xC4, // language: und (undetermined) 媒体语言码。最高位为0，后面15位为3个字符（见ISO 639-2/T标准中定义）\n    0x00, 0x00 // pre_defined = 0\n    ]);\n    return Fmp4.initBox(12 + content.byteLength, 'mdhd', Fmp4.extension(0, 0), content);\n  }\n  static hdlr(type) {\n    let value = [0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // pre_defined\n    0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\n    ];\n    if (type === 'audio') {\n      value.splice(8, 4, ...[0x73, 0x6f, 0x75, 0x6e]);\n      value.splice(24, 13, ...[0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00]);\n    }\n    return Fmp4.initBox(8 + value.length, 'hdlr', new Uint8Array(value));\n  }\n  static minf(data) {\n    let size = 8;\n    let vmhd = data.type === 'video' ? Fmp4.vmhd() : Fmp4.smhd();\n    let dinf = Fmp4.dinf();\n    let stbl = Fmp4.stbl(data);\n    [vmhd, dinf, stbl].forEach(item => {\n      size += item.byteLength;\n    });\n    return Fmp4.initBox(size, 'minf', vmhd, dinf, stbl);\n  }\n  static vmhd() {\n    return Fmp4.initBox(20, 'vmhd', new Uint8Array([0x00, // version\n    0x00, 0x00, 0x01, // flags\n    0x00, 0x00, // graphicsmode\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor\n    ]));\n  }\n  static smhd() {\n    return Fmp4.initBox(16, 'smhd', new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, // balance\n    0x00, 0x00 // reserved\n    ]));\n  }\n  static dinf() {\n    let buffer = new _xgplayerUtils.Buffer();\n    let dref = [0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x01, // entry_count\n    0x00, 0x00, 0x00, 0x0c, // entry_size\n    0x75, 0x72, 0x6c, 0x20, // 'url' type\n    0x00, // version 0\n    0x00, 0x00, 0x01 // entry_flags\n    ];\n    buffer.write(Fmp4.size(36), Fmp4.type('dinf'), Fmp4.size(28), Fmp4.type('dref'), new Uint8Array(dref));\n    return buffer.buffer;\n  }\n  static stbl(data) {\n    let size = 8;\n    let stsd = Fmp4.stsd(data);\n    let stts = Fmp4.stts();\n    let stsc = Fmp4.stsc();\n    let stsz = Fmp4.stsz();\n    let stco = Fmp4.stco();\n    [stsd, stts, stsc, stsz, stco].forEach(item => {\n      size += item.byteLength;\n    });\n    return Fmp4.initBox(size, 'stbl', stsd, stts, stsc, stsz, stco);\n  }\n  static stsd(data) {\n    let content;\n    if (data.type === 'audio') {\n      // if (!data.isAAC && data.codec === 'mp4') {\n      //     content = FMP4.mp3(data);\n      // } else {\n      //\n      // }\n      // 支持mp4a\n      content = Fmp4.mp4a(data);\n    } else {\n      content = Fmp4.avc1(data);\n    }\n    return Fmp4.initBox(16 + content.byteLength, 'stsd', Fmp4.extension(0, 0), new Uint8Array([0x00, 0x00, 0x00, 0x01]), content);\n  }\n  static mp4a(data) {\n    let content = new Uint8Array([0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // data_reference_index\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, data.channelCount, // channelcount\n    0x00, 0x10, // sampleSize:16bits\n    0x00, 0x00, 0x00, 0x00, // reserved2\n    data.samplerate >> 8 & 0xff, data.samplerate & 0xff, //\n    0x00, 0x00]);\n    let esds = Fmp4.esds(data.config);\n    return Fmp4.initBox(8 + content.byteLength + esds.byteLength, 'mp4a', content, esds);\n  }\n  static esds(config = [43, 146, 8, 0]) {\n    const configlen = config.length;\n    let buffer = new _xgplayerUtils.Buffer();\n    let content = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n\n    0x03, // descriptor_type\n    0x17 + configlen, // length\n    0x00, 0x01, // es_id\n    0x00, // stream_priority\n\n    0x04, // descriptor_type\n    0x0f + configlen, // length\n    0x40, // codec : mpeg4_audio\n    0x15, // stream_type\n    0x00, 0x00, 0x00, // buffer_size\n    0x00, 0x00, 0x00, 0x00, // maxBitrate\n    0x00, 0x00, 0x00, 0x00, // avgBitrate\n\n    0x05 // descriptor_type\n    ].concat([configlen]).concat(config).concat([0x06, 0x01, 0x02]));\n    buffer.write(Fmp4.size(8 + content.byteLength), Fmp4.type('esds'), content);\n    return buffer.buffer;\n  }\n  static avc1(data) {\n    let buffer = new _xgplayerUtils.Buffer();\n    let size = 40; // 8(avc1)+8(avcc)+8(btrt)+16(pasp)\n    // let sps = data.sps\n    // let pps = data.pps\n    let width = data.width;\n    let height = data.height;\n    let hSpacing = data.parRatio.height;\n    let vSpacing = data.parRatio.width;\n    // let avccBuffer = new Buffer()\n    // avccBuffer.write(new Uint8Array([\n    //   0x01, // version\n    //   sps[1], // profile\n    //   sps[2], // profile compatible\n    //   sps[3], // level\n    //   0xfc | 3,\n    //   0xE0 | 1 // 目前只处理一个sps\n    // ].concat([sps.length >>> 8 & 0xff, sps.length & 0xff])))\n    // avccBuffer.write(sps, new Uint8Array([1, pps.length >>> 8 & 0xff, pps.length & 0xff]), pps)\n\n    let avcc = data.avcc;\n    let avc1 = new Uint8Array([0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // data_reference_index\n    0x00, 0x00, // pre_defined\n    0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined\n    width >> 8 & 0xff, width & 0xff, // width\n    height >> 8 & 0xff, height & 0xff, // height\n    0x00, 0x48, 0x00, 0x00, // horizresolution\n    0x00, 0x48, 0x00, 0x00, // vertresolution\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x01, // frame_count\n    0x12, 0x64, 0x61, 0x69, 0x6C, // dailymotion/hls.js\n    0x79, 0x6D, 0x6F, 0x74, 0x69, 0x6F, 0x6E, 0x2F, 0x68, 0x6C, 0x73, 0x2E, 0x6A, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // compressorname\n    0x00, 0x18, // depth = 24\n    0x11, 0x11]); // pre_defined = -1\n    let btrt = new Uint8Array([0x00, 0x1c, 0x9c, 0x80, // bufferSizeDB\n    0x00, 0x2d, 0xc6, 0xc0, // maxBitrate\n    0x00, 0x2d, 0xc6, 0xc0 // avgBitrate\n    ]);\n    let pasp = new Uint8Array([hSpacing >> 24, // hSpacing\n    hSpacing >> 16 & 0xff, hSpacing >> 8 & 0xff, hSpacing & 0xff, vSpacing >> 24, // vSpacing\n    vSpacing >> 16 & 0xff, vSpacing >> 8 & 0xff, vSpacing & 0xff]);\n\n    buffer.write(Fmp4.size(size + avc1.byteLength + avcc.byteLength + btrt.byteLength), Fmp4.type('avc1'), avc1, Fmp4.size(8 + avcc.byteLength), Fmp4.type('avcC'), avcc, Fmp4.size(20), Fmp4.type('btrt'), btrt, Fmp4.size(16), Fmp4.type('pasp'), pasp);\n    return buffer.buffer;\n  }\n  static stts() {\n    let content = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00 // entry_count\n    ]);\n    return Fmp4.initBox(16, 'stts', content);\n  }\n  static stsc() {\n    let content = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00 // entry_count\n    ]);\n    return Fmp4.initBox(16, 'stsc', content);\n  }\n  static stco() {\n    let content = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00 // entry_count\n    ]);\n    return Fmp4.initBox(16, 'stco', content);\n  }\n  static stsz() {\n    let content = new Uint8Array([0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // sample_size\n    0x00, 0x00, 0x00, 0x00 // sample_count\n    ]);\n    return Fmp4.initBox(20, 'stsz', content);\n  }\n  static mvex(duration, timescale = 1000, trackID) {\n    let buffer = new _xgplayerUtils.Buffer();\n    let mehd = _xgplayerUtils.Buffer.writeUint32(duration);\n    buffer.write(Fmp4.size(56), Fmp4.type('mvex'), Fmp4.size(16), Fmp4.type('mehd'), Fmp4.extension(0, 0), mehd, Fmp4.trex(trackID));\n    return buffer.buffer;\n  }\n  static trex(id) {\n    let content = new Uint8Array([0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff, // track_ID\n    0x00, 0x00, 0x00, 0x01, // default_sample_description_index\n    0x00, 0x00, 0x00, 0x00, // default_sample_duration\n    0x00, 0x00, 0x00, 0x00, // default_sample_size\n    0x00, 0x01, 0x00, 0x01 // default_sample_flags\n    ]);\n    return Fmp4.initBox(8 + content.byteLength, 'trex', content);\n  }\n  static moof(data) {\n    let size = 8;\n    let mfhd = Fmp4.mfhd();\n    let traf = Fmp4.traf(data);\n    [mfhd, traf].forEach(item => {\n      size += item.byteLength;\n    });\n    return Fmp4.initBox(size, 'moof', mfhd, traf);\n  }\n  static mfhd() {\n    let content = _xgplayerUtils.Buffer.writeUint32(Fmp4.sequence);\n    Fmp4.sequence += 1;\n    return Fmp4.initBox(16, 'mfhd', Fmp4.extension(0, 0), content);\n  }\n  static traf(data) {\n    let size = 8;\n    let tfhd = Fmp4.tfhd(data.id);\n    let tfdt = Fmp4.tfdt(data.time);\n    let sdtp = Fmp4.sdtp(data);\n    let trun = Fmp4.trun(data, sdtp.byteLength);\n\n    [tfhd, tfdt, trun, sdtp].forEach(item => {\n      size += item.byteLength;\n    });\n    return Fmp4.initBox(size, 'traf', tfhd, tfdt, trun, sdtp);\n  }\n  static tfhd(id) {\n    let content = _xgplayerUtils.Buffer.writeUint32(id);\n    return Fmp4.initBox(16, 'tfhd', Fmp4.extension(0, 0), content);\n  }\n  static tfdt(time) {\n    // let upper = Math.floor(time / (UINT32_MAX + 1)),\n    //     lower = Math.floor(time % (UINT32_MAX + 1));\n    return Fmp4.initBox(16, 'tfdt', Fmp4.extension(0, 0), _xgplayerUtils.Buffer.writeUint32(time));\n  }\n  static trun(data, sdtpLength) {\n    // let id = data.id;\n    // let ceil = id === 1 ? 16 : 12;\n    let buffer = new _xgplayerUtils.Buffer();\n    let sampleCount = _xgplayerUtils.Buffer.writeUint32(data.samples.length);\n    // mdat-header 8\n    // moof-header 8\n    // mfhd 16\n    // traf-header 8\n    // thhd 16\n    // tfdt 20\n    // trun-header 12\n    // sampleCount 4\n    // data-offset 4\n    // samples.length\n    let offset = _xgplayerUtils.Buffer.writeUint32(8 + 8 + 16 + 8 + 16 + 16 + 12 + 4 + 4 + 16 * data.samples.length + sdtpLength);\n    buffer.write(Fmp4.size(20 + 16 * data.samples.length), Fmp4.type('trun'), new Uint8Array([0x00, 0x00, 0x0F, 0x01]), sampleCount, offset);\n\n    // let size = buffer.buffer.byteLength\n    // let writeOffset = 0\n    // data.samples.forEach(() => {\n    //   size += 16\n    // })\n    //\n    // let trunBox = new Uint8Array(size)\n\n    // trunBox.set(buffer.buffer, 0)\n\n    data.samples.forEach(item => {\n      const flags = item.flags;\n      // console.log(item.type, item.dts, item.duration)\n\n      buffer.write(new Uint8Array([item.duration >>> 24 & 0xFF, // sample_duration\n      item.duration >>> 16 & 0xFF, item.duration >>> 8 & 0xFF, item.duration & 0xFF, item.size >>> 24 & 0xFF, // sample_size\n      item.size >>> 16 & 0xFF, item.size >>> 8 & 0xFF, item.size & 0xFF, flags.isLeading << 2 | flags.dependsOn, // sample_flags\n      flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.isNonSync, 0x00, 0x00, // sample_degradation_priority\n      item.cts >>> 24 & 0xFF, // sample_composition_time_offset\n      item.cts >>> 16 & 0xFF, item.cts >>> 8 & 0xFF, item.cts & 0xFF]));\n      // writeOffset += 16\n      // buffer.write(Buffer.writeUint32(0));\n    });\n    return buffer.buffer;\n  }\n  static sdtp(data) {\n    let buffer = new _xgplayerUtils.Buffer();\n    buffer.write(Fmp4.size(12 + data.samples.length), Fmp4.type('sdtp'), Fmp4.extension(0, 0));\n    data.samples.forEach(item => {\n      const flags = item.flags;\n      const num = flags.isLeading << 6 | // is_leading: 2 (bit)\n      flags.dependsOn << 4 | // sample_depends_on\n      flags.isDependedOn << 2 | // sample_is_depended_on\n      flags.hasRedundancy; // sample_has_redundancy\n\n      buffer.write(new Uint8Array([num]));\n    });\n    return buffer.buffer;\n  }\n  static mdat(data) {\n    let buffer = new _xgplayerUtils.Buffer();\n    let size = 8;\n    data.samples.forEach(item => {\n      size += item.size;\n    });\n    buffer.write(Fmp4.size(size), Fmp4.type('mdat'));\n    let mdatBox = new Uint8Array(size);\n    let offset = 0;\n    mdatBox.set(buffer.buffer, offset);\n    offset += 8;\n    data.samples.forEach(item => {\n      item.buffer.forEach(unit => {\n        mdatBox.set(unit, offset);\n        offset += unit.byteLength;\n        // buffer.write(unit.data);\n      });\n    });\n    return mdatBox;\n  }\n}\nFmp4.type = name => {\n  return new Uint8Array([name.charCodeAt(0), name.charCodeAt(1), name.charCodeAt(2), name.charCodeAt(3)]);\n};\nFmp4.sequence = 1;\n\nexports.default = Fmp4;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-remux/src/mp4/fmp4.js?")},"../xgplayer-remux/src/mp4/index.js":
/*!******************************************!*\
  !*** ../xgplayer-remux/src/mp4/index.js ***!
  \******************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _xgplayerUtils = __webpack_require__(/*! xgplayer-utils */ \"../xgplayer-utils/index.js\");\n\nvar _fmp = __webpack_require__(/*! ./fmp4 */ \"../xgplayer-remux/src/mp4/fmp4.js\");\n\nvar _fmp2 = _interopRequireDefault(_fmp);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst REMUX_EVENTS = _xgplayerUtils.EVENTS.REMUX_EVENTS;\n\nclass Mp4Remuxer {\n  constructor() {\n    this._dtsBase = 0;\n    this._isDtsBaseInited = false;\n\n    this.videoAllDuration = 0;\n    this.audioAllDuration = 0;\n  }\n\n  init() {\n    this.on(REMUX_EVENTS.REMUX_MEDIA, this.remux.bind(this));\n    this.on(REMUX_EVENTS.REMUX_METADATA, this.onMetaDataReady.bind(this));\n  }\n\n  destroy() {\n    this._dtsBase = -1;\n    this._dtsBaseInited = false;\n  }\n\n  reset() {\n    this._dtsBase = 0;\n    this._isDtsBaseInited = false;\n  }\n\n  remux() {\n    const { audioTrack, videoTrack } = this._context.getInstance('TRACKS');\n    !this._isDtsBaseInited && this.calcDtsBase(audioTrack, videoTrack);\n\n    this._remuxVideo(videoTrack);\n    this._remuxAudio(audioTrack);\n  }\n\n  seek() {}\n\n  onMetaDataReady(type) {\n    let initSegment = new _xgplayerUtils.Buffer();\n    let ftyp = _fmp2.default.ftyp();\n    let moov;\n    let track;\n\n    if (type === 'audio') {\n      const { audioTrack } = this._context.getInstance('TRACKS');\n      track = audioTrack;\n    } else {\n      const { videoTrack } = this._context.getInstance('TRACKS');\n      track = videoTrack;\n    }\n\n    moov = _fmp2.default.moov({ type, meta: track.meta });\n\n    initSegment.write(ftyp, moov);\n\n    let presourcebuffer = this._context.getInstance('PRE_SOURCE_BUFFER');\n    let source = presourcebuffer.getSource(type);\n    if (!source) {\n      source = presourcebuffer.createSource(type);\n    }\n\n    source.mimetype = track.meta.codec;\n    source.init = initSegment;\n    this.emit(REMUX_EVENTS.INIT_SEGMENT, type);\n  }\n\n  calcDtsBase(audioTrack, videoTrack) {\n    if (!audioTrack.samples.length && !videoTrack.samples.length) {\n      return;\n    }\n\n    let audioBase = Infinity;\n    let videoBase = Infinity;\n\n    if (audioTrack.samples && audioTrack.samples.length) {\n      audioBase = audioTrack.samples[0].dts;\n    }\n    if (videoTrack.samples && videoTrack.samples.length) {\n      videoBase = videoTrack.samples[0].dts;\n    }\n\n    this._dtsBase = Math.min(audioBase, videoBase);\n    this._isDtsBaseInited = true;\n  }\n\n  _remuxVideo(videoTrack) {\n    const track = videoTrack;\n\n    if (!videoTrack.samples || !videoTrack.samples.length) {\n      return;\n    }\n\n    let { samples } = track;\n    let firstDts = -1;\n\n    const mp4Samples = [];\n    const mdatBox = {\n      samples: []\n    };\n\n    while (samples.length) {\n      const avcSample = samples.shift();\n      const { isKeyframe } = avcSample;\n      let dts = avcSample.dts - this._dtsBase;\n\n      if (firstDts === -1) {\n        firstDts = dts;\n      }\n\n      let cts;\n      let pts;\n      if (avcSample.pts) {\n        pts = avcSample.pts - this._dtsBase;\n        cts = pts - dts;\n      }\n      if (avcSample.cts) {\n        pts = avcSample.cts + dts;\n        cts = avcSample.cts;\n      }\n\n      let mdatSample = {\n        buffer: [],\n        size: 0\n      };\n      mdatBox.samples.push(mdatSample);\n      mdatSample.buffer.push(avcSample.data);\n      mdatSample.size += avcSample.data.byteLength;\n\n      let sampleDuration = 0;\n      if (samples.length >= 1) {\n        const nextDts = samples[0].dts - this._dtsBase;\n        sampleDuration = nextDts - dts;\n      } else {\n        if (mp4Samples.length >= 1) {\n          // lastest sample, use second last duration\n          sampleDuration = mp4Samples[mp4Samples.length - 1].duration;\n        } else {\n          // the only one sample, use reference duration\n          sampleDuration = this.videoMeta.refSampleDuration;\n        }\n      }\n      this.videoAllDuration += sampleDuration;\n      mp4Samples.push({\n        dts,\n        cts,\n        pts,\n        data: avcSample.data,\n        size: avcSample.data.byteLength,\n        isKeyframe,\n        duration: sampleDuration,\n        flags: {\n          isLeading: 0,\n          dependsOn: isKeyframe ? 2 : 1,\n          isDependedOn: isKeyframe ? 1 : 0,\n          hasRedundancy: 0,\n          isNonSync: isKeyframe ? 0 : 1\n        },\n        originDts: dts,\n        type: 'video'\n      });\n    }\n\n    let moofMdat = new _xgplayerUtils.Buffer();\n\n    const moof = _fmp2.default.moof({\n      id: track.meta.id,\n      time: firstDts,\n      samples: mp4Samples\n    });\n    const mdat = _fmp2.default.mdat(mdatBox);\n    moofMdat.write(moof, mdat);\n\n    track.samples = [];\n    track.length = 0;\n\n    let presourcebuffer = this._context.getInstance('PRE_SOURCE_BUFFER');\n    let source = presourcebuffer.getSource('video');\n    if (!source) {\n      source = presourcebuffer.createSource('video');\n    }\n\n    source.data.push(moofMdat);\n\n    this.emit(REMUX_EVENTS.MEDIA_SEGMENT, 'video');\n  }\n\n  _remuxAudio(track) {\n    const { samples } = track;\n    let firstDts = -1;\n    let mp4Samples = [];\n\n    const mdatBox = {\n      samples: []\n    };\n    if (!samples || !samples.length) {\n      return;\n    }\n    let isFirstDtsInited = false;\n    while (samples.length) {\n      let sample = samples.shift();\n      const { data } = sample;\n      let dts = sample.dts - this._dtsBase;\n      const originDts = dts;\n      if (!isFirstDtsInited) {\n        firstDts = dts;\n        isFirstDtsInited = true;\n      }\n\n      let sampleDuration = 0;\n\n      if (this.audioMeta.refSampleDurationFixed) {\n        sampleDuration = this.audioMeta.refSampleDurationFixed;\n      } else if (samples.length >= 1) {\n        const nextDts = samples[0].dts - this._dtsBase;\n        sampleDuration = nextDts - dts;\n      } else {\n        if (mp4Samples.length >= 1) {\n          // use second last sample duration\n          sampleDuration = mp4Samples[mp4Samples.length - 1].duration;\n        } else {\n          // the only one sample, use reference sample duration\n          sampleDuration = this.audioMeta.refSampleDuration;\n        }\n      }\n\n      // console.log('remux audio ', dts)\n      this.audioAllDuration += sampleDuration;\n      const mp4Sample = {\n        dts,\n        pts: dts,\n        cts: 0,\n        size: data.byteLength,\n        duration: sample.duration ? sample.duration : sampleDuration,\n        flags: {\n          isLeading: 0,\n          dependsOn: 2,\n          isDependedOn: 1,\n          hasRedundancy: 0,\n          isNonSync: 0\n        },\n        isKeyframe: true,\n        originDts,\n        type: 'audio'\n      };\n\n      let mdatSample = {\n        buffer: [],\n        size: 0\n      };\n      mdatSample.buffer.push(data);\n      mdatSample.size += data.byteLength;\n\n      mdatBox.samples.push(mdatSample);\n\n      mp4Samples.push(mp4Sample);\n    }\n\n    const moofMdat = new _xgplayerUtils.Buffer();\n    const moof = _fmp2.default.moof({\n      id: track.meta.id,\n      time: firstDts,\n      samples: mp4Samples\n    });\n    const mdat = _fmp2.default.mdat(mdatBox);\n    moofMdat.write(moof, mdat);\n\n    track.samples = [];\n    track.length = 0;\n\n    let presourcebuffer = this._context.getInstance('PRE_SOURCE_BUFFER');\n    let source = presourcebuffer.getSource('audio');\n    if (!source) {\n      source = presourcebuffer.createSource('audio');\n    }\n    source.data.push(moofMdat);\n    this.emit(REMUX_EVENTS.MEDIA_SEGMENT, 'audio', moofMdat);\n  }\n\n  initSilentAudio(dts, duration) {\n    const unit = Mp4Remuxer.getSilentFrame(this.audioMeta.channelCount);\n    return {\n      dts,\n      pts: dts,\n      cts: 0,\n      duration,\n      unit,\n      size: unit.byteLength,\n      originDts: dts,\n      type: 'video'\n    };\n  }\n\n  get videoMeta() {\n    return this._context.getInstance('TRACKS').videoTrack.meta;\n  }\n  get audioMeta() {\n    return this._context.getInstance('TRACKS').audioTrack.meta;\n  }\n\n  static getSilentFrame(channelCount) {\n    if (channelCount === 1) {\n      return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);\n    } else if (channelCount === 2) {\n      return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);\n    } else if (channelCount === 3) {\n      return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);\n    } else if (channelCount === 4) {\n      return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);\n    } else if (channelCount === 5) {\n      return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);\n    } else if (channelCount === 6) {\n      return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);\n    }\n    return null;\n  }\n}\nexports.default = Mp4Remuxer;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-remux/src/mp4/index.js?")},"../xgplayer-utils/index.js":
/*!**********************************!*\
  !*** ../xgplayer-utils/index.js ***!
  \**********************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nmodule.exports = {\n  Context: __webpack_require__(/*! ./src/context */ "../xgplayer-utils/src/context.js").default,\n\n  // Modules from constants\n  EVENTS: __webpack_require__(/*! ./src/constants/events */ "../xgplayer-utils/src/constants/events.js").default,\n  WORKER_COMMANDS: __webpack_require__(/*! ./src/constants/worker-commands */ "../xgplayer-utils/src/constants/worker-commands.js").default,\n\n  // Modules from env\n  sniffer: __webpack_require__(/*! ./src/env/sniffer */ "../xgplayer-utils/src/env/sniffer.js").default,\n  isLe: __webpack_require__(/*! ./src/env/isle */ "../xgplayer-utils/src/env/isle.js").default,\n  UTF8: __webpack_require__(/*! ./src/env/utf8 */ "../xgplayer-utils/src/env/utf8.js").default,\n\n  // Models\n  MediaInfo: __webpack_require__(/*! ./src/models/media-info */ "../xgplayer-utils/src/models/media-info.js").default,\n  MediaSample: __webpack_require__(/*! ./src/models/media-sample */ "../xgplayer-utils/src/models/media-sample.js").default,\n  MediaSegment: __webpack_require__(/*! ./src/models/media-segment */ "../xgplayer-utils/src/models/media-segment.js").default,\n  MediaSegmentList: __webpack_require__(/*! ./src/models/media-segment-list */ "../xgplayer-utils/src/models/media-segment-list.js").default,\n  AudioTrackMeta: __webpack_require__(/*! ./src/models/track-meta */ "../xgplayer-utils/src/models/track-meta.js").AudioTrackMeta,\n  VideoTrackMeta: __webpack_require__(/*! ./src/models/track-meta */ "../xgplayer-utils/src/models/track-meta.js").VideoTrackMeta,\n  AudioTrackSample: __webpack_require__(/*! ./src/models/track-sample */ "../xgplayer-utils/src/models/track-sample.js").AudioTrackSample,\n  VideoTrackSample: __webpack_require__(/*! ./src/models/track-sample */ "../xgplayer-utils/src/models/track-sample.js").VideoTrackSample,\n\n  // Modules from mse\n  Mse: __webpack_require__(/*! ./src/mse/index */ "../xgplayer-utils/src/mse/index.js").default,\n\n  // Modules from write\n  Stream: __webpack_require__(/*! ./src/write/stream */ "../xgplayer-utils/src/write/stream.js").default,\n  Buffer: __webpack_require__(/*! ./src/write/buffer */ "../xgplayer-utils/src/write/buffer.js").default,\n\n  MobileVideo: __webpack_require__(/*! ./src/mobile/mobile-video */ "../xgplayer-utils/src/mobile/mobile-video.js")\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/index.js?')},"../xgplayer-utils/node_modules/concat-typed-array/lib/concat.js":
/*!***********************************************************************!*\
  !*** ../xgplayer-utils/node_modules/concat-typed-array/lib/concat.js ***!
  \***********************************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\n\nexports.default = function (ResultConstructor) {\n  var totalLength = 0;\n\n  for (var _len = arguments.length, arrays = Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n    arrays[_key - 1] = arguments[_key];\n  }\n\n  var _iteratorNormalCompletion = true;\n  var _didIteratorError = false;\n  var _iteratorError = undefined;\n\n  try {\n    for (var _iterator = arrays[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n      var arr = _step.value;\n\n      totalLength += arr.length;\n    }\n  } catch (err) {\n    _didIteratorError = true;\n    _iteratorError = err;\n  } finally {\n    try {\n      if (!_iteratorNormalCompletion && _iterator.return) {\n        _iterator.return();\n      }\n    } finally {\n      if (_didIteratorError) {\n        throw _iteratorError;\n      }\n    }\n  }\n\n  var result = new ResultConstructor(totalLength);\n  var offset = 0;\n  var _iteratorNormalCompletion2 = true;\n  var _didIteratorError2 = false;\n  var _iteratorError2 = undefined;\n\n  try {\n    for (var _iterator2 = arrays[Symbol.iterator](), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {\n      var _arr = _step2.value;\n\n      result.set(_arr, offset);\n      offset += _arr.length;\n    }\n  } catch (err) {\n    _didIteratorError2 = true;\n    _iteratorError2 = err;\n  } finally {\n    try {\n      if (!_iteratorNormalCompletion2 && _iterator2.return) {\n        _iterator2.return();\n      }\n    } finally {\n      if (_didIteratorError2) {\n        throw _iteratorError2;\n      }\n    }\n  }\n\n  return result;\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/node_modules/concat-typed-array/lib/concat.js?')},"../xgplayer-utils/node_modules/concat-typed-array/lib/index.js":
/*!**********************************************************************!*\
  !*** ../xgplayer-utils/node_modules/concat-typed-array/lib/index.js ***!
  \**********************************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nvar _concat = __webpack_require__(/*! ./concat */ "../xgplayer-utils/node_modules/concat-typed-array/lib/concat.js");\n\nvar _concat2 = _interopRequireDefault(_concat);\n\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : { default: obj };\n}\n\nmodule.exports = _concat2.default;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/node_modules/concat-typed-array/lib/index.js?')},"../xgplayer-utils/node_modules/webworkify-webpack/index.js":
/*!******************************************************************!*\
  !*** ../xgplayer-utils/node_modules/webworkify-webpack/index.js ***!
  \******************************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nfunction webpackBootstrapFunc(modules) {\n  /******/ // The module cache\n  /******/var installedModules = {};\n\n  /******/ // The require function\n  /******/function __webpack_require__(moduleId) {\n\n    /******/ // Check if module is in cache\n    /******/if (installedModules[moduleId])\n      /******/return installedModules[moduleId].exports;\n\n    /******/ // Create a new module (and put it into the cache)\n    /******/var module = installedModules[moduleId] = {\n      /******/i: moduleId,\n      /******/l: false,\n      /******/exports: {}\n      /******/ };\n\n    /******/ // Execute the module function\n    /******/modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n    /******/ // Flag the module as loaded\n    /******/module.l = true;\n\n    /******/ // Return the exports of the module\n    /******/return module.exports;\n    /******/\n  }\n\n  /******/ // expose the modules object (__webpack_modules__)\n  /******/__webpack_require__.m = modules;\n\n  /******/ // expose the module cache\n  /******/__webpack_require__.c = installedModules;\n\n  /******/ // identity function for calling harmony imports with the correct context\n  /******/__webpack_require__.i = function (value) {\n    return value;\n  };\n\n  /******/ // define getter function for harmony exports\n  /******/__webpack_require__.d = function (exports, name, getter) {\n    /******/if (!__webpack_require__.o(exports, name)) {\n      /******/Object.defineProperty(exports, name, {\n        /******/configurable: false,\n        /******/enumerable: true,\n        /******/get: getter\n        /******/ });\n      /******/\n    }\n    /******/\n  };\n\n  /******/ // define __esModule on exports\n  /******/__webpack_require__.r = function (exports) {\n    /******/Object.defineProperty(exports, '__esModule', { value: true });\n    /******/\n  };\n\n  /******/ // getDefaultExport function for compatibility with non-harmony modules\n  /******/__webpack_require__.n = function (module) {\n    /******/var getter = module && module.__esModule ?\n    /******/function getDefault() {\n      return module['default'];\n    } :\n    /******/function getModuleExports() {\n      return module;\n    };\n    /******/__webpack_require__.d(getter, 'a', getter);\n    /******/return getter;\n    /******/\n  };\n\n  /******/ // Object.prototype.hasOwnProperty.call\n  /******/__webpack_require__.o = function (object, property) {\n    return Object.prototype.hasOwnProperty.call(object, property);\n  };\n\n  /******/ // __webpack_public_path__\n  /******/__webpack_require__.p = \"/\";\n\n  /******/ // on error function for async loading\n  /******/__webpack_require__.oe = function (err) {\n    console.error(err);throw err;\n  };\n\n  var f = __webpack_require__(__webpack_require__.s = ENTRY_MODULE);\n  return f.default || f; // try to call default if defined to also support babel esmodule exports\n}\n\nvar moduleNameReqExp = '[\\\\.|\\\\-|\\\\+|\\\\w|\\/|@]+';\nvar dependencyRegExp = '\\\\(\\\\s*(\\/\\\\*.*?\\\\*\\/)?\\\\s*.*?(' + moduleNameReqExp + ').*?\\\\)'; // additional chars when output.pathinfo is true\n\n// http://stackoverflow.com/a/2593661/130442\nfunction quoteRegExp(str) {\n  return (str + '').replace(/[.?*+^$[\\]\\\\(){}|-]/g, '\\\\$&');\n}\n\nfunction isNumeric(n) {\n  return !isNaN(1 * n); // 1 * n converts integers, integers as string (\"123\"), 1e3 and \"1e3\" to integers and strings to NaN\n}\n\nfunction getModuleDependencies(sources, module, queueName) {\n  var retval = {};\n  retval[queueName] = [];\n\n  var fnString = module.toString();\n  var wrapperSignature = fnString.match(/^function\\s?\\w*\\(\\w+,\\s*\\w+,\\s*(\\w+)\\)/);\n  if (!wrapperSignature) return retval;\n  var webpackRequireName = wrapperSignature[1];\n\n  // main bundle deps\n  var re = new RegExp('(\\\\\\\\n|\\\\W)' + quoteRegExp(webpackRequireName) + dependencyRegExp, 'g');\n  var match;\n  while (match = re.exec(fnString)) {\n    if (match[3] === 'dll-reference') continue;\n    retval[queueName].push(match[3]);\n  }\n\n  // dll deps\n  re = new RegExp('\\\\(' + quoteRegExp(webpackRequireName) + '\\\\(\"(dll-reference\\\\s(' + moduleNameReqExp + '))\"\\\\)\\\\)' + dependencyRegExp, 'g');\n  while (match = re.exec(fnString)) {\n    if (!sources[match[2]]) {\n      retval[queueName].push(match[1]);\n      sources[match[2]] = __webpack_require__(match[1]).m;\n    }\n    retval[match[2]] = retval[match[2]] || [];\n    retval[match[2]].push(match[4]);\n  }\n\n  // convert 1e3 back to 1000 - this can be important after uglify-js converted 1000 to 1e3\n  var keys = Object.keys(retval);\n  for (var i = 0; i < keys.length; i++) {\n    for (var j = 0; j < retval[keys[i]].length; j++) {\n      if (isNumeric(retval[keys[i]][j])) {\n        retval[keys[i]][j] = 1 * retval[keys[i]][j];\n      }\n    }\n  }\n\n  return retval;\n}\n\nfunction hasValuesInQueues(queues) {\n  var keys = Object.keys(queues);\n  return keys.reduce(function (hasValues, key) {\n    return hasValues || queues[key].length > 0;\n  }, false);\n}\n\nfunction getRequiredModules(sources, moduleId) {\n  var modulesQueue = {\n    main: [moduleId]\n  };\n  var requiredModules = {\n    main: []\n  };\n  var seenModules = {\n    main: {}\n  };\n\n  while (hasValuesInQueues(modulesQueue)) {\n    var queues = Object.keys(modulesQueue);\n    for (var i = 0; i < queues.length; i++) {\n      var queueName = queues[i];\n      var queue = modulesQueue[queueName];\n      var moduleToCheck = queue.pop();\n      seenModules[queueName] = seenModules[queueName] || {};\n      if (seenModules[queueName][moduleToCheck] || !sources[queueName][moduleToCheck]) continue;\n      seenModules[queueName][moduleToCheck] = true;\n      requiredModules[queueName] = requiredModules[queueName] || [];\n      requiredModules[queueName].push(moduleToCheck);\n      var newModules = getModuleDependencies(sources, sources[queueName][moduleToCheck], queueName);\n      var newModulesKeys = Object.keys(newModules);\n      for (var j = 0; j < newModulesKeys.length; j++) {\n        modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]] || [];\n        modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]].concat(newModules[newModulesKeys[j]]);\n      }\n    }\n  }\n\n  return requiredModules;\n}\n\nmodule.exports = function (moduleId, options) {\n  options = options || {};\n  var sources = {\n    main: __webpack_require__.m\n  };\n\n  var requiredModules = options.all ? { main: Object.keys(sources.main) } : getRequiredModules(sources, moduleId);\n\n  var src = '';\n\n  Object.keys(requiredModules).filter(function (m) {\n    return m !== 'main';\n  }).forEach(function (module) {\n    var entryModule = 0;\n    while (requiredModules[module][entryModule]) {\n      entryModule++;\n    }\n    requiredModules[module].push(entryModule);\n    sources[module][entryModule] = '(function(module, exports, __webpack_require__) { module.exports = __webpack_require__; })';\n    src = src + 'var ' + module + ' = (' + webpackBootstrapFunc.toString().replace('ENTRY_MODULE', JSON.stringify(entryModule)) + ')({' + requiredModules[module].map(function (id) {\n      return '' + JSON.stringify(id) + ': ' + sources[module][id].toString();\n    }).join(',') + '});\\n';\n  });\n\n  src = src + 'new ((' + webpackBootstrapFunc.toString().replace('ENTRY_MODULE', JSON.stringify(moduleId)) + ')({' + requiredModules.main.map(function (id) {\n    return '' + JSON.stringify(id) + ': ' + sources.main[id].toString();\n  }).join(',') + '}))(self);';\n\n  var blob = new window.Blob([src], { type: 'text/javascript' });\n  if (options.bare) {\n    return blob;\n  }\n\n  var URL = window.URL || window.webkitURL || window.mozURL || window.msURL;\n\n  var workerUrl = URL.createObjectURL(blob);\n  var worker = new window.Worker(workerUrl);\n  worker.objectURL = workerUrl;\n\n  return worker;\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/node_modules/webworkify-webpack/index.js?")},"../xgplayer-utils/src/constants/events.js":
/*!*************************************************!*\
  !*** ../xgplayer-utils/src/constants/events.js ***!
  \*************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nconst LOADER_EVENTS = {\n  LADER_START: 'LOADER_START',\n  LOADER_DATALOADED: 'LOADER_DATALOADED',\n  LOADER_COMPLETE: 'LOADER_COMPLETE',\n  LOADER_ERROR: 'LOADER_ERROR'\n};\n\nconst DEMUX_EVENTS = {\n  DEMUX_START: 'DEMUX_START',\n  DEMUX_COMPLETE: 'DEMUX_COMPLETE',\n  DEMUX_ERROR: 'DEMUX_ERROR',\n  METADATA_PARSED: 'METADATA_PARSED',\n  VIDEO_METADATA_CHANGE: 'VIDEO_METADATA_CHANGE',\n  AUDIO_METADATA_CHANGE: 'AUDIO_METADATA_CHANGE',\n  MEDIA_INFO: 'MEDIA_INFO'\n};\n\nconst REMUX_EVENTS = {\n  REMUX_METADATA: 'REMUX_METADATA',\n  REMUX_MEDIA: 'REMUX_MEDIA',\n  MEDIA_SEGMENT: 'MEDIA_SEGMENT',\n  REMUX_ERROR: 'REMUX_ERROR',\n  INIT_SEGMENT: 'INIT_SEGMENT'\n};\n\nconst MSE_EVENTS = {\n  SOURCE_UPDATE_END: 'SOURCE_UPDATE_END'\n\n  // hls专有events\n};const HLS_EVENTS = {\n  RETRY_TIME_EXCEEDED: 'RETRY_TIME_EXCEEDED'\n};\n\nconst ALLEVENTS = Object.assign({}, LOADER_EVENTS, DEMUX_EVENTS, REMUX_EVENTS, MSE_EVENTS, HLS_EVENTS);\n\nconst FlvAllowedEvents = [];\nconst HlsAllowedEvents = [];\n\nfor (let key in ALLEVENTS) {\n  if (ALLEVENTS.hasOwnProperty(key)) {\n    FlvAllowedEvents.push(ALLEVENTS[key]);\n  }\n}\n\nfor (let key in ALLEVENTS) {\n  if (ALLEVENTS.hasOwnProperty(key)) {\n    HlsAllowedEvents.push(ALLEVENTS[key]);\n  }\n}\n\nexports.default = {\n  ALLEVENTS,\n  HLS_EVENTS,\n  REMUX_EVENTS,\n  DEMUX_EVENTS,\n  MSE_EVENTS,\n  LOADER_EVENTS,\n  FlvAllowedEvents,\n  HlsAllowedEvents\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/constants/events.js?")},"../xgplayer-utils/src/constants/worker-commands.js":
/*!**********************************************************!*\
  !*** ../xgplayer-utils/src/constants/worker-commands.js ***!
  \**********************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nconst CONTEXT_COMOMANDS = exports.CONTEXT_COMOMANDS = {\n  ON: 'on',\n  ONCE: 'once',\n  OFF: 'off',\n  EMIT: 'emit',\n  DESTROY: 'destroy'\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/constants/worker-commands.js?")},"../xgplayer-utils/src/context.js":
/*!****************************************!*\
  !*** ../xgplayer-utils/src/context.js ***!
  \****************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\n\nvar _mediaInfo = __webpack_require__(/*! ./models/media-info */ "../xgplayer-utils/src/models/media-info.js");\n\nvar _mediaInfo2 = _interopRequireDefault(_mediaInfo);\n\nvar _events = __webpack_require__(/*! events */ "../../node_modules/events/events.js");\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst DIRECT_EMIT_FLAG = \'__TO__\';\n\nclass Context {\n  constructor(allowedEvents = []) {\n    this._emitter = new _events.EventEmitter();\n    this._instanceMap = {}; // 所有的解码流程实例\n    this._clsMap = {}; // 构造函数的map\n    this._inited = false;\n    this.mediaInfo = new _mediaInfo2.default();\n    this.allowedEvents = allowedEvents;\n    this._hooks = {}; // 注册在事件前/后的钩子，例如 before(\'DEMUX_COMPLETE\')\n  }\n\n  /**\n   * 从上下文中获取解码流程实例，如果没有实例，构造一个\n   * @param tag\n   * @param args\n   * @returns {*}\n   */\n  getInstance(tag) {\n    if (this._instanceMap[tag]) {\n      return this._instanceMap[tag];\n    } else {\n      // throw new Error(`${tag}实例尚未初始化`)\n      return null;\n    }\n  }\n\n  /**\n   * 初始化具体实例\n   * @param tag\n   * @param args\n   */\n  initInstance(tag, ...args) {\n    if (this._clsMap[tag]) {\n      const newInstance = new this._clsMap[tag](...args);\n      this._instanceMap[tag] = newInstance;\n      if (newInstance.init) {\n        newInstance.init(); // TODO: lifecircle\n      }\n      return newInstance;\n    } else {\n      throw new Error(`${tag}未在context中注册`);\n    }\n  }\n\n  /**\n   * 避免大量的initInstance调用，初始化所有的组件\n   * @param config\n   */\n  init(config) {\n    if (this._inited) {\n      return;\n    }\n    for (let tag in this._clsMap) {\n      // if not inited, init an instance\n      if (this._clsMap.hasOwnProperty(tag) && !this._instanceMap[tag]) {\n        this.initInstance(tag, config);\n      }\n    }\n    this._inited = true;\n  }\n\n  /**\n   * 注册一个上下文流程，提供安全的事件发送机制\n   * @param tag\n   * @param cls\n   */\n  registry(tag, cls) {\n    const emitter = this._emitter;\n    const checkMessageName = this._isMessageNameValid.bind(this);\n    const self = this;\n    const enhanced = class extends cls {\n      constructor(...args) {\n        super(...args);\n        this.listeners = {};\n        this.onceListeners = {};\n        this.TAG = tag;\n        this._context = self;\n      }\n\n      on(messageName, callback) {\n        checkMessageName(messageName);\n\n        if (this.listeners[messageName]) {\n          this.listeners[messageName].push(callback);\n        } else {\n          this.listeners[messageName] = [callback];\n        }\n\n        emitter.on(`${messageName}${DIRECT_EMIT_FLAG}${tag}`, callback); // 建立定向通信监听\n        return emitter.on(messageName, callback);\n      }\n\n      /**\n       * 在某个事件触发前执行\n       * @param messageName\n       * @param callback\n       */\n      before(messageName, callback) {\n        checkMessageName(messageName);\n        if (self._hooks[messageName]) {\n          self._hooks[messageName].push(callback);\n        } else {\n          self._hooks[messageName] = [callback];\n        }\n      }\n\n      once(messageName, callback) {\n        checkMessageName(messageName);\n\n        if (this.onceListeners[messageName]) {\n          this.onceListeners[messageName].push(callback);\n        } else {\n          this.onceListeners[messageName] = [callback];\n        }\n\n        emitter.once(`${messageName}${DIRECT_EMIT_FLAG}${tag}`, callback);\n        return emitter.once(messageName, callback);\n      }\n\n      emit(messageName, ...args) {\n        checkMessageName(messageName);\n\n        const beforeList = self._hooks[messageName];\n        if (beforeList) {\n          for (let i = 0, len = beforeList.length; i < len; i++) {\n            const callback = beforeList[i];\n            callback();\n          }\n        }\n        return emitter.emit(messageName, ...args);\n      }\n\n      /**\n       * 定向发送给某个组件单例的消息\n       * @param messageName\n       * @param args\n       */\n      emitTo(tag, messageName, ...args) {\n        checkMessageName(messageName);\n\n        return emitter.emit(`${messageName}${DIRECT_EMIT_FLAG}${tag}`, ...args);\n      }\n\n      off(messageName, callback) {\n        checkMessageName(messageName);\n        return emitter.off(messageName, callback);\n      }\n\n      removeListeners() {\n        const hasOwn = Object.prototype.hasOwnProperty.bind(this.listeners);\n\n        for (let messageName in this.listeners) {\n          if (hasOwn(messageName)) {\n            const callbacks = this.listeners[messageName] || [];\n            for (let i = 0; i < callbacks.length; i++) {\n              const callback = callbacks[i];\n              emitter.off(messageName, callback);\n              emitter.off(`${messageName}${DIRECT_EMIT_FLAG}${tag}`, callback);\n            }\n          }\n        }\n\n        for (let messageName in this.onceListeners) {\n          if (hasOwn(messageName)) {\n            const callbacks = this.onceListeners[messageName] || [];\n            for (let i = 0; i < callbacks.length; i++) {\n              const callback = callbacks[i];\n              emitter.off(messageName, callback);\n              emitter.off(`${messageName}${DIRECT_EMIT_FLAG}${tag}`, callback);\n            }\n          }\n        }\n      }\n\n      /**\n       * 在组件销毁时，默认将它注册的事件全部卸载，确保不会造成内存泄漏\n       */\n      destroy() {\n        // step1 unlisten events\n        this.removeListeners();\n\n        // step2 release from context\n        delete self._instanceMap[tag];\n        if (super.destroy) {\n          super.destroy();\n        }\n      }\n    };\n    this._clsMap[tag] = enhanced;\n\n    /**\n     * get instance immediately\n     * e.g const instance = context.registry(tag, Cls)(config)\n     * */\n    return (...args) => {\n      return this.initInstance(tag, ...args);\n    };\n  }\n\n  /**\n   * 对存在的实例进行\n   */\n  destroyInstances() {\n    Object.keys(this._instanceMap).forEach(tag => {\n      if (this._instanceMap[tag].destroy) {\n        this._instanceMap[tag].destroy();\n      }\n    });\n  }\n\n  /**\n   * 编解码流程无需关注事件的解绑\n   */\n  destroy() {\n    this._emitter = null;\n    this.allowedEvents = [];\n    this._clsMap = null;\n    this._context = null;\n    this.destroyInstances();\n  }\n\n  /**\n   * 对信道进行收拢\n   * @param messageName\n   * @private\n   */\n  _isMessageNameValid(messageName) {\n    if (!this.allowedEvents.indexOf(messageName) < 0) {\n      throw new Error(`unregistered message name: ${messageName}`);\n    }\n  }\n}\n\nexports.default = Context;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/context.js?')},"../xgplayer-utils/src/env/isle.js":
/*!*****************************************!*\
  !*** ../xgplayer-utils/src/env/isle.js ***!
  \*****************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\nconst le = function () {\n  const buf = new ArrayBuffer(2);\n  new DataView(buf).setInt16(0, 256, true); // little-endian write\n  return new Int16Array(buf)[0] === 256; // platform-spec read, if equal then LE\n}();\n\nexports.default = le;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/env/isle.js?')},"../xgplayer-utils/src/env/sniffer.js":
/*!********************************************!*\
  !*** ../xgplayer-utils/src/env/sniffer.js ***!
  \********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nconst le = function () {\n  const buf = new ArrayBuffer(2);\n  new DataView(buf).setInt16(0, 256, true); // little-endian write\n  return new Int16Array(buf)[0] === 256; // platform-spec read, if equal then LE\n}();\n\nconst sniffer = {\n  get device() {\n    let r = sniffer.os;\n    return r.isPc ? 'pc' : r.isTablet ? 'tablet' : 'mobile';\n  },\n  get browser() {\n    let ua = navigator.userAgent.toLowerCase();\n    let reg = {\n      ie: /rv:([\\d.]+)\\) like gecko/,\n      firfox: /firefox\\/([\\d.]+)/,\n      chrome: /chrome\\/([\\d.]+)/,\n      opera: /opera.([\\d.]+)/,\n      safari: /version\\/([\\d.]+).*safari/\n    };\n    return [].concat(Object.keys(reg).filter(key => reg[key].test(ua)))[0];\n  },\n  get os() {\n    let ua = navigator.userAgent;\n    let isWindowsPhone = /(?:Windows Phone)/.test(ua);\n    let isSymbian = /(?:SymbianOS)/.test(ua) || isWindowsPhone;\n    let isAndroid = /(?:Android)/.test(ua);\n    let isFireFox = /(?:Firefox)/.test(ua);\n    let isTablet = /(?:iPad|PlayBook)/.test(ua) || isAndroid && !/(?:Mobile)/.test(ua) || isFireFox && /(?:Tablet)/.test(ua);\n    let isPhone = /(?:iPhone)/.test(ua) && !isTablet;\n    let isPc = !isPhone && !isAndroid && !isSymbian;\n    return {\n      isTablet,\n      isPhone,\n      isAndroid,\n      isPc,\n      isSymbian,\n      isWindowsPhone,\n      isFireFox\n    };\n  },\n\n  get isLe() {\n    return le;\n  }\n};\n\nexports.default = sniffer;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/env/sniffer.js?")},"../xgplayer-utils/src/env/utf8.js":
/*!*****************************************!*\
  !*** ../xgplayer-utils/src/env/utf8.js ***!
  \*****************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass UTF8 {\n  static decode(uint8array) {\n    const out = [];\n    const input = uint8array;\n    let i = 0;\n    const length = uint8array.length;\n\n    while (i < length) {\n      if (input[i] < 0x80) {\n        out.push(String.fromCharCode(input[i]));\n        ++i;\n        continue;\n      } else if (input[i] < 0xC0) {\n        // fallthrough\n      } else if (input[i] < 0xE0) {\n        if (UTF8._checkContinuation(input, i, 1)) {\n          const ucs4 = (input[i] & 0x1F) << 6 | input[i + 1] & 0x3F;\n          if (ucs4 >= 0x80) {\n            out.push(String.fromCharCode(ucs4 & 0xFFFF));\n            i += 2;\n            continue;\n          }\n        }\n      } else if (input[i] < 0xF0) {\n        if (UTF8._checkContinuation(input, i, 2)) {\n          const ucs4 = (input[i] & 0xF) << 12 | (input[i + 1] & 0x3F) << 6 | input[i + 2] & 0x3F;\n          if (ucs4 >= 0x800 && (ucs4 & 0xF800) !== 0xD800) {\n            out.push(String.fromCharCode(ucs4 & 0xFFFF));\n            i += 3;\n            continue;\n          }\n        }\n      } else if (input[i] < 0xF8) {\n        if (UTF8._checkContinuation(input, i, 3)) {\n          let ucs4 = (input[i] & 0x7) << 18 | (input[i + 1] & 0x3F) << 12 | (input[i + 2] & 0x3F) << 6 | input[i + 3] & 0x3F;\n          if (ucs4 > 0x10000 && ucs4 < 0x110000) {\n            ucs4 -= 0x10000;\n            out.push(String.fromCharCode(ucs4 >>> 10 | 0xD800));\n            out.push(String.fromCharCode(ucs4 & 0x3FF | 0xDC00));\n            i += 4;\n            continue;\n          }\n        }\n      }\n      out.push(String.fromCharCode(0xFFFD));\n      ++i;\n    }\n\n    return out.join('');\n  }\n\n  static _checkContinuation(uint8array, start, checkLength) {\n    let array = uint8array;\n    if (start + checkLength < array.length) {\n      while (checkLength--) {\n        if ((array[++start] & 0xC0) !== 0x80) {\n          return false;\n        }\n      }\n      return true;\n    } else {\n      return false;\n    }\n  }\n}\n\nexports.default = UTF8;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/env/utf8.js?")},"../xgplayer-utils/src/mobile/audio-context.js":
/*!*****************************************************!*\
  !*** ../xgplayer-utils/src/mobile/audio-context.js ***!
  \*****************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\nclass AudioCtx {\n  constructor(config) {\n    this.config = Object.assign({}, config);\n    let AudioContext = window.AudioContext || window.webkitAudioContext;\n    this.context = new AudioContext();\n    this.gainNode = this.context.createGain();\n    this.gainNode.connect(this.context.destination);\n    this.meta = undefined;\n    this.samples = [];\n    this.preloadTime = this.config.preloadTime || 3;\n    this.duration = 0;\n\n    this._currentBuffer = undefined;\n    this._nextBuffer = undefined;\n    this._lastpts = undefined;\n    this._preDecode = [];\n    this._currentTime = 0;\n    this._decoding = false;\n    // 记录外部传输的状态\n    this._played = false;\n  }\n\n  get currentTime() {\n    return this._currentTime;\n  }\n\n  decodeAudio(audioTrack) {\n    let { samples } = audioTrack;\n    let data = samples;\n    audioTrack.samples = [];\n    this.setAudioData(data);\n  }\n  setAudioData(data) {\n    for (let i = 0; i < data.length; i++) {\n      data[i].pts = data[i].pts === undefined ? data[i].dts : data[i].pts;\n      this._preDecode.push(data[i]);\n    }\n    if (this._preDecode.length > 0) {\n      if (this._lastpts === undefined) {\n        this._lastpts = this._preDecode[0].pts;\n      }\n      if ((this._preDecode[this._preDecode.length - 1].pts - this._lastpts) / 1000 > this.preloadTime) {\n        this.decodeAAC();\n      }\n    }\n  }\n\n  decodeAAC() {\n    if (this._decoding) {\n      return;\n    }\n    this._decoding = true;\n    let data = this._preDecode;\n    let samples = [];\n    let _this = this;\n    let sample = data.shift();\n    while (sample) {\n      let sampleData = AudioCtx.getAACData(this.meta, sample);\n      samples.push(sampleData);\n      this._lastpts = sample.pts;\n      sample = data.shift();\n    }\n    let buffer = AudioCtx.combileData(samples);\n    try {\n      this.context.decodeAudioData(buffer.buffer, function (buffer) {\n        let audioSource = _this.context.createBufferSource();\n        audioSource.buffer = buffer;\n        audioSource.onended = _this.onSourceEnded.bind(_this);\n        _this.samples.push({\n          time: _this.duration,\n          duration: buffer.duration,\n          data: audioSource\n        });\n\n        _this.duration += buffer.duration;\n\n        if (!_this._currentBuffer) {\n          _this._currentBuffer = _this.getTimeBuffer(_this.currentTime);\n\n          if (_this._played) {\n            _this.play();\n          }\n        }\n\n        if (!_this._nextBuffer && _this._currentBuffer) {\n          _this._nextBuffer = _this.getTimeBuffer(_this.currentTime + _this._currentBuffer.duration);\n        }\n        _this._decoding = false;\n\n        if ((_this._preDecode.length > 0 && _this._preDecode[_this._preDecode.length - 1].pts - _this._lastpts) / 1000 >= _this.preloadTime) {\n          _this.decodeAAC();\n        }\n      });\n    } catch (err) {\n      console.error(err);\n    }\n  }\n\n  onSourceEnded() {\n    if (!this._nextBuffer || !this._played) {\n      return;\n    }\n    let audioSource = this._nextBuffer.data;\n    audioSource.start();\n    audioSource.connect(this.gainNode);\n    this._currentBuffer = this._nextBuffer;\n    this._currentTime = this._currentBuffer.time;\n    this._nextBuffer = this.getTimeBuffer(this.currentTime);\n    if (this._currentBuffer) {\n      this._nextBuffer = this.getTimeBuffer(this.currentTime + this._currentBuffer.duration);\n    }\n  }\n\n  play() {\n    this._played = true;\n    if (!this._currentBuffer) {\n      return;\n    }\n    let audioSource = this._currentBuffer.data;\n    audioSource.connect(this.gainNode);\n    audioSource.start();\n  }\n\n  getTimeBuffer(time) {\n    let ret;\n    for (let i = 0; i < this.samples.length; i++) {\n      let sample = this.samples[i];\n      if (sample.time <= time && sample.time + sample.duration > time) {\n        ret = sample;\n        break;\n      }\n    }\n    return ret;\n  }\n\n  setAudioMetaData(meta) {\n    this.meta = meta;\n  }\n\n  static getAACData(meta, sample) {\n    let buffer = new Uint8Array(sample.data.byteLength + 7);\n    let adts = AudioCtx.getAdts(meta, sample.data);\n    buffer.set(adts);\n    buffer.set(sample.data, 7);\n    return buffer;\n  }\n\n  static combileData(samples) {\n    // get length\n    let length = 0;\n    for (let i = 0, k = samples.length; i < k; i++) {\n      length += samples[i].byteLength;\n    }\n\n    let ret = new Uint8Array(length);\n    let offset = 0;\n    // combile data;\n    for (let i = 0, k = samples.length; i < k; i++) {\n      ret.set(samples[i], offset);\n      offset += samples[i].byteLength;\n    }\n    return ret;\n  }\n\n  static getAdts(meta, data) {\n    let adts = new Uint8Array(7);\n\n    // 设置同步位 0xfff 12bit\n    adts[0] = 0xff;\n    adts[1] = 0xf0;\n\n    // Object data (没什么人用MPEG-2了，HLS和FLV也全是MPEG-4，这里直接0)  1bit\n    // Level always 00 2bit\n    // CRC always 1 1bit\n    adts[1] = adts[1] | 0x01;\n\n    // profile 2bit\n    adts[2] = 0xc0 & meta.objectType - 1 << 6;\n\n    //sampleFrequencyIndex\n    adts[2] = adts[2] | 0x3c & meta.sampleRateIndex << 2;\n\n    //private bit 0 1bit\n    // chanel configuration 3bit\n    adts[2] = adts[2] | 0x01 & meta.channelCount >> 2;\n    adts[3] = 0xc0 & meta.channelCount << 6;\n\n    // original_copy: 0 1bit\n    // home: 0 1bit\n\n    // adts_variable_header()\n    // copyrighted_id_bit 0 1bit\n    // copyrighted_id_start 0 1bit\n\n    // aac_frame_length 13bit;\n    let aacframelength = data.byteLength + 7;\n\n    adts[3] = adts[3] | 0x03 & aacframelength >> 11;\n    adts[4] = 0xff & aacframelength >> 3;\n    adts[5] = 0xe0 & aacframelength << 5;\n\n    // adts_buffer_fullness 0x7ff 11bit\n    adts[5] = adts[5] | 0x1f;\n    adts[6] = 0xfc;\n\n    // number_of_raw_data_blocks_in_frame 0 2bit;\n    return adts;\n  }\n}\n\nexports.default = AudioCtx;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/mobile/audio-context.js?')},"../xgplayer-utils/src/mobile/mobile-video.js":
/*!****************************************************!*\
  !*** ../xgplayer-utils/src/mobile/mobile-video.js ***!
  \****************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nvar _videoContext = __webpack_require__(/*! ./video-context */ "../xgplayer-utils/src/mobile/video-context.js");\n\nvar _videoContext2 = _interopRequireDefault(_videoContext);\n\nvar _audioContext = __webpack_require__(/*! ./audio-context */ "../xgplayer-utils/src/mobile/audio-context.js");\n\nvar _audioContext2 = _interopRequireDefault(_audioContext);\n\nvar _ticker = __webpack_require__(/*! ./ticker */ "../xgplayer-utils/src/mobile/ticker.js");\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * 音画同步调和器\n */\nclass AVReconciler {\n  constructor(props) {\n    this.aCtx = props.aCtx;\n    this.vCtx = props.vCtx;\n\n    this.timeoutId = null;\n  }\n\n  doReconcile() {\n    const vCurTime = this.vCtx.currentTime || 0;\n    const aCurTime = (this.aCtx.currentTime || 0) * 1000;\n\n    const gap = vCurTime - aCurTime;\n    if (this.timeoutId) {\n      return;\n    }\n    if (gap > 2000) {// audio delayed for more than 100ms\n      // this.vCtx.pause()\n      // this.timeoutId = setTimeout(() => {\n      //   this.vCtx.play()\n      //   this.timeoutId = null\n      // }, gap)\n    } else if (gap < -200) {\n      this.vCtx.currentTime = this.vCtx.currentTime + Math.abs(gap);\n    }\n  }\n\n  destroy() {\n    this.aCtx = null;\n    this.vCtx = null;\n  }\n}\n\n// eslint-disable-next-line no-undef\nclass MobileVideo extends HTMLElement {\n  constructor(config) {\n    super();\n    let _this = this;\n    this.vCtx = new _videoContext2.default();\n    this.aCtx = new _audioContext2.default(config);\n    this.ticker = new ((0, _ticker.getTicker)())();\n    this.historyTime = 0;\n    this.reconciler = new AVReconciler({\n      vCtx: this.vCtx,\n      aCtx: this.aCtx\n    });\n\n    this.init();\n  }\n\n  init() {\n    this.vCtx.oncanplay = () => {\n      this.appendChild(this.vCtx.canvas);\n      // eslint-disable-next-line no-undef\n      this.dispatchEvent(new Event(\'canplay\'));\n    };\n\n    this.ticker.start(() => {\n      // this.reconciler.doReconcile()\n      console.log(this.aCtx.currentTime);\n    });\n  }\n\n  destroy() {\n    this.reconciler.destroy();\n  }\n\n  onDemuxComplete(videoTrack, audioTrack) {\n    this.aCtx.decodeAudio(audioTrack);\n    this.vCtx.decodeVideo(videoTrack);\n  }\n\n  setAudioMeta(meta) {\n    this.aCtx.setAudioMetaData(meta);\n  }\n\n  setVideoMeta(meta) {\n    this.vCtx.setVideoMetaData(meta);\n  }\n\n  get currentTime() {}\n\n  play() {\n    // if (!this.vCtx.)\n    this.vCtx.play();\n    this.aCtx.play();\n  }\n}\n// eslint-disable-next-line no-undef\ncustomElements.define(\'mobile-video\', MobileVideo);\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/mobile/mobile-video.js?')},"../xgplayer-utils/src/mobile/sourcebuffer.js":
/*!****************************************************!*\
  !*** ../xgplayer-utils/src/mobile/sourcebuffer.js ***!
  \****************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass SourceBuffer {\n  constructor(config) {\n    this.config = Object.assign({}, config);\n    this.type = this.config.type;\n    this.buffer = [];\n    this.currentGop = undefined;\n    this._lastGet = undefined;\n  }\n\n  push(frame) {\n    if (this.type === 'video') {\n      if (frame.isKeyframe) {\n        let currentGop = {\n          samples: [],\n          start: frame.dts,\n          end: frame.dts,\n          nextGop: undefined\n        };\n        if (this.currentGop) {\n          this.currentGop.nextGop = currentGop;\n        }\n        this.currentGop = currentGop;\n        this.buffer.push(this.currentGop);\n      }\n\n      if (this.currentGop) {\n        this.currentGop.samples.push(frame);\n\n        if (frame.dts < this.currentGop.start) {\n          this.currentGop.start = frame.dts;\n        }\n\n        if (frame.dts > this.currentGop.end) {\n          this.currentGop.end = frame.dts;\n        }\n      }\n    }\n  }\n\n  get(time) {\n    if (this.type === 'video') {\n      if (this.buffer.length < 1) {\n        return;\n      }\n\n      if (time === undefined) {\n        let sample = this._getNext();\n        return sample;\n      }\n    }\n  }\n\n  _getNext() {\n    if (!this._lastGet) {\n      let gop = this.buffer[0];\n      if (gop.samples.length < 1) {\n        return;\n      }\n\n      this._lastGet = {\n        gop,\n        index: 0\n      };\n      return gop.samples[0];\n    } else {\n      let gop = this._lastGet.gop;\n      let sample = gop.samples[this._lastGet.index + 1];\n      if (sample) {\n        this._lastGet.index = this._lastGet.index + 1;\n        return sample;\n      } else {\n        gop = gop.nextGop;\n        if (!gop || gop.samples.length < 1) {\n          return;\n        }\n        sample = gop.samples[0];\n        this._lastGet = {\n          gop,\n          index: 0\n        };\n        return sample;\n      }\n    }\n  }\n\n  remove(start, end) {\n    if (this.buffer.length < 0) {\n      return;\n    }\n\n    let i = 0;\n    let gop = this.buffer[0];\n    while (gop) {\n      if (gop.end < end && gop.start >= start) {\n        delete this.buffer[i];\n        gop = this.buffer[i];\n      } else {\n        i += 1;\n        gop = this.buffer[i];\n      }\n    }\n  }\n}\n\nexports.default = SourceBuffer;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/mobile/sourcebuffer.js?")},"../xgplayer-utils/src/mobile/ticker.js":
/*!**********************************************!*\
  !*** ../xgplayer-utils/src/mobile/ticker.js ***!
  \**********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\n/**\n * @author fuyuhao@bytedance.com\n */\n\nclass Ticker {\n  constructor(options) {\n    this.options = Object.assign({}, options || {}, {\n      interval: 16\n    });\n\n    this.callbacks = [];\n  }\n\n  start(...callbacks) {\n    this.callbacks = callbacks;\n  }\n\n  onTick() {\n    for (let i = 0, len = this.callbacks.length; i < len; i++) {\n      const callback = this.callbacks[i];\n      callback();\n    }\n  }\n\n  setInterval(interval) {\n    this.options.interval = interval;\n    return this;\n  }\n}\n\n/**\n * ticker use requestAnimationFrame\n */\nclass RafTicker extends Ticker {\n  constructor(props) {\n    super(props);\n    this.prev = null;\n    this.timerId = null;\n    this._subTimerId = null;\n\n    this._tickFunc = RafTicker.getTickFunc();\n    this.tick = this.tick.bind(this);\n  }\n\n  start(...callbacks) {\n    super.start(...callbacks);\n    this.tick();\n  }\n\n  tick(timestamp) {\n    console.log(timestamp);\n    this.nextTick();\n    this.onTick();\n  }\n\n  nextTick() {\n    const { _tickFunc } = this;\n    this.timerId = _tickFunc(this.tick);\n  }\n\n  stop() {\n    if (this.timerId) {\n      const cancelFunc = RafTicker.getCancelFunc();\n\n      cancelFunc(this.timerId);\n    }\n  }\n\n  static getTickFunc() {\n    return window.requestAnimationFrame || window.webkitRequestAnimationFrame;\n  }\n\n  static getCancelFunc() {\n    return window.cancelAnimationFrame || window.webkitCancelAnimationFrame;\n  }\n\n  static isSupported() {\n    return RafTicker.getTickFunc() !== undefined;\n  }\n}\n\n/**\n * use setTimeout for browsers without raf support\n */\nclass TimeoutTicker extends Ticker {\n  constructor(config) {\n    super(config);\n    this.timeoutId = null;\n  }\n\n  start(...callbacks) {\n    super.nextTick(...callbacks);\n    this.timeoutId = window.setInterval(() => {\n      this.onTick();\n    }, this.options.interval || 16);\n  }\n\n  stop() {\n    if (this.timeoutId) {\n      window.clearInterval(this.timeoutId);\n    }\n  }\n\n}\n\n/**\n * 返回Ticker构造函数\n * @returns {Ticker}\n */\nconst getTicker = exports.getTicker = () => {\n  if (RafTicker.isSupported()) {\n    return RafTicker;\n  } else {\n    return TimeoutTicker;\n  }\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/mobile/ticker.js?')},"../xgplayer-utils/src/mobile/video-context.js":
/*!*****************************************************!*\
  !*** ../xgplayer-utils/src/mobile/video-context.js ***!
  \*****************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _webworkifyWebpack = __webpack_require__(/*! webworkify-webpack */ \"../xgplayer-utils/node_modules/webworkify-webpack/index.js\");\n\nvar _webworkifyWebpack2 = _interopRequireDefault(_webworkifyWebpack);\n\nvar _stream = __webpack_require__(/*! ../write/stream */ \"../xgplayer-utils/src/write/stream.js\");\n\nvar _stream2 = _interopRequireDefault(_stream);\n\nvar _nalunit = __webpack_require__(/*! ../../../xgplayer-codec/src/h264/nalunit */ \"../xgplayer-codec/src/h264/nalunit/index.js\");\n\nvar _nalunit2 = _interopRequireDefault(_nalunit);\n\nvar _yuvCanvas = __webpack_require__(/*! ./yuv-canvas */ \"../xgplayer-utils/src/mobile/yuv-canvas.js\");\n\nvar _yuvCanvas2 = _interopRequireDefault(_yuvCanvas);\n\nvar _sourcebuffer = __webpack_require__(/*! ./sourcebuffer */ \"../xgplayer-utils/src/mobile/sourcebuffer.js\");\n\nvar _sourcebuffer2 = _interopRequireDefault(_sourcebuffer);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nclass VideoCanvas {\n  constructor(config) {\n    this.config = Object.assign({}, config);\n    this.canvas = this.config.canvas ? this.config.canvas : document.createElement('canvas');\n    this.source = new _sourcebuffer2.default({ type: 'video' });\n    this.preloadTime = this.config.preloadTime || 3;\n    this.oncanplay = undefined;\n    this.onFirstFrame = undefined;\n    this.meta = undefined;\n    this.readyStatus = 0;\n    this.paused = true;\n    this.count = 0;\n    this.currentTime = 0;\n    this.lastPlayed = 0;\n\n    this._decoderInited = false;\n    this._avccpushed = false;\n    this._decodedFrames = {};\n    this._lastSampleDts = undefined;\n    this._baseDts = undefined;\n    this.initWasmWorker();\n  }\n\n  initWasmWorker() {\n    let _this = this;\n    this.wasmworker = (0, _webworkifyWebpack2.default)(/*require.resolve*/(/*! ./worker.js */ \"../xgplayer-utils/src/mobile/worker.js\"));\n    this.wasmworker.postMessage({\n      msg: 'init'\n    });\n    this.wasmworker.addEventListener('message', msg => {\n      switch (msg.data.msg) {\n        case 'DECODER_READY':\n          _this._decoderInited = true;\n          break;\n        case 'DECODED':\n          this._onDecoded(msg.data);\n          break;\n      }\n    });\n  }\n\n  setVideoMetaData(meta) {\n    this.meta = meta;\n    if (!this._decoderInited) {\n      return;\n    }\n    this._avccpushed = true;\n    let data = new Uint8Array(meta.sps.byteLength + 4);\n    data.set([0, 0, 0, 1]);\n    data.set(meta.sps, 4);\n    this.wasmworker.postMessage({\n      msg: 'decode',\n      data: data\n    });\n\n    data = new Uint8Array(meta.pps.byteLength + 4);\n    data.set([0, 0, 0, 1]);\n    data.set(meta.pps, 4);\n    this.wasmworker.postMessage({\n      msg: 'decode',\n      data: data\n    });\n\n    if (!this.yuvCanvas) {\n      let config = Object.assign({ meta, canvas: this.canvas }, this.config);\n      this.yuvCanvas = new _yuvCanvas2.default(config);\n    }\n    this.readyStatus = 1;\n  }\n\n  decodeVideo(videoTrack) {\n    if (!this._decoderInited) {\n      return;\n    }\n\n    if (!this._avccpushed) {\n      this.setVideoMetaData(this.meta);\n    }\n    let { samples } = videoTrack;\n    let sample = samples.shift();\n\n    while (sample) {\n      if (!this._baseDts) {\n        this._baseDts = sample.dts;\n      }\n      this.source.push(sample);\n      sample = samples.shift();\n    }\n\n    this._preload();\n  }\n\n  _preload() {\n    if (!this._lastSampleDts || this._lastSampleDts - this._baseDts < this.currentTime + this.preloadTime * 1000) {\n      let sample = this.source.get();\n      if (sample) {\n        this._lastSampleDts = sample.dts;\n        this._analyseNal(sample);\n      }\n\n      while (sample && this._lastSampleDts - this._baseDts < this.currentTime + this.preloadTime * 1000) {\n        sample = this.source.get();\n        if (sample) {\n          this._analyseNal(sample);\n          this._lastSampleDts = sample.dts;\n        }\n      }\n    }\n  }\n\n  _analyseNal(sample) {\n    let nals = _nalunit2.default.getAvccNals(new _stream2.default(sample.data.buffer));\n\n    let length = 0;\n    for (let i = 0; i < nals.length; i++) {\n      let nal = nals[i];\n      length += nal.body.byteLength + 4;\n    }\n    let offset = 0;\n    let data = new Uint8Array(length);\n    for (let i = 0; i < nals.length; i++) {\n      let nal = nals[i];\n      data.set([0, 0, 0, 1], offset);\n      offset += 4;\n      data.set(new Uint8Array(nal.body), offset);\n      offset += nal.body.byteLength;\n    }\n    this.wasmworker.postMessage({\n      msg: 'decode',\n      data: data,\n      info: {\n        dts: sample.dts,\n        pts: sample.pts ? sample.pts : sample.dts + sample.cts,\n        key: sample.isKeyframe\n      }\n    });\n  }\n\n  _onDecoded(data) {\n    let { dts } = data.info;\n    this._decodedFrames[dts] = data;\n  }\n\n  play() {\n    this.paused = false;\n    this._onTimer();\n  }\n\n  _onTimer() {\n    let renderCost = 0;\n    const renderStart = Date.now();\n    if (this.paused) {\n      return;\n    }\n    let nextTime = 1000 / 60;\n    if (this.meta) {\n      if (this.meta.frameRate && this.meta.frameRate.fixed && this.meta.frameRate.fps) {\n        nextTime = Math.ceil(1000 / this.meta.frameRate.fps);\n      }\n      let frameTimes = Object.keys(this._decodedFrames);\n      if (frameTimes.length > 0) {\n        this.currentTime += nextTime;\n        let frameTime = -1;\n        for (let i = 0; i < frameTimes.length && frameTimes[i] - this._baseDts <= this.currentTime; i++) {\n          frameTime = frameTimes[i];\n          break;\n        }\n        let frame = this._decodedFrames[frameTime];\n        if (frame) {\n          if (this.oncanplay && this.readyStatus < 4) {\n            this.oncanplay();\n            this.readyStatus = 4;\n          }\n          console.log('video time', this.currentTime);\n          this.yuvCanvas.render(frame.buffer, frame.width, frame.height);\n          renderCost = Date.now() - renderStart;\n          delete this._decodedFrames[frameTime];\n        }\n      }\n    }\n    this._cleanBuffer();\n    setTimeout(this._onTimer.bind(this), nextTime - renderCost);\n  }\n\n  _cleanBuffer() {\n    this.source.remove(0, this.currentTime);\n  }\n}\nexports.default = VideoCanvas;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/mobile/video-context.js?")},"../xgplayer-utils/src/mobile/worker.js":
/*!**********************************************!*\
  !*** ../xgplayer-utils/src/mobile/worker.js ***!
  \**********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nconst MAX_STREAM_BUFFER_LENGTH = 1024 * 1024;\nvar Decoder = function (self) {\n  this.inited = false;\n  this.self = self;\n  this.infolist = {};\n  self.par_broadwayOnBroadwayInited = this.broadwayOnBroadwayInited.bind(this);\n  self.par_broadwayOnPictureDecoded = this.broadwayOnPictureDecoded.bind(this);\n};\n\nDecoder.prototype.toU8Array = function (ptr, length) {\n  return this.self.HEAPU8.subarray(ptr, ptr + length);\n};\n\nDecoder.prototype.init = function () {\n  Module._broadwayInit();\n  this.streamBuffer = this.toU8Array(Module._broadwayCreateStream(MAX_STREAM_BUFFER_LENGTH), MAX_STREAM_BUFFER_LENGTH);\n};\n\nDecoder.prototype.broadwayOnPictureDecoded = function (offset, width, height, infoid) {\n  let info = Object.assign({}, this.infolist[infoid]);\n  let data = this.toU8Array(offset, width * height * 3 / 2);\n  this.infolist[infoid] = null;\n  let datetemp = new Uint8Array(data.length);\n  datetemp.set(data);\n  let buffer = datetemp.buffer;\n  this.self.postMessage({\n    msg: 'DECODED',\n    width,\n    height,\n    info,\n    buffer\n  }, [buffer]);\n};\n\nDecoder.prototype.broadwayOnBroadwayInited = function () {\n  this.inited = true;\n  this.self.postMessage({ msg: 'DECODER_READY' });\n};\n\nDecoder.prototype.decode = function (data, info) {\n  let time = parseInt(new Date().getTime());\n  let infoid = time - Math.floor(time / 10e8) * 10e8;\n  this.infolist[infoid] = info;\n  this.streamBuffer.set(data);\n  Module._broadwayPlayStream(data.length, infoid);\n};\n\nvar decoder;\n\nfunction onPostRun() {\n  decoder = new Decoder(this);\n  decoder.init();\n}\n\nfunction init() {\n  self.importScripts('http://10.95.45.202:9090/examples/flv/decoder.js');\n  addOnPostRun(onPostRun.bind(self));\n}\n\nmodule.exports = function (self) {\n  self.addEventListener('message', function (e) {\n    var data = e.data;\n    if (!data.msg) {\n      self.postMessage({\n        msg: 'ERROR:invalid message'\n      });\n    } else {\n      switch (data.msg) {\n        case 'init':\n          init(self);\n          break;\n        case 'decode':\n          decoder.decode(data.data, data.info);\n          break;\n        default:\n          break;\n      }\n    }\n  }, false);\n};\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/mobile/worker.js?")},"../xgplayer-utils/src/mobile/yuv-canvas.js":
/*!**************************************************!*\
  !*** ../xgplayer-utils/src/mobile/yuv-canvas.js ***!
  \**************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass YUVCanvas {\n  constructor(configs) {\n    this.configs = Object.assign({}, configs);\n    this.canvas = this.configs.canvas;\n    this.meta = Object.assign({}, this.configs.meta);\n    this.chroma = this.meta.chromaFormat;\n    this.height = this.meta.presentHeight;\n    this.width = this.meta.presentWidth;\n    this.canvas.width = this.width;\n    this.canvas.height = this.height;\n    this.canvas.style.width = '100%';\n    this.canvas.style.height = '100%';\n    this._initContextGL();\n    if (this.contextGL) {\n      this._initProgram();\n      this._initBuffers();\n      this._initTextures();\n    };\n  }\n\n  _initContextGL() {\n    var canvas = this.canvas;\n    var gl = null;\n\n    var validContextNames = ['webgl', 'experimental-webgl', 'moz-webgl', 'webkit-3d'];\n    var nameIndex = 0;\n\n    while (!gl && nameIndex < validContextNames.length) {\n      var contextName = validContextNames[nameIndex];\n\n      try {\n        if (this.contextOptions) {\n          gl = canvas.getContext(contextName, this.contextOptions);\n        } else {\n          gl = canvas.getContext(contextName);\n        };\n      } catch (e) {\n        gl = null;\n      }\n\n      if (!gl || typeof gl.getParameter !== 'function') {\n        gl = null;\n      }\n\n      ++nameIndex;\n    };\n\n    this.contextGL = gl;\n  }\n\n  _initProgram() {\n    var gl = this.contextGL;\n\n    // vertex shader is the same for all types\n    var vertexShaderScript;\n    var fragmentShaderScript;\n    if (this.chroma === 420) {\n      vertexShaderScript = ['attribute vec4 vertexPos;', 'attribute vec4 texturePos;', 'attribute vec4 uTexturePos;', 'attribute vec4 vTexturePos;', 'varying vec2 textureCoord;', 'varying vec2 uTextureCoord;', 'varying vec2 vTextureCoord;', 'void main()', '{', '  gl_Position = vertexPos;', '  textureCoord = texturePos.xy;', '  uTextureCoord = uTexturePos.xy;', '  vTextureCoord = vTexturePos.xy;', '}'].join('\\n');\n\n      fragmentShaderScript = ['precision highp float;', 'varying highp vec2 textureCoord;', 'varying highp vec2 uTextureCoord;', 'varying highp vec2 vTextureCoord;', 'uniform sampler2D ySampler;', 'uniform sampler2D uSampler;', 'uniform sampler2D vSampler;', 'uniform mat4 YUV2RGB;', 'void main(void) {', '  highp float y = texture2D(ySampler,  textureCoord).r;', '  highp float u = texture2D(uSampler,  uTextureCoord).r;', '  highp float v = texture2D(vSampler,  vTextureCoord).r;', '  gl_FragColor = vec4(y, u, v, 1) * YUV2RGB;', '}'].join('\\n');\n    } else if (this.chroma === 422) {\n      vertexShaderScript = ['attribute vec4 vertexPos;', 'attribute vec4 texturePos;', 'varying vec2 textureCoord;', 'void main()', '{', '  gl_Position = vertexPos;', '  textureCoord = texturePos.xy;', '}'].join('\\n');\n\n      fragmentShaderScript = ['precision highp float;', 'varying highp vec2 textureCoord;', 'uniform sampler2D sampler;', 'uniform highp vec2 resolution;', 'uniform mat4 YUV2RGB;', 'void main(void) {', '  highp float texPixX = 1.0 / resolution.x;', '  highp float logPixX = 2.0 / resolution.x;', // half the resolution of the texture\n      '  highp float logHalfPixX = 4.0 / resolution.x;', // half of the logical resolution so every 4th pixel\n      '  highp float steps = floor(textureCoord.x / logPixX);', '  highp float uvSteps = floor(textureCoord.x / logHalfPixX);', '  highp float y = texture2D(sampler, vec2((logPixX * steps) + texPixX, textureCoord.y)).r;', '  highp float u = texture2D(sampler, vec2((logHalfPixX * uvSteps), textureCoord.y)).r;', '  highp float v = texture2D(sampler, vec2((logHalfPixX * uvSteps) + texPixX + texPixX, textureCoord.y)).r;',\n\n      // '  highp float y = texture2D(sampler,  textureCoord).r;',\n      // '  gl_FragColor = vec4(y, u, v, 1) * YUV2RGB;',\n      '  gl_FragColor = vec4(y, u, v, 1.0) * YUV2RGB;', '}'].join('\\n');\n    };\n\n    var YUV2RGB = [1.16438, 0.00000, 1.59603, -0.87079, 1.16438, -0.39176, -0.81297, 0.52959, 1.16438, 2.01723, 0.00000, -1.08139, 0, 0, 0, 1];\n    var vertexShader = gl.createShader(gl.VERTEX_SHADER);\n    gl.shaderSource(vertexShader, vertexShaderScript);\n    gl.compileShader(vertexShader);\n    if (!gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS)) {\n      console.log('Vertex shader failed to compile: ' + gl.getShaderInfoLog(vertexShader));\n    }\n\n    var fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);\n    gl.shaderSource(fragmentShader, fragmentShaderScript);\n    gl.compileShader(fragmentShader);\n    if (!gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) {\n      console.log('Fragment shader failed to compile: ' + gl.getShaderInfoLog(fragmentShader));\n    }\n\n    var program = gl.createProgram();\n    gl.attachShader(program, vertexShader);\n    gl.attachShader(program, fragmentShader);\n    gl.linkProgram(program);\n    if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {\n      console.log('Program failed to compile: ' + gl.getProgramInfoLog(program));\n    }\n\n    gl.useProgram(program);\n\n    var YUV2RGBRef = gl.getUniformLocation(program, 'YUV2RGB');\n    gl.uniformMatrix4fv(YUV2RGBRef, false, YUV2RGB);\n\n    this.shaderProgram = program;\n  }\n\n  _initBuffers() {\n    var gl = this.contextGL;\n    var program = this.shaderProgram;\n\n    var vertexPosBuffer = gl.createBuffer();\n    gl.bindBuffer(gl.ARRAY_BUFFER, vertexPosBuffer);\n    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([1, 1, -1, 1, 1, -1, -1, -1]), gl.STATIC_DRAW);\n\n    var vertexPosRef = gl.getAttribLocation(program, 'vertexPos');\n    gl.enableVertexAttribArray(vertexPosRef);\n    gl.vertexAttribPointer(vertexPosRef, 2, gl.FLOAT, false, 0, 0);\n\n    var texturePosBuffer = gl.createBuffer();\n    gl.bindBuffer(gl.ARRAY_BUFFER, texturePosBuffer);\n    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([1, 0, 0, 0, 1, 1, 0, 1]), gl.STATIC_DRAW);\n\n    var texturePosRef = gl.getAttribLocation(program, 'texturePos');\n    gl.enableVertexAttribArray(texturePosRef);\n    gl.vertexAttribPointer(texturePosRef, 2, gl.FLOAT, false, 0, 0);\n\n    this.texturePosBuffer = texturePosBuffer;\n\n    if (this.chroma === 420) {\n      var uTexturePosBuffer = gl.createBuffer();\n      gl.bindBuffer(gl.ARRAY_BUFFER, uTexturePosBuffer);\n      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([1, 0, 0, 0, 1, 1, 0, 1]), gl.STATIC_DRAW);\n\n      var uTexturePosRef = gl.getAttribLocation(program, 'uTexturePos');\n      gl.enableVertexAttribArray(uTexturePosRef);\n      gl.vertexAttribPointer(uTexturePosRef, 2, gl.FLOAT, false, 0, 0);\n\n      this.uTexturePosBuffer = uTexturePosBuffer;\n\n      var vTexturePosBuffer = gl.createBuffer();\n      gl.bindBuffer(gl.ARRAY_BUFFER, vTexturePosBuffer);\n      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([1, 0, 0, 0, 1, 1, 0, 1]), gl.STATIC_DRAW);\n\n      var vTexturePosRef = gl.getAttribLocation(program, 'vTexturePos');\n      gl.enableVertexAttribArray(vTexturePosRef);\n      gl.vertexAttribPointer(vTexturePosRef, 2, gl.FLOAT, false, 0, 0);\n\n      this.vTexturePosBuffer = vTexturePosBuffer;\n    };\n  }\n\n  _initTextures() {\n    var gl = this.contextGL;\n    var program = this.shaderProgram;\n\n    if (this.chroma === 420) {\n      var yTextureRef = this._initTexture();\n      var ySamplerRef = gl.getUniformLocation(program, 'ySampler');\n      gl.uniform1i(ySamplerRef, 0);\n      this.yTextureRef = yTextureRef;\n\n      var uTextureRef = this._initTexture();\n      var uSamplerRef = gl.getUniformLocation(program, 'uSampler');\n      gl.uniform1i(uSamplerRef, 1);\n      this.uTextureRef = uTextureRef;\n\n      var vTextureRef = this._initTexture();\n      var vSamplerRef = gl.getUniformLocation(program, 'vSampler');\n      gl.uniform1i(vSamplerRef, 2);\n      this.vTextureRef = vTextureRef;\n    } else if (this.chroma === 422) {\n      // only one texture for 422\n      var textureRef = this._initTexture();\n      var samplerRef = gl.getUniformLocation(program, 'sampler');\n      gl.uniform1i(samplerRef, 0);\n      this.textureRef = textureRef;\n    };\n  }\n\n  _initTexture() {\n    var gl = this.contextGL;\n\n    var textureRef = gl.createTexture();\n    gl.bindTexture(gl.TEXTURE_2D, textureRef);\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n    gl.bindTexture(gl.TEXTURE_2D, null);\n\n    return textureRef;\n  }\n\n  _drawPictureGL(data, width, height) {\n    if (this.chroma === 420) {\n      let nWidth = width;\n      var ylen = width * height;\n      var uvlen = width / 2 * (height / 2);\n      data = new Uint8Array(data);\n      let renderData = {\n        yData: data.subarray(0, ylen),\n        uData: data.subarray(ylen, ylen + uvlen),\n        vData: data.subarray(ylen + uvlen, ylen + uvlen + uvlen)\n      };\n      if (width % 4 > 0) {\n        nWidth = width + 4 - width % 4;\n        let yArray = new Uint8Array(nWidth * height);\n        for (let i = 0; i < height; i++) {\n          yArray.set(renderData.yData.subarray(i * width, (i + 1) * width), i * nWidth);\n        }\n        renderData.yData = yArray;\n      }\n\n      if (width / 2 % 4 > 0) {\n        nWidth = width / 2 + 4 - width / 2 % 4;\n        let uArray = new Uint8Array(nWidth * height / 2);\n        let vArray = new Uint8Array(nWidth * height / 2);\n        for (let i = 0; i < height / 2; i++) {\n          uArray.set(renderData.uData.subarray(i * width / 2, (i + 1) * width / 2), i * nWidth);\n          vArray.set(renderData.vData.subarray(i * width / 2, (i + 1) * width / 2), i * nWidth);\n        }\n        renderData.uData = uArray;\n        renderData.vData = vArray;\n      }\n      this._drawPictureGL420(renderData, width, height);\n    } else if (this.chroma === 422) {\n      data = new Uint8Array(data);\n      this._drawPictureGL422(width, height, data);\n    }\n  }\n\n  _drawPictureGL422(data, width, height) {\n    var gl = this.contextGL;\n    var texturePosBuffer = this.texturePosBuffer;\n\n    var textureRef = this.textureRef;\n\n    var dataPerRow = width * 2;\n    var rowCnt = height;\n\n    gl.viewport(0, 0, width, height);\n\n    var tTop = 0;\n    var tLeft = 0;\n    var tBottom = height / rowCnt;\n    var tRight = width / (dataPerRow / 2);\n    var texturePosValues = new Float32Array([tRight, tTop, tLeft, tTop, tRight, tBottom, tLeft, tBottom]);\n\n    gl.bindBuffer(gl.ARRAY_BUFFER, texturePosBuffer);\n    gl.bufferData(gl.ARRAY_BUFFER, texturePosValues, gl.DYNAMIC_DRAW);\n\n    gl.uniform2f(gl.getUniformLocation(this.shaderProgram, 'resolution'), dataPerRow, height);\n\n    gl.activeTexture(gl.TEXTURE0);\n    gl.bindTexture(gl.TEXTURE_2D, textureRef);\n    gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, dataPerRow, rowCnt, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, data);\n\n    gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);\n  }\n\n  _drawPictureGL420(data, width, height) {\n    var gl = this.contextGL;\n    var texturePosBuffer = this.texturePosBuffer;\n    var uTexturePosBuffer = this.uTexturePosBuffer;\n    var vTexturePosBuffer = this.vTexturePosBuffer;\n\n    var yTextureRef = this.yTextureRef;\n    var uTextureRef = this.uTextureRef;\n    var vTextureRef = this.vTextureRef;\n\n    var yData = data.yData;\n    var uData = data.uData;\n    var vData = data.vData;\n\n    var yDataPerRow = width;\n    var yRowCnt = height;\n\n    var uDataPerRow = width / 2;\n    var uRowCnt = height / 2;\n\n    var vDataPerRow = uDataPerRow;\n    var vRowCnt = uRowCnt;\n    gl.viewport(0, 0, this.width, this.height);\n\n    var tTop = 0;\n    var tLeft = 0;\n    var tBottom = height / yRowCnt;\n    var tRight = width / yDataPerRow;\n    var texturePosValues = new Float32Array([tRight, tTop, tLeft, tTop, tRight, tBottom, tLeft, tBottom]);\n\n    gl.bindBuffer(gl.ARRAY_BUFFER, texturePosBuffer);\n    gl.bufferData(gl.ARRAY_BUFFER, texturePosValues, gl.DYNAMIC_DRAW);\n\n    tBottom = height / 2 / uRowCnt;\n    tRight = width / 2 / uDataPerRow;\n    var uTexturePosValues = new Float32Array([tRight, tTop, tLeft, tTop, tRight, tBottom, tLeft, tBottom]);\n\n    gl.bindBuffer(gl.ARRAY_BUFFER, uTexturePosBuffer);\n    gl.bufferData(gl.ARRAY_BUFFER, uTexturePosValues, gl.DYNAMIC_DRAW);\n\n    tBottom = height / 2 / vRowCnt;\n    tRight = width / 2 / vDataPerRow;\n\n    var vTexturePosValues = new Float32Array([tRight, tTop, tLeft, tTop, tRight, tBottom, tLeft, tBottom]);\n\n    gl.bindBuffer(gl.ARRAY_BUFFER, vTexturePosBuffer);\n    gl.bufferData(gl.ARRAY_BUFFER, vTexturePosValues, gl.DYNAMIC_DRAW);\n\n    gl.activeTexture(gl.TEXTURE0);\n    gl.bindTexture(gl.TEXTURE_2D, yTextureRef);\n    gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, yDataPerRow, yRowCnt, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, yData);\n\n    gl.activeTexture(gl.TEXTURE1);\n    gl.bindTexture(gl.TEXTURE_2D, uTextureRef);\n    gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, uDataPerRow, uRowCnt, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, uData);\n\n    gl.activeTexture(gl.TEXTURE2);\n    gl.bindTexture(gl.TEXTURE_2D, vTextureRef);\n    gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, vDataPerRow, vRowCnt, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, vData);\n\n    gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);\n  }\n\n  _drawPictureRGB(data) {}\n\n  render(data, width, height) {\n    var gl = this.contextGL;\n    if (gl) {\n      this._drawPictureGL(data, width, height);\n    } else {\n      this._drawPictureRGB(data);\n    }\n  }\n}\n\nexports.default = YUVCanvas;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/mobile/yuv-canvas.js?")},"../xgplayer-utils/src/models/media-info.js":
/*!**************************************************!*\
  !*** ../xgplayer-utils/src/models/media-info.js ***!
  \**************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\nconst isObjectFilled = obj => {\n  for (let key in obj) {\n    if (obj.hasOwnProperty(key)) {\n      if (obj[key] === null) {\n        return false;\n      }\n    }\n  }\n  return true;\n};\n\nclass MediaInfo {\n  constructor() {\n    this.mimeType = null;\n    this.duration = null;\n\n    this.hasVideo = null;\n    this.video = {\n      codec: null,\n      width: null,\n      height: null,\n      profile: null,\n      level: null,\n      frameRate: {\n        fixed: true,\n        fps: 25,\n        fps_num: 25000,\n        fps_den: 1000\n      },\n      chromaFormat: null,\n      parRatio: {\n        width: 1,\n        height: 1\n      }\n    };\n\n    this.hasAudio = null;\n\n    this.audio = {\n      codec: null,\n      sampleRate: null,\n      sampleRateIndex: null,\n      channelCount: null\n    };\n  }\n\n  isComplete() {\n    return MediaInfo.isBaseInfoReady(this) && MediaInfo.isVideoReady(this) && MediaInfo.isAudioReady(this);\n  }\n\n  static isBaseInfoReady(mediaInfo) {\n    return isObjectFilled(mediaInfo);\n  }\n\n  static isVideoReady(mediaInfo) {\n    if (!mediaInfo.hasVideo) {\n      return true;\n    }\n\n    return isObjectFilled(mediaInfo.video);\n  }\n\n  static isAudioReady(mediaInfo) {\n    if (!mediaInfo.hasAudio) {\n      return true;\n    }\n\n    return isObjectFilled(mediaInfo.video);\n  }\n}\nexports.default = MediaInfo;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/models/media-info.js?')},"../xgplayer-utils/src/models/media-sample.js":
/*!****************************************************!*\
  !*** ../xgplayer-utils/src/models/media-sample.js ***!
  \****************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass MediaSample {\n  constructor(info) {\n    let _default = MediaSample.getDefaultInf();\n\n    if (!info || Object.prototype.toString.call(info) !== '[object Object]') {\n      return _default;\n    }\n    let sample = Object.assign({}, _default, info);\n\n    Object.entries(sample).forEach(([k, v]) => {\n      this[k] = v;\n    });\n  }\n\n  static getDefaultInf() {\n    return {\n      dts: null,\n      pts: null,\n      duration: null,\n      position: null,\n      isRAP: false, // is Random access point\n      originDts: null\n    };\n  }\n}\nexports.default = MediaSample;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/models/media-sample.js?")},"../xgplayer-utils/src/models/media-segment-list.js":
/*!**********************************************************!*\
  !*** ../xgplayer-utils/src/models/media-segment-list.js ***!
  \**********************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n    value: true\n});\nclass MediaSegmentList {\n\n    constructor(type) {\n        this._type = type;\n        this._list = [];\n        this._lastAppendLocation = -1; // cached last insert location\n    }\n\n    get type() {\n        return this._type;\n    }\n\n    get length() {\n        return this._list.length;\n    }\n\n    isEmpty() {\n        return this._list.length === 0;\n    }\n\n    clear() {\n        this._list = [];\n        this._lastAppendLocation = -1;\n    }\n\n    _searchNearestSegmentBefore(beginDts) {\n        let list = this._list;\n        if (list.length === 0) {\n            return -2;\n        }\n        let last = list.length - 1;\n        let mid = 0;\n        let lbound = 0;\n        let ubound = last;\n\n        let idx = 0;\n\n        if (beginDts < list[0].originDts) {\n            idx = -1;\n            return idx;\n        }\n\n        while (lbound <= ubound) {\n            mid = lbound + Math.floor((ubound - lbound) / 2);\n            if (mid === last || beginDts > list[mid].lastSample.originDts && beginDts < list[mid + 1].originDts) {\n                idx = mid;\n                break;\n            } else if (list[mid].originDts < beginDts) {\n                lbound = mid + 1;\n            } else {\n                ubound = mid - 1;\n            }\n        }\n        return idx;\n    }\n\n    _searchNearestSegmentAfter(beginDts) {\n        return this._searchNearestSegmentBefore(beginDts) + 1;\n    }\n\n    append(segment) {\n        let list = this._list;\n        let lastAppendIdx = this._lastAppendLocation;\n        let insertIdx = 0;\n\n        if (lastAppendIdx !== -1 && lastAppendIdx < list.length && segment.originStartDts >= list[lastAppendIdx].lastSample.originDts && (lastAppendIdx === list.length - 1 || lastAppendIdx < list.length - 1 && segment.originStartDts < list[lastAppendIdx + 1].originStartDts)) {\n            insertIdx = lastAppendIdx + 1; // use cached location idx\n        } else {\n            if (list.length > 0) {\n                insertIdx = this._searchNearestSegmentBefore(segment.originStartDts) + 1;\n            }\n        }\n\n        this._lastAppendLocation = insertIdx;\n        this._list.splice(insertIdx, 0, segment);\n    }\n\n    getLastSegmentBefore(beginDts) {\n        let idx = this._searchNearestSegmentBefore(beginDts);\n        if (idx >= 0) {\n            return this._list[idx];\n        } else {\n            // -1\n            return null;\n        }\n    }\n\n    getLastSampleBefore(beginDts) {\n        let segment = this.getLastSegmentBefore(beginDts);\n        if (segment !== null) {\n            return segment.lastSample;\n        } else {\n            return null;\n        }\n    }\n\n    getLastRAPBefore(beginDts) {\n        let segmentIdx = this._searchNearestSegmentBefore(beginDts);\n        let randomAccessPoints = this._list[segmentIdx].randomAccessPoints;\n        while (randomAccessPoints.length === 0 && segmentIdx > 0) {\n            segmentIdx--;\n            randomAccessPoints = this._list[segmentIdx].randomAccessPoints;\n        }\n        if (randomAccessPoints.length > 0) {\n            return randomAccessPoints[randomAccessPoints.length - 1];\n        } else {\n            return null;\n        }\n    }\n\n}\nexports.default = MediaSegmentList;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/models/media-segment-list.js?')},"../xgplayer-utils/src/models/media-segment.js":
/*!*****************************************************!*\
  !*** ../xgplayer-utils/src/models/media-segment.js ***!
  \*****************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n    value: true\n});\nclass MediaSegment {\n    constructor() {\n        this.startDts = -1;\n        this.endDts = -1;\n        this.startPts = -1;\n        this.endPts = -1;\n        this.originStartDts = -1;\n        this.originEndDts = -1;\n        this.randomAccessPoints = [];\n        this.firstSample = null;\n        this.lastSample = null;\n    }\n\n    addRAP(sample) {\n        sample.isRAP = true;\n        this.randomAccessPoints.push(sample);\n    }\n}\nexports.default = MediaSegment;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/models/media-segment.js?')},"../xgplayer-utils/src/models/track-meta.js":
/*!**************************************************!*\
  !*** ../xgplayer-utils/src/models/track-meta.js ***!
  \**************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass AudioTrackMeta {\n  constructor(meta) {\n    const _default = {\n      sampleRate: 48000,\n      channelCount: 2,\n      codec: 'mp4a.40.2',\n      config: [41, 401, 136, 0],\n      duration: 0,\n      id: 2,\n      refSampleDuration: 21,\n      sampleRateIndex: 3,\n      timescale: 1000,\n      type: 'audio'\n    };\n    if (meta) {\n      return Object.assign({}, _default, meta);\n    }\n    return _default;\n  }\n}\n\nexports.AudioTrackMeta = AudioTrackMeta;\nclass VideoTrackMeta {\n  constructor(meta) {\n    const _default = {\n      avcc: null,\n      sps: new Uint8Array(0),\n      pps: new Uint8Array(0),\n      chromaFormat: 420,\n      codec: 'avc1.640020',\n      codecHeight: 720,\n      codecWidth: 1280,\n      duration: 0,\n      frameRate: {\n        fixed: true,\n        fps: 25,\n        fps_num: 25000,\n        fps_den: 1000\n      },\n      id: 1,\n      level: '3.2',\n      presentHeight: 720,\n      presentWidth: 1280,\n      profile: 'High',\n      refSampleDuration: 40,\n      parRatio: {\n        height: 1,\n        width: 1\n      },\n      timescale: 1000,\n      type: 'video'\n    };\n\n    if (meta) {\n      return Object.assign({}, _default, meta);\n    }\n    return _default;\n  }\n}\nexports.VideoTrackMeta = VideoTrackMeta;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/models/track-meta.js?")},"../xgplayer-utils/src/models/track-sample.js":
/*!****************************************************!*\
  !*** ../xgplayer-utils/src/models/track-sample.js ***!
  \****************************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval('\n\nObject.defineProperty(exports, "__esModule", {\n  value: true\n});\nclass AudioTrackSample {\n  constructor(info) {\n    let _default = AudioTrackSample.getDefault();\n    if (!info) {\n      return _default;\n    }\n    let sample = Object.assign({}, _default, info);\n\n    return sample;\n  }\n\n  static getDefault() {\n    return {\n      dts: null,\n      pts: null,\n      data: new Uint8Array()\n    };\n  }\n}\n\nexports.AudioTrackSample = AudioTrackSample;\nclass VideoTrackSample {\n  constructor(info) {\n    let _default = VideoTrackSample.getDefault();\n\n    if (!info) {\n      return _default;\n    }\n    let sample = Object.assign({}, _default, info);\n\n    return sample;\n  }\n\n  static getDefault() {\n    return {\n      dts: null,\n      pts: null,\n      isKeyframe: false, // is Random access point\n      originDts: null,\n      data: new Uint8Array()\n    };\n  }\n}\nexports.VideoTrackSample = VideoTrackSample;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/models/track-sample.js?')},"../xgplayer-utils/src/mse/index.js":
/*!******************************************!*\
  !*** ../xgplayer-utils/src/mse/index.js ***!
  \******************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass MSE {\n  constructor(configs) {\n    this.configs = Object.assign({}, configs);\n    this.container = this.configs.container;\n    this.mediaSource = null;\n    this.sourceBuffers = {};\n    this.preloadTime = this.configs.preloadTime || 1;\n  }\n\n  init() {\n    // eslint-disable-next-line no-undef\n    this.mediaSource = new self.MediaSource();\n    this.mediaSource.addEventListener('sourceopen', this.onSourceOpen.bind(this));\n    this.container.src = URL.createObjectURL(this.mediaSource);\n    this.url = this.container.src;\n    this.container.addEventListener('timeupdate', this.onTimeUpdate.bind(this));\n    this.container.addEventListener('waiting', this.onWaiting.bind(this));\n  }\n\n  onTimeUpdate() {\n    this.emit('TIME_UPDATE', this.container);\n  }\n\n  onWaiting() {\n    this.emit('WAITING', this.container);\n  }\n\n  onSourceOpen() {\n    this.addSourceBuffers();\n  }\n\n  onUpdateEnd() {\n    this.emit('SOURCE_UPDATE_END');\n    this.doAppend();\n  }\n  addSourceBuffers() {\n    if (this.mediaSource.readyState !== 'open') {\n      return;\n    }\n    let sources = this._context.getInstance('PRE_SOURCE_BUFFER');\n    let tracks = this._context.getInstance('TRACKS');\n    let track;\n\n    sources = sources.sources;\n    let add = false;\n    for (let i = 0, k = Object.keys(sources).length; i < k; i++) {\n      let type = Object.keys(sources)[i];\n      if (type === 'audio') {\n        track = tracks.audioTrack;\n      } else if (type === 'video') {\n        track = tracks.videoTrack;\n      }\n      if (track) {\n        let dur = type === 'audio' ? 21 : 40;\n        if (track.meta && track.meta.refSampleDuration) dur = track.meta.refSampleDuration;\n        if (sources[type].data.length >= this.preloadTime / dur) {\n          add = true;\n        }\n      }\n    }\n\n    if (add) {\n      if (Object.keys(this.sourceBuffers).length > 0) {\n        return;\n      }\n      for (let i = 0, k = Object.keys(sources).length; i < k; i++) {\n        let type = Object.keys(sources)[i];\n        let source = sources[type];\n        let mime = type === 'video' ? 'video/mp4;codecs=' + source.mimetype : 'audio/mp4;codecs=' + source.mimetype;\n        let sourceBuffer = this.mediaSource.addSourceBuffer(mime);\n        this.sourceBuffers[type] = sourceBuffer;\n        sourceBuffer.addEventListener('updateend', this.onUpdateEnd.bind(this));\n        this.doAppend();\n      }\n    }\n  }\n\n  doAppend() {\n    let sources = this._context.getInstance('PRE_SOURCE_BUFFER');\n    if (sources) {\n      for (let i = 0; i < Object.keys(this.sourceBuffers).length; i++) {\n        let type = Object.keys(this.sourceBuffers)[i];\n        let sourceBuffer = this.sourceBuffers[type];\n        if (!sourceBuffer.updating) {\n          let source = sources.sources[type];\n          if (source && !source.inited) {\n            sourceBuffer.appendBuffer(source.init.buffer.buffer);\n            source.inited = true;\n          } else if (source) {\n            let data = source.data.shift();\n            if (data) {\n              sourceBuffer.appendBuffer(data.buffer.buffer);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  endOfStream() {\n    if (this.mediaSource.readyState === 'open') {\n      this.mediaSource.endOfStream();\n    }\n  }\n\n  remove(end) {\n    for (let i = 0; i < Object.keys(this.sourceBuffers).length; i++) {\n      let buffer = this.sourceBuffers[Object.keys(this.sourceBuffers)[i]];\n      if (!buffer.updating) {\n        buffer.remove(0, end);\n      }\n    }\n  }\n\n  destroy() {\n    this.container.removeEventListener('timeupdate', this.onTimeUpdate);\n    this.container.removeEventListener('waiting', this.onWaiting);\n    this.mediaSource.removeEventListener('sourceopen', this.onSourceOpen);\n    this.configs = {};\n    this.container = null;\n    this.mediaSource = null;\n    this.sourceBuffers = {};\n    this.preloadTime = 1;\n    for (let i = 0; i < Object.keys(this.sourceBuffers).length; i++) {\n      let buffer = this.sourceBuffers[Object.keys(this.sourceBuffers)[i]];\n      buffer.removeEventListener('updateend', this.onUpdateEnd);\n      this.mediaSource.removeSourceBuffer(buffer);\n      delete this.sourceBuffers[Object.keys(this.sourceBuffers)[i]];\n    }\n  }\n}\nexports.default = MSE;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/mse/index.js?")},"../xgplayer-utils/src/write/buffer.js":
/*!*********************************************!*\
  !*** ../xgplayer-utils/src/write/buffer.js ***!
  \*********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _concatTypedArray = __webpack_require__(/*! concat-typed-array */ \"../xgplayer-utils/node_modules/concat-typed-array/lib/index.js\");\n\nvar _concatTypedArray2 = _interopRequireDefault(_concatTypedArray);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nclass Buffer {\n  constructor(buffer) {\n    this.buffer = buffer || new Uint8Array(0);\n  }\n\n  write(...buffer) {\n    buffer.forEach(item => {\n      this.buffer = (0, _concatTypedArray2.default)(Uint8Array, this.buffer, item);\n    });\n  }\n\n  static writeUint32(value) {\n    return new Uint8Array([value >> 24, value >> 16 & 0xff, value >> 8 & 0xff, value & 0xff]);\n  }\n\n  static readAsInt(arr) {\n    let temp = '';\n\n    function padStart4Hex(hexNum) {\n      let hexStr = hexNum.toString(16);\n      return hexStr.padStart(2, '0');\n    }\n\n    arr.forEach(num => {\n      temp += padStart4Hex(num);\n    });\n    return parseInt(temp, 16);\n  }\n}\n\nexports.default = Buffer;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/write/buffer.js?")},"../xgplayer-utils/src/write/stream.js":
/*!*********************************************!*\
  !*** ../xgplayer-utils/src/write/stream.js ***!
  \*********************************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nclass Stream {\n  constructor(buffer) {\n    if (buffer instanceof ArrayBuffer) {\n      this.buffer = buffer;\n      this.dataview = new DataView(buffer);\n      this.dataview.position = 0;\n    } else {\n      throw new Error('data is invalid');\n    }\n  }\n\n  get length() {\n    return this.buffer.byteLength;\n  }\n\n  set position(value) {\n    this.dataview.position = value;\n  }\n\n  get position() {\n    return this.dataview.position;\n  }\n\n  back(count) {\n    this.position -= count;\n  }\n\n  skip(count) {\n    let loop = Math.floor(count / 4);\n    let last = count % 4;\n    for (let i = 0; i < loop; i++) {\n      Stream.readByte(this.dataview, 4);\n    }\n    if (last > 0) {\n      Stream.readByte(this.dataview, last);\n    }\n  }\n\n  /**\n   * [readByte 从DataView中读取数据]\n   * @param  {DataView} buffer [DataView实例]\n   * @param  {Number} size   [读取字节数]\n   * @return {Number}        [整数]\n   */\n  static readByte(buffer, size, sign) {\n    let res;\n    switch (size) {\n      case 1:\n        if (sign) {\n          res = buffer.getInt8(buffer.position);\n        } else {\n          res = buffer.getUint8(buffer.position);\n        }\n        break;\n      case 2:\n        if (sign) {\n          res = buffer.getInt16(buffer.position);\n        } else {\n          res = buffer.getUint16(buffer.position);\n        }\n        break;\n      case 3:\n        if (sign) {\n          throw new Error('not supported for readByte 3');\n        } else {\n          res = buffer.getUint8(buffer.position) << 16;\n          res |= buffer.getUint8(buffer.position + 1) << 8;\n          res |= buffer.getUint8(buffer.position + 2);\n        }\n        break;\n      case 4:\n        if (sign) {\n          res = buffer.getInt32(buffer.position);\n        } else {\n          res = buffer.getUint32(buffer.position);\n        }\n        break;\n      case 8:\n        if (sign) {\n          throw new Error('not supported for readBody 8');\n        } else {\n          res = buffer.getUint32(buffer.position) << 32;\n          res |= buffer.getUint32(buffer.position + 4);\n        }\n        break;\n      default:\n        res = '';\n    }\n    buffer.position += size;\n    return res;\n  }\n\n  readUint8() {\n    return Stream.readByte(this.dataview, 1);\n  }\n\n  readUint16() {\n    return Stream.readByte(this.dataview, 2);\n  }\n\n  readUint24() {\n    return Stream.readByte(this.dataview, 3);\n  }\n\n  readUint32() {\n    return Stream.readByte(this.dataview, 4);\n  }\n\n  readUint64() {\n    return Stream.readByte(this.dataview, 8);\n  }\n\n  readInt8() {\n    return Stream.readByte(this.dataview, 1, true);\n  }\n  readInt16() {\n    return Stream.readByte(this.dataview, 2, true);\n  }\n\n  readInt32() {\n    return Stream.readByte(this.dataview, 4, true);\n  }\n\n  writeUint32(value) {\n    return new Uint8Array([value >>> 24 & 0xff, value >>> 16 & 0xff, value >>> 8 & 0xff, value & 0xff]);\n  }\n}\n\nexports.default = Stream;\n\n//# sourceURL=webpack://xgplayer-flv/../xgplayer-utils/src/write/stream.js?")},"./src/flv-live-mobile.js":
/*!********************************!*\
  !*** ./src/flv-live-mobile.js ***!
  \********************************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _xgplayerLoader = __webpack_require__(/*! xgplayer-loader */ \"../xgplayer-loader/index.js\");\n\nvar _xgplayerDemux = __webpack_require__(/*! xgplayer-demux */ \"../xgplayer-demux/index.js\");\n\nvar _xgplayerRemux = __webpack_require__(/*! xgplayer-remux */ \"../xgplayer-remux/index.js\");\n\nvar _xgplayerBuffer = __webpack_require__(/*! xgplayer-buffer */ \"../xgplayer-buffer/index.js\");\n\nvar _xgplayerUtils = __webpack_require__(/*! xgplayer-utils */ \"../xgplayer-utils/index.js\");\n\nvar _xgplayerCodec = __webpack_require__(/*! xgplayer-codec */ \"../xgplayer-codec/index.js\");\n\nvar _xgplayer = __webpack_require__(/*! xgplayer */ \"xgplayer\");\n\nvar _xgplayer2 = _interopRequireDefault(_xgplayer);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst DEMUX_EVENTS = _xgplayerUtils.EVENTS.DEMUX_EVENTS;\nconst LOADER_EVENTS = _xgplayerUtils.EVENTS.LOADER_EVENTS;\nconst REMUX_EVENTS = _xgplayerUtils.EVENTS.REMUX_EVENTS;\n\nconst Tag = 'FLVController';\n\nclass Logger {\n  warn() {}\n}\n\nclass FlvController {\n  constructor(player) {\n    this.TAG = Tag;\n    this._player = player;\n\n    // TODO 临时挂的 需要处理到Player层\n    // this.video = document.createElement('mobile-video');\n    this._player.video = document.createElement('mobile-video');\n    this.video = this._player.video;\n    this.state = {\n      initSegmentArrived: false\n    };\n  }\n\n  init() {\n    this._context.registry('FETCH_LOADER', _xgplayerLoader.FetchLoader);\n    this._context.registry('LOADER_BUFFER', _xgplayerBuffer.XgBuffer);\n    this._context.registry('PRE_SOURCE_BUFFER', _xgplayerBuffer.PreSource);\n\n    this._context.registry('FLV_DEMUXER', _xgplayerDemux.FlvDemuxer);\n\n    this._context.registry('MP4_REMUXER', _xgplayerRemux.Mp4Remuxer);\n    this._context.registry('TRACKS', _xgplayerBuffer.Tracks);\n\n    this._context.registry('COMPATIBILITY', _xgplayerCodec.Compatibility);\n\n    this._context.registry('LOGGER', Logger);\n\n    this.initListeners();\n  }\n\n  initListeners() {\n    this.on(LOADER_EVENTS.LOADER_DATALOADED, this._handleLoaderDataLoaded.bind(this));\n    this.on(LOADER_EVENTS.LOADER_ERROR, this._handleNetworkError.bind(this));\n\n    this.on(DEMUX_EVENTS.MEDIA_INFO, this._handleMediaInfo.bind(this));\n    this.on(DEMUX_EVENTS.METADATA_PARSED, this._handleMetadataParsed.bind(this));\n    this.on(DEMUX_EVENTS.DEMUX_COMPLETE, this._handleDemuxComplete.bind(this));\n    this.on(DEMUX_EVENTS.DEMUX_ERROR, this._handleDemuxError.bind(this));\n  }\n\n  _handleMediaInfo() {\n    if (!this._context.mediaInfo) {\n      this.emit(DEMUX_EVENTS.DEMUX_ERROR, new Error('failed to get mediainfo'));\n    }\n  }\n\n  _handleLoaderDataLoaded() {\n    this.emitTo('FLV_DEMUXER', DEMUX_EVENTS.DEMUX_START);\n  }\n\n  _handleMetadataParsed(type) {\n    if (type === 'audio') {\n      // 将音频meta信息交给audioContext，不走remux封装\n      const { audioTrack } = this._context.getInstance('TRACKS');\n      if (audioTrack && audioTrack.meta) {\n        this._setMetaToAudio(audioTrack.meta);\n      }\n    } else {\n      const { videoTrack } = this._context.getInstance('TRACKS');\n      if (videoTrack && videoTrack.meta) {\n        this._setMetaToVideo(videoTrack.meta);\n      }\n    }\n  }\n\n  _handleDemuxComplete() {\n    if (this._player.video) {\n      const { videoTrack, audioTrack } = this._context.getInstance('TRACKS');\n      this._player.video.onDemuxComplete(videoTrack, audioTrack);\n    }\n  }\n\n  _handleAppendInitSegment() {\n    this.state.initSegmentArrived = true;\n    //  this.mse.addSourceBuffers()\n  }\n\n  _handleNetworkError() {\n    this._player.emit('error', new _xgplayer2.default.Errors('network', this._player.config.url));\n  }\n\n  _handleDemuxError() {\n    this._player.emit('error', new _xgplayer2.default.Errors('parse', this._player.config.url));\n  }\n\n  _setMetaToAudio(audioMeta) {\n    if (this._player.video) {\n      this._player.video.setAudioMeta(audioMeta);\n    }\n  }\n\n  _setMetaToVideo(videoMeta) {\n    if (this._player.video) {\n      this._player.video.setVideoMeta(videoMeta);\n    }\n  }\n\n  seek() {\n    if (!this.state.initSegmentArrived) {\n      this.loadData();\n    }\n  }\n\n  loadData() {\n    this.emit(LOADER_EVENTS.LADER_START, this._player.config.url);\n  }\n\n  pause() {\n    const loader = this._context.getInstance('FETCH_LOADER');\n\n    if (loader) {\n      loader.cancel();\n    }\n  }\n\n  /**\n   * 保证当前播放的视频以gop为单位\n   * @param videoTrack\n   */\n  static resolveVideoGOP(videoTrack) {\n    const { samples } = videoTrack;\n    if (!samples.length) {\n      return;\n    }\n\n    let firstIframeIdx = null;\n    let lastIframeIdx = null;\n\n    if (videoTrack.tempSamples && videoTrack.tempSamples.length) {\n      // 将缓存帧放置到队列的头部\n      samples.unshift.apply(samples, videoTrack.tempSamples);\n    }\n\n    // 寻找第一个I帧\n    for (let i = 0, len = samples.length; i < len; i++) {\n      const current = samples[i];\n      if (current.isKeyframe) {\n        firstIframeIdx = i;\n        break;\n      }\n    }\n\n    // 寻找最后一个I帧\n    for (let i = samples.length - 1; i > 0; i++) {\n      const current = samples[i];\n\n      if (current.isKeyframe) {\n        lastIframeIdx = i;\n        break;\n      }\n    }\n\n    if (firstIframeIdx !== 0) {\n      samples.splice(0, firstIframeIdx - 1);\n    }\n\n    videoTrack.samples = samples.slice(0, lastIframeIdx);\n    const rest = samples.slice(lastIframeIdx);\n    if (videoTrack.tempSamples) {\n      videoTrack.tempSamples.push.apply(videoTrack.tempSamples, rest);\n    } else {\n      // 将剩下的帧缓存，等待一个完整的gop\n      videoTrack.tempSamples = rest;\n    }\n  }\n}\nexports.default = FlvController;\n\n//# sourceURL=webpack://xgplayer-flv/./src/flv-live-mobile.js?")},"./src/mobile.js":
/*!***********************!*\
  !*** ./src/mobile.js ***!
  \***********************/
/*! no static exports found */function(module,exports,__webpack_require__){"use strict";eval("\n\nvar _xgplayer = __webpack_require__(/*! xgplayer */ \"xgplayer\");\n\nvar _xgplayer2 = _interopRequireDefault(_xgplayer);\n\nvar _xgplayerUtils = __webpack_require__(/*! xgplayer-utils */ \"../xgplayer-utils/index.js\");\n\nvar _flvLiveMobile = __webpack_require__(/*! ./flv-live-mobile */ \"./src/flv-live-mobile.js\");\n\nvar _flvLiveMobile2 = _interopRequireDefault(_flvLiveMobile);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst flvAllowedEvents = _xgplayerUtils.EVENTS.FlvAllowedEvents;\n\nclass FlvPlayer extends _xgplayer2.default {\n  constructor(config) {\n    super(config);\n    this.context = new _xgplayerUtils.Context(flvAllowedEvents);\n    this.initEvents();\n  }\n\n  start() {\n    this.initFlv();\n    this.context.init();\n    this.flv.seek(0);\n    super.start(this.config.url);\n    this.play();\n  }\n\n  initFlvEvents(flv) {\n    const player = this;\n    flv.once(_xgplayerUtils.EVENTS.REMUX_EVENTS.INIT_SEGMENT, () => {\n      _xgplayer2.default.util.addClass(player.root, 'xgplayer-is-live');\n      if (!_xgplayer2.default.util.findDom(this.root, 'xg-live')) {\n        const live = _xgplayer2.default.util.createDom('xg-live', '正在直播', {}, 'xgplayer-live');\n        player.controls.appendChild(live);\n      }\n    });\n\n    flv.once(_xgplayerUtils.EVENTS.LOADER_EVENTS.LOADER_COMPLETE, () => {\n      // 直播完成，待播放器播完缓存后发送关闭事件\n      if (!player.paused) {\n        const timer = setInterval(() => {\n          const end = player.getBufferedRange()[1];\n          if (Math.abs(player.currentTime - end) < 0.5) {\n            player.emit('ended');\n            window.clearInterval(timer);\n          }\n        }, 200);\n      }\n    });\n  }\n\n  initEvents() {\n    this.on('timeupdate', () => {\n      this.loadData();\n    });\n\n    this.on('seeking', () => {\n      const time = this.currentTime;\n      const range = this.getBufferedRange();\n      if (time > range[1] || time < range[0]) {\n        this.flv.seek(this.currentTime);\n      }\n    });\n  }\n\n  initFlv() {\n    const flv = this.context.registry('FLV_CONTROLLER', _flvLiveMobile2.default)(this);\n    this.initFlvEvents(flv);\n    this.flv = flv;\n  }\n\n  play() {\n    console.log('play');\n    if (this._hasStart) {\n      this._destroy();\n      this.context = new _xgplayerUtils.Context(flvAllowedEvents);\n      const flv = this.context.registry('FLV_CONTROLLER', _flvLiveMobile2.default)(this);\n      this.initFlvEvents(flv);\n      this.flv = flv;\n      this.context.init();\n      super.start(flv.mse.url);\n      super.play();\n    } else {\n      super.play();\n    }\n  }\n\n  pause() {\n    super.pause();\n    if (this.flv) {\n      this.flv.pause();\n    }\n  }\n\n  loadData(time = this.currentTime) {\n    if (this.flv) {\n      this.flv.seek(time);\n    }\n  }\n  destroy() {\n    this._destroy();\n    super.destroy();\n  }\n\n  _destroy() {\n    this.context.destroy();\n    this.flv = null;\n    this.context = null;\n  }\n\n  get src() {\n    return this.currentSrc;\n  }\n\n  set src(url) {\n    this.player.config.url = url;\n    if (!this.paused) {\n      this.pause();\n      this.once('pause', () => {\n        this.start(url);\n      });\n      this.once('canplay', () => {\n        this.play();\n      });\n    } else {\n      this.start(url);\n    }\n    this.once('canplay', () => {\n      this.currentTime = 0;\n    });\n  }\n}\n\nmodule.exports = FlvPlayer;\n\n//# sourceURL=webpack://xgplayer-flv/./src/mobile.js?")},1:
/*!*****************************!*\
  !*** multi ./src/mobile.js ***!
  \*****************************/
/*! no static exports found */function(module,exports,__webpack_require__){eval('module.exports = __webpack_require__(/*! ./src/mobile.js */"./src/mobile.js");\n\n\n//# sourceURL=webpack://xgplayer-flv/multi_./src/mobile.js?')},xgplayer:
/*!***************************!*\
  !*** external "xgplayer" ***!
  \***************************/
/*! no static exports found */function(module,exports){eval("module.exports = __WEBPACK_EXTERNAL_MODULE_xgplayer__;\n\n//# sourceURL=webpack://xgplayer-flv/external_%22xgplayer%22?")}})}));